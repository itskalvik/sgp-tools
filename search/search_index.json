{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Home","text":"<p> A Python library for efficient sensor placement and informative path planning </p> <p> </p> <p> </p>"},{"location":"index.html#what-is-sgp-tools","title":"What is SGP-Tools?","text":"<p>SGP-Tools is a powerful and flexible Python library designed for solving Sensor Placement and Informative Path Planning problems, enabling efficient and scalable solutions for environment monitoring, e.g., monitoring air/water quality, soil moisture, or temperature.</p>"},{"location":"index.html#sensor-placement","title":"Sensor Placement","text":"<p>Sensor Placement is the problem of finding ideal locations to deploy a set of static sensors to best monitor a spatial phenomenon. The goal is to select a finite number of locations from a continuous space or a discrete set of candidates to maximize the information gathered about an entire area of interest. This is crucial when deploying a limited number of sensors to cover a large field.</p>"},{"location":"index.html#informative-path-planning-ipp","title":"Informative Path Planning (IPP)","text":"<p>Informative Path Planning extends this concept to mobile sensors. Instead of finding static locations, IPP aims to compute an informative path for one or more robots to travel along. The path is designed to maximize information gain about the environment, often while adhering to constraints such as a limited travel distance. This is essential for applications like aerial surveying or robotic exploration.</p>"},{"location":"index.html#ipp-vs-lawnmower-paths","title":"IPP vs. Lawnmower Paths","text":"<p>A common approach to surveying an area is to use a \"lawnmower\" path, a simple back-and-forth pattern designed for complete coverage. The following table summarizes the key differences between IPP and Lawnmower Paths:</p> Factor Lawnmower Path Informative Path Planning (IPP) Primary Goal Complete and uniform coverage of a predefined area. Targeted data collection in areas of high information or uncertainty. Performance Slow data collection but provides a high accuracy reconstruction of the envionment. Fast data collection but provides an approximate reconstruction of the envionment. Prior Knowledge Not required; often used when no prior information is available. Beneficial, but not required for adaptiev IPP; uses prior information to guide the sampling strategy. Adaptability Non-adaptive; the path is fixed before the mission starts. Highly adaptive; the path is updated in real-time based on sensor data. Efficiency Can be inefficient if the phenomenon of interest is sparse. Highly efficient for sparse or spatially variable phenomena. Computational Cost Low; simple to plan and execute. Medium; requires onboard processing to analyze data and update the path. Best For Baseline mapping, homogenous environments, initial surveys. Dynamic phenomena, resource-constrained missions."},{"location":"index.html#why-sgp-tools","title":"Why SGP-Tools?","text":"<ul> <li>State-of-the-Art Algorithms: Includes a variety of optimization methods including greedy algorithms, Bayesian optimization, CMA-ES, and SGP-based optimization.</li> <li>Advanced Modeling Capabilities: Go beyond simple point sensing with tools for informative path planning for multi-robot systems and complex sensor field-of-view (FoV) models.</li> <li>Non-Stationary Kernels: Capture complex, real-world phenomena with specialized non-stationary kernels like the Neural Spectral Kernel and the Attentive Kernel.</li> <li>Flexible and Extensible: Built on GPflow and TensorFlow, the library is designed to be modular and easy to extend with your own custom methods, kernels, and objectives.</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<p>The library is available as a <code>pip</code> package. To install the package, run the following command:</p> <pre><code>python3 -m pip install sgptools\n</code></pre> <p>Installation from source:</p> <pre><code>git clone https://github.com/itskalvik/sgp-tools.git\ncd sgp-tools/\npython3 -m pip install -r requirements.txt\npython3 -m pip install -e .\n</code></pre> <p>Note: The requirements.txt file contains packages and their latest versions that were last verified to be working without any issues.</p>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<p>Here's an example of how to use SGP-Tools to get an informative path using the <code>ContinuousSGP</code> method:</p> <pre><code>from sgptools.utils.data import Dataset # Class for loading and managing datasets\nfrom sgptools.utils.misc import get_inducing_pts # Utility for selecting inducing points\nfrom sgptools.utils.tsp import run_tsp # TSP/VRP solver for initial path planning\nfrom sgptools.utils.gpflow import get_model_params # For training initial GP/SGP hyperparameters\nfrom sgptools.methods import get_method # Gets the class for continuous SGP optimization\nfrom sgptools.core.transformations import IPPTransform # Transforms for IPP\n\n# 1. Load or generate a dataset\n# This will create a synthetic dataset for demonstration\ndataset = Dataset(num_train=500, num_test=10000, \n                  shape=(100, 100))\nX_train, y_train = dataset.get_train()\nX_test, y_test = dataset.get_test()\n\n# 2. Learn the GP hyperparameters from the training data\nprint(\"Learning GP hyperparameters...\")\n_, noise_variance, kernel = get_model_params(\n    X_train, y_train, max_steps=1000, verbose=True\n)\n\n# 3. Setup the IPP model\nnum_placements = 15\n\n# Initialize inducing points and get initial path\nXu_init = get_inducing_pts(X_train, num_placements)\nXu_init, _ = run_tsp(Xu_init, time_limit=10)\n\n# Setup IPP transform with a sampling rate for continuous sensing\ntransform_continuous_sensing = IPPTransform(sampling_rate=4)\n\n# Initialize the ContinuousSGP model\nmethod = get_method('ContinuousSGP')\ncsgp_optimizer = method(\n    num_placements, \n    X_train, \n    kernel,\n    noise_variance, \n    transform_continuous_sensing,\n    X_init=Xu_init[0]\n)\n\n# 4. Run the optimization\nprint(\"Optimizing sensor placements...\")\nsolution_path = csgp_optimizer.optimize(max_steps=200)\n\nprint(f\"Solution Path: {solution_path}\")\n</code></pre> <p> </p> <p>For more detailed instructions, please refer to our tutorials</p>"},{"location":"index.html#sgp-based-ipp","title":"SGP-based IPP","text":""},{"location":"index.html#datasets","title":"Datasets","text":"<p>High-resolution topography and bathymetry data can be downloaded from NOAA Digital Coast</p>"},{"location":"index.html#about","title":"About","text":"<p>Please consider citing the following papers if you use SGP-Tools in your academic work \ud83d\ude04</p> <pre><code>@article{JakkalaA25,\nauthor={Kalvik Jakkala and Srinivas Akella},\ntitle ={Fully differentiable sensor placement and informative path planning},\njournal = {The International Journal of Robotics Research},\nyear = {2025},\nURL={https://www.itskalvik.com/publication/sgp-foundation/},\n}\n\n@inproceedings{JakkalaA24IPP,\nAUTHOR={Kalvik Jakkala and Srinivas Akella},\nTITLE={Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes},\nbooktitle={IEEE International Conference on Robotics and Automation, {ICRA}},\nYEAR={2024},\nPUBLISHER = {{IEEE}},\nURL={https://www.itskalvik.com/publication/sgp-ipp/}\n}\n\n@inproceedings{JakkalaA25AIPP,\nAUTHOR={Kalvik Jakkala and Srinivas Akella},\nTITLE={Fully Differentiable Adaptive Informative Path Planning},\nbooktitle={IEEE International Conference on Robotics and Automation, {ICRA}},\nYEAR={2025},\nPUBLISHER = {{IEEE}},\nURL={https://www.itskalvik.com/publication/sgp-aipp/}\n}\n</code></pre>"},{"location":"index.html#acknowledgements","title":"Acknowledgements","text":"<p>This work was funded in part by the UNC Charlotte Office of Research and Economic Development and by NSF under Award Number IIP-1919233.</p>"},{"location":"api/index.html","title":"How It All Works Together: A Conceptual Workflow","text":"<p>A typical use case of the <code>sgptools</code> library would follow these steps:</p> <ol> <li> <p>Load Data: A user would start by creating a <code>Dataset</code> object from their data, which could be a <code>.tif</code> file or a <code>NumPy</code> array. The <code>Dataset</code> class handles the necessary preprocessing and standardization. Alternatively, the user can use real-time data from a robot. </p> </li> <li> <p>Define a Transformation: Based on the problem, the user would instantiate a <code>Transform</code> object. For example, for a multi-robot path planning problem with a distance budget, they would use <code>IPPTransform</code>. For a single sensor with a square field of view, they might use <code>SquareTransform</code>.</p> </li> <li> <p>Choose an Optimization Method: The user would then select an optimization method from the <code>methods</code> module. For the novel SGP-based approach, they would choose <code>ContinuousSGP</code>. For comparison with other methods, they could use <code>BayesianOpt</code>, <code>CMA</code>, or the greedy methods.</p> </li> <li> <p>Run Optimization: The <code>optimize()</code> method of the chosen optimizer is called. This will run the optimization algorithm (e.g., maximizing the ELBO in the case of <code>ContinuousSGP</code>) and return the optimized sensor locations or paths.</p> </li> <li> <p>Post-processing: The solution might be post-processed, for example, by mapping the continuous locations to a set of discrete candidates using <code>cont2disc</code>.</p> </li> </ol>"},{"location":"api/core/index.html","title":"<code>core</code>: Core Gaussian Process Models and Transformations","text":"<p>This module contains the fundamental building blocks for modeling and transforming sensor data.</p> <ul> <li> <p><code>AugmentedSGPR</code> and <code>AugmentedGPR</code>: These are extensions of GPflow's <code>SGPR</code> and <code>GPR</code> models. They are \"augmented\" to incorporate custom <code>Transformations</code> on the inducing points, which is a key feature of this library for modeling complex sensor setups.</p> </li> <li> <p><code>Transformations</code>: This is a crucial part of the library, defining how inducing points in the SGP are manipulated to represent different physical sensing scenarios.</p> <ul> <li> <p><code>Transform</code>: The base class for all transformations.</p> </li> <li> <p><code>IPPTransform</code>: A versatile transform for Informative Path Planning (IPP). It can model continuous sensing paths (by interpolating points between waypoints), handle multi-robot scenarios, and enforce distance constraints on the paths. It also supports online IPP where some waypoints are fixed.</p> </li> <li> <p><code>SquareTransform</code> and <code>SquareHeightTransform</code>: These transforms model non-point, 2D fields of view (FoV). <code>SquareTransform</code> creates a square FoV with a fixed size and optimizable orientation, while <code>SquareHeightTransform</code> models a FoV whose size depends on the sensor's height from the ground (the z-dimension).</p> </li> </ul> </li> <li> <p><code>osgpr</code>: This module provides an implementation of an Online Sparse Variational GP regression model (<code>OSGPR_VFE</code>), which is designed for streaming data scenarios where the model is updated sequentially with new data batches; used for adaptive IPP. The <code>init_osgpr</code> function helps in setting up this model.</p> </li> </ul>"},{"location":"api/core/augmented_gpr.html","title":"AugmentedGPR","text":""},{"location":"api/core/augmented_gpr.html#sgptools.core.augmented_gpr.AugmentedGPR","title":"<code>sgptools.core.augmented_gpr.AugmentedGPR</code>","text":"<p>               Bases: <code>GPR</code></p> <p>GPR model from the GPFlow library augmented to use a transform object's expand and aggregate functions on the data points where necessary.  </p> Refer to the following papers for more details <ul> <li>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]</li> <li>Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>tuple</code> <p>(X, y) ndarrays with inputs (n, d) and labels (n, 1)</p> required <code>kernel</code> <code>Kernel</code> <p>gpflow kernel function</p> required <code>noise_variance</code> <code>float</code> <p>data variance</p> required <code>transform</code> <code>Transform</code> <p>Transform object</p> <code>None</code> Source code in <code>sgptools/core/augmented_gpr.py</code> <pre><code>class AugmentedGPR(GPR):\n    \"\"\"GPR model from the GPFlow library augmented to use a transform object's\n    expand and aggregate functions on the data points where necessary.  \n\n    Refer to the following papers for more details:\n        - Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]\n        - Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]\n\n    Args:\n        data (tuple): (X, y) ndarrays with inputs (n, d) and labels (n, 1)\n        kernel (gpflow.kernels.Kernel): gpflow kernel function\n        noise_variance (float): data variance\n        transform (Transform): Transform object\n    \"\"\"\n\n    def __init__(self, *args, transform=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        if transform is None:\n            self.transform = Transform()\n        else:\n            self.transform = transform\n\n    def predict_f(\n        self,\n        Xnew: InputData,\n        full_cov: bool = True,\n        full_output_cov: bool = False,\n        aggregate_train: bool = False,\n    ) -&gt; MeanAndVariance:\n        assert_params_false(self.predict_f, full_output_cov=full_output_cov)\n        if self.transform is not None:\n            Xnew = self.transform.expand(Xnew)\n\n        X, Y = self.data\n        err = Y - self.mean_function(X)\n\n        kmm = self.kernel(X)\n        knn = self.kernel(Xnew, full_cov=full_cov)\n        kmn = self.kernel(X, Xnew)\n        kmm_plus_s = add_likelihood_noise_cov(kmm, self.likelihood, X)\n\n        if self.transform is not None:\n            kmn = self.transform.aggregate(tf.transpose(kmn))\n            kmn = tf.transpose(kmn)\n            knn = self.transform.aggregate(knn)\n\n        if aggregate_train:\n            kmm_plus_s = self.transform.aggregate(kmm_plus_s)\n            err = self.transform.aggregate(err)\n            # reduce kmn only if it was not reduced before\n            # which can when train and test data are the same size\n            if kmn.shape[0] != kmn.shape[1]:\n                kmn = self.transform.aggregate(kmn)\n\n        conditional = gpflow.conditionals.base_conditional\n        f_mean_zero, f_var = conditional(\n            kmn, kmm_plus_s, knn, err, full_cov=full_cov,\n            white=False)  # [N, P], [N, P] or [P, N, N]\n        f_mean = f_mean_zero + self.mean_function(Xnew)\n        return f_mean, f_var\n</code></pre>"},{"location":"api/core/augmented_sgpr.html","title":"AugmentedSGPR","text":""},{"location":"api/core/augmented_sgpr.html#sgptools.core.augmented_sgpr.AugmentedSGPR","title":"<code>sgptools.core.augmented_sgpr.AugmentedSGPR</code>","text":"<p>               Bases: <code>SGPR</code></p> <p>SGPR model from the GPFlow library augmented to use a transform object's expand and aggregate functions on the inducing points where necessary. The object has an additional update function to update the kernel and noise variance parameters  (currently, the online updates part works only with RBF kernels).  </p> Refer to the following papers for more details <ul> <li>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]</li> <li>Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>tuple</code> <p>(X, y) ndarrays with inputs (n, d) and labels (n, 1)</p> required <code>kernel</code> <code>Kernel</code> <p>gpflow kernel function</p> required <code>noise_variance</code> <code>float</code> <p>data variance</p> required <code>inducing_variable</code> <code>ndarray</code> <p>(m, d); Initial inducing points</p> required <code>transform</code> <code>Transform</code> <p>Transform object</p> <code>None</code> <code>inducing_variable_time</code> <code>ndarray</code> <p>(m, d); Temporal dimensions of the inducing points,                                  used when modeling spatio-temporal IPP</p> <code>None</code> Source code in <code>sgptools/core/augmented_sgpr.py</code> <pre><code>class AugmentedSGPR(SGPR):\n    \"\"\"SGPR model from the GPFlow library augmented to use a transform object's\n    expand and aggregate functions on the inducing points where necessary. The object\n    has an additional update function to update the kernel and noise variance parameters \n    (currently, the online updates part works only with RBF kernels).  \n\n\n    Refer to the following papers for more details:\n        - Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]\n        - Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]\n\n    Args:\n        data (tuple): (X, y) ndarrays with inputs (n, d) and labels (n, 1)\n        kernel (gpflow.kernels.Kernel): gpflow kernel function\n        noise_variance (float): data variance\n        inducing_variable (ndarray): (m, d); Initial inducing points\n        transform (Transform): Transform object\n        inducing_variable_time (ndarray): (m, d); Temporal dimensions of the inducing points, \n                                            used when modeling spatio-temporal IPP\n    \"\"\"\n\n    def __init__(self,\n                 *args,\n                 transform=None,\n                 inducing_variable_time=None,\n                 **kwargs):\n        super().__init__(*args, **kwargs)\n        if transform is None:\n            self.transform = Transform()\n        else:\n            self.transform = transform\n\n        if inducing_variable_time is not None:\n            self.inducing_variable_time = inducingpoint_wrapper(\n                inducing_variable_time)\n            self.transform.inducing_variable_time = self.inducing_variable_time\n        else:\n            self.inducing_variable_time = None\n\n    def update(self, kernel, noise_variance):\n        \"\"\"Update SGP noise variance and kernel function parameters\n\n        Args:\n            kernel (gpflow.kernels.Kernel): gpflow kernel function\n            noise_variance (float): data variance\n        \"\"\"\n        self.likelihood.variance.assign(noise_variance)\n        for self_var, var in zip(self.kernel.trainable_variables,\n                                 kernel.trainable_variables):\n            self_var.assign(var)\n\n    def _common_calculation(self) -&gt; \"SGPR.CommonTensors\":\n        \"\"\"\n        Matrices used in log-det calculation\n        :return: A , B, LB, AAT with :math:`LL\u1d40 = K\u1d64\u1d64 , A = L\u207b\u00b9K_{uf}/\u03c3, AAT = AA\u1d40,\n            B = AAT+I, LBLB\u1d40 = B`\n            A is M x N, B is M x M, LB is M x M, AAT is M x M\n        \"\"\"\n        x, _ = self.data\n\n        iv = self.inducing_variable.Z  # [M]\n        iv = self.transform.expand(iv)\n\n        kuf = self.kernel(iv, x)\n        kuf = self.transform.aggregate(kuf)\n\n        kuu = self.kernel(iv) + 1e-6 * tf.eye(tf.shape(iv)[0], dtype=iv.dtype)\n        kuu = self.transform.aggregate(kuu)\n\n        L = tf.linalg.cholesky(kuu)\n\n        sigma_sq = self.likelihood.variance\n        sigma = tf.sqrt(sigma_sq)\n\n        # Compute intermediate matrices\n        A = tf.linalg.triangular_solve(L, kuf, lower=True) / sigma\n        AAT = tf.linalg.matmul(A, A, transpose_b=True)\n        B = add_noise_cov(AAT, tf.cast(1.0, AAT.dtype))\n        LB = tf.linalg.cholesky(B)\n\n        return self.CommonTensors(sigma_sq, sigma, A, B, LB, AAT, L)\n\n    def elbo(self) -&gt; tf.Tensor:\n        \"\"\"\n        Construct a tensorflow function to compute the bound on the marginal\n        likelihood. For a derivation of the terms in here, see the associated\n        SGPR notebook.\n        \"\"\"\n        common = self._common_calculation()\n        output_shape = tf.shape(self.data[-1])\n        num_data = to_default_float(output_shape[0])\n        output_dim = to_default_float(output_shape[1])\n        const = -0.5 * num_data * output_dim * np.log(2 * np.pi)\n        logdet = self.logdet_term(common)\n        quad = self.quad_term(common)\n        constraints = self.transform.constraints(self.inducing_variable.Z)\n        return const + logdet + quad + constraints\n\n    def predict_f(self,\n                  Xnew: InputData,\n                  full_cov: bool = False,\n                  full_output_cov: bool = False) -&gt; MeanAndVariance:\n\n        # could copy into posterior into a fused version\n        \"\"\"\n        Compute the mean and variance of the latent function at some new points\n        Xnew. For a derivation of the terms in here, see the associated SGPR\n        notebook.\n        \"\"\"\n        X_data, Y_data = self.data\n\n        iv = self.inducing_variable.Z\n        iv = self.transform.expand(iv)\n\n        num_inducing = tf.shape(iv)[0]\n\n        err = Y_data - self.mean_function(X_data)\n        kuf = self.kernel(iv, X_data)\n        kuu = self.kernel(iv) + 1e-6 * tf.eye(num_inducing, dtype=iv.dtype)\n        Kus = self.kernel(iv, Xnew)\n        sigma = tf.sqrt(self.likelihood.variance)\n        L = tf.linalg.cholesky(kuu)\n        A = tf.linalg.triangular_solve(L, kuf, lower=True) / sigma\n        B = tf.linalg.matmul(A, A, transpose_b=True) + tf.eye(\n            num_inducing, dtype=default_float())  # cache qinv\n        LB = tf.linalg.cholesky(B)\n        Aerr = tf.linalg.matmul(A, err)\n        c = tf.linalg.triangular_solve(LB, Aerr, lower=True) / sigma\n        tmp1 = tf.linalg.triangular_solve(L, Kus, lower=True)\n        tmp2 = tf.linalg.triangular_solve(LB, tmp1, lower=True)\n        mean = tf.linalg.matmul(tmp2, c, transpose_a=True)\n        if full_cov:\n            var = (self.kernel(Xnew) +\n                   tf.linalg.matmul(tmp2, tmp2, transpose_a=True) -\n                   tf.linalg.matmul(tmp1, tmp1, transpose_a=True))\n            var = tf.tile(var[None, ...],\n                          [self.num_latent_gps, 1, 1])  # [P, N, N]\n        else:\n            var = (self.kernel(Xnew, full_cov=False) +\n                   tf.reduce_sum(tf.square(tmp2), 0) -\n                   tf.reduce_sum(tf.square(tmp1), 0))\n            var = tf.tile(var[:, None], [1, self.num_latent_gps])\n\n        return mean + self.mean_function(Xnew), var\n</code></pre>"},{"location":"api/core/augmented_sgpr.html#sgptools.core.augmented_sgpr.AugmentedSGPR.elbo","title":"<code>elbo()</code>","text":"<p>Construct a tensorflow function to compute the bound on the marginal likelihood. For a derivation of the terms in here, see the associated SGPR notebook.</p> Source code in <code>sgptools/core/augmented_sgpr.py</code> <pre><code>def elbo(self) -&gt; tf.Tensor:\n    \"\"\"\n    Construct a tensorflow function to compute the bound on the marginal\n    likelihood. For a derivation of the terms in here, see the associated\n    SGPR notebook.\n    \"\"\"\n    common = self._common_calculation()\n    output_shape = tf.shape(self.data[-1])\n    num_data = to_default_float(output_shape[0])\n    output_dim = to_default_float(output_shape[1])\n    const = -0.5 * num_data * output_dim * np.log(2 * np.pi)\n    logdet = self.logdet_term(common)\n    quad = self.quad_term(common)\n    constraints = self.transform.constraints(self.inducing_variable.Z)\n    return const + logdet + quad + constraints\n</code></pre>"},{"location":"api/core/augmented_sgpr.html#sgptools.core.augmented_sgpr.AugmentedSGPR.predict_f","title":"<code>predict_f(Xnew, full_cov=False, full_output_cov=False)</code>","text":"<p>Compute the mean and variance of the latent function at some new points Xnew. For a derivation of the terms in here, see the associated SGPR notebook.</p> Source code in <code>sgptools/core/augmented_sgpr.py</code> <pre><code>def predict_f(self,\n              Xnew: InputData,\n              full_cov: bool = False,\n              full_output_cov: bool = False) -&gt; MeanAndVariance:\n\n    # could copy into posterior into a fused version\n    \"\"\"\n    Compute the mean and variance of the latent function at some new points\n    Xnew. For a derivation of the terms in here, see the associated SGPR\n    notebook.\n    \"\"\"\n    X_data, Y_data = self.data\n\n    iv = self.inducing_variable.Z\n    iv = self.transform.expand(iv)\n\n    num_inducing = tf.shape(iv)[0]\n\n    err = Y_data - self.mean_function(X_data)\n    kuf = self.kernel(iv, X_data)\n    kuu = self.kernel(iv) + 1e-6 * tf.eye(num_inducing, dtype=iv.dtype)\n    Kus = self.kernel(iv, Xnew)\n    sigma = tf.sqrt(self.likelihood.variance)\n    L = tf.linalg.cholesky(kuu)\n    A = tf.linalg.triangular_solve(L, kuf, lower=True) / sigma\n    B = tf.linalg.matmul(A, A, transpose_b=True) + tf.eye(\n        num_inducing, dtype=default_float())  # cache qinv\n    LB = tf.linalg.cholesky(B)\n    Aerr = tf.linalg.matmul(A, err)\n    c = tf.linalg.triangular_solve(LB, Aerr, lower=True) / sigma\n    tmp1 = tf.linalg.triangular_solve(L, Kus, lower=True)\n    tmp2 = tf.linalg.triangular_solve(LB, tmp1, lower=True)\n    mean = tf.linalg.matmul(tmp2, c, transpose_a=True)\n    if full_cov:\n        var = (self.kernel(Xnew) +\n               tf.linalg.matmul(tmp2, tmp2, transpose_a=True) -\n               tf.linalg.matmul(tmp1, tmp1, transpose_a=True))\n        var = tf.tile(var[None, ...],\n                      [self.num_latent_gps, 1, 1])  # [P, N, N]\n    else:\n        var = (self.kernel(Xnew, full_cov=False) +\n               tf.reduce_sum(tf.square(tmp2), 0) -\n               tf.reduce_sum(tf.square(tmp1), 0))\n        var = tf.tile(var[:, None], [1, self.num_latent_gps])\n\n    return mean + self.mean_function(Xnew), var\n</code></pre>"},{"location":"api/core/augmented_sgpr.html#sgptools.core.augmented_sgpr.AugmentedSGPR.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Update SGP noise variance and kernel function parameters</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>gpflow kernel function</p> required <code>noise_variance</code> <code>float</code> <p>data variance</p> required Source code in <code>sgptools/core/augmented_sgpr.py</code> <pre><code>def update(self, kernel, noise_variance):\n    \"\"\"Update SGP noise variance and kernel function parameters\n\n    Args:\n        kernel (gpflow.kernels.Kernel): gpflow kernel function\n        noise_variance (float): data variance\n    \"\"\"\n    self.likelihood.variance.assign(noise_variance)\n    for self_var, var in zip(self.kernel.trainable_variables,\n                             kernel.trainable_variables):\n        self_var.assign(var)\n</code></pre>"},{"location":"api/core/osgpr.html","title":"OSGPR","text":""},{"location":"api/core/osgpr.html#sgptools.core.osgpr.OSGPR_VFE","title":"<code>sgptools.core.osgpr.OSGPR_VFE</code>","text":"<p>               Bases: <code>GPModel</code>, <code>InternalDataTrainingLossMixin</code></p> <p>Online Sparse Variational GP regression model from streaming_sparse_gp</p> Refer to the following paper for more details <ul> <li>Streaming Gaussian process approximations [Bui et al., 2017]</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>tuple</code> <p>(X, y) ndarrays with inputs (n, d) and labels (n, 1)</p> required <code>kernel</code> <code>Kernel</code> <p>gpflow kernel function</p> required <code>mu_old</code> <code>ndarray</code> <p>mean of old <code>q(u)</code>; here <code>u</code> are the latents corresponding to the inducing points <code>Z_old</code></p> required <code>Su_old</code> <code>ndarray</code> <p>posterior covariance of old <code>q(u)</code></p> required <code>Kaa_old</code> <code>ndarray</code> <p>prior covariance of old <code>q(u)</code></p> required <code>Z_old</code> <code>ndarray</code> <p>(m_old, d): Old initial inducing points</p> required <code>Z</code> <code>ndarray</code> <p>(m_new, d): New initial inducing points</p> required <code>mean_function</code> <code>function</code> <p>GP mean function</p> <code>None</code> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>class OSGPR_VFE(GPModel, InternalDataTrainingLossMixin):\n    \"\"\"Online Sparse Variational GP regression model from [streaming_sparse_gp](https://github.com/thangbui/streaming_sparse_gp/tree/master)\n\n    Refer to the following paper for more details:\n        - Streaming Gaussian process approximations [Bui et al., 2017]\n\n    Args:\n        data (tuple): (X, y) ndarrays with inputs (n, d) and labels (n, 1)\n        kernel (gpflow.kernels.Kernel): gpflow kernel function\n        mu_old (ndarray): mean of old `q(u)`; here `u` are the latents corresponding to the inducing points `Z_old`\n        Su_old (ndarray): posterior covariance of old `q(u)`\n        Kaa_old (ndarray): prior covariance of old `q(u)`\n        Z_old (ndarray): (m_old, d): Old initial inducing points\n        Z (ndarray): (m_new, d): New initial inducing points\n        mean_function (function): GP mean function\n    \"\"\"\n\n    def __init__(self,\n                 data,\n                 kernel,\n                 mu_old,\n                 Su_old,\n                 Kaa_old,\n                 Z_old,\n                 Z,\n                 mean_function=None):\n        self.X, self.Y = self.data = gpflow.models.util.data_input_to_tensor(\n            data)\n        likelihood = gpflow.likelihoods.Gaussian()\n        num_latent_gps = GPModel.calc_num_latent_gps_from_data(\n            data, kernel, likelihood)\n        super().__init__(kernel, likelihood, mean_function, num_latent_gps)\n\n        self.inducing_variable = InducingPoints(Z)\n        self.num_data = self.X.shape[0]\n\n        self.mu_old = tf.Variable(mu_old,\n                                  shape=tf.TensorShape(None),\n                                  trainable=False)\n        self.M_old = Z_old.shape[0]\n        self.Su_old = tf.Variable(Su_old,\n                                  shape=tf.TensorShape(None),\n                                  trainable=False)\n        self.Kaa_old = tf.Variable(Kaa_old,\n                                   shape=tf.TensorShape(None),\n                                   trainable=False)\n        self.Z_old = tf.Variable(Z_old,\n                                 shape=tf.TensorShape(None),\n                                 trainable=False)\n\n    def init_Z(self) -&gt; np.ndarray:\n        \"\"\"\n        Initializes the new set of inducing points (Z) for the OSGPR model.\n        It combines a subset of the old inducing points (Z_old) with a subset\n        of the current training data (X).\n\n        Returns:\n            np.ndarray: (M, d); A NumPy array of the newly initialized inducing points,\n                        combining old and new data-based points.\n        \"\"\"\n        M = self.inducing_variable.Z.shape[0]\n        M_old = int(0.7 * M)  # Proportion of old inducing points to retain\n        M_new = M - M_old  # Proportion of new data points to select\n\n        # Randomly select M_old points from the old inducing points\n        old_Z = self.Z_old.numpy()[np.random.permutation(M)[0:M_old], :]\n\n        # Randomly select M_new points from the current training data\n        new_Z = self.X.numpy()[\n            np.random.permutation(self.X.shape[0])[0:M_new], :]\n\n        # Vertically stack the selected old and new points to form the new Z\n        Z = np.vstack((old_Z, new_Z))\n        return Z\n\n    def update(self, data, inducing_variable=None, update_inducing=True):\n        \"\"\"\n        Configures the OSGPR model to adapt to a new batch of data.\n        This method updates the model's data, its inducing points (optionally),\n        and caches the posterior mean and covariance of the *old* inducing points\n        to facilitate the streaming update equations.\n\n        Note: After calling this update, the OSGPR model typically needs to be\n        trained further using gradient-based optimization to fully incorporate\n        the new data and optimize its parameters.\n\n        Args:\n            data (Tuple[np.ndarray, np.ndarray]): A tuple (X, y) representing the new batch\n                                                  of input data `X` (n, d) and corresponding labels `y` (n, 1).\n            inducing_variable (Optional[np.ndarray]): (m_new, d); Optional NumPy array for the new\n                                                     set of inducing points. If None and `update_inducing`\n                                                     is True, `init_Z` will be called to determine them.\n                                                     Defaults to None.\n            update_inducing (bool): If True, the inducing points will be updated. If False,\n                                    they will remain as they were before the update call.\n                                    Defaults to True.\n        \"\"\"\n        self.X, self.Y = self.data = gpflow.models.util.data_input_to_tensor(\n            data)\n        self.num_data = self.X.shape[0]\n\n        # Store the current inducing points as 'old' for the next update step\n        self.Z_old.assign(self.inducing_variable.Z)\n\n        # Update the inducing points based on `update_inducing` flag\n        if update_inducing:\n            if inducing_variable is None:\n                # If no explicit inducing_variable is provided, initialize new ones\n                new_Z_init = self.init_Z()\n            else:\n                # Use the explicitly provided inducing_variable\n                new_Z_init = inducing_variable\n            self.inducing_variable.Z.assign(\n                tf.constant(new_Z_init, dtype=self.inducing_variable.Z.dtype))\n        # If update_inducing is False, inducing_variable.Z retains its current value.\n\n        # Get posterior mean and covariance for the *old* inducing points using the current model state\n        mu_old, Su_old = self.predict_f(self.Z_old, full_cov=True)\n        self.mu_old.assign(mu_old)\n        self.Su_old.assign(Su_old)\n\n        # Get the prior covariance matrix for the *old* inducing points using the current kernel\n        Kaa_old = self.kernel(self.Z_old)\n        self.Kaa_old.assign(Kaa_old)\n\n    def _common_terms(self):\n        Mb = self.inducing_variable.num_inducing\n        Ma = self.M_old\n        # jitter = gpflow.default_jitter()\n        jitter = gpflow.utilities.to_default_float(1e-4)\n        sigma2 = self.likelihood.variance\n        sigma = tf.sqrt(sigma2)\n\n        Saa = self.Su_old\n        ma = self.mu_old\n\n        # a is old inducing points, b is new\n        # f is training points\n        # s is test points\n        Kbf = covariances.Kuf(self.inducing_variable, self.kernel, self.X)\n        Kbb = covariances.Kuu(self.inducing_variable,\n                              self.kernel,\n                              jitter=jitter)\n        Kba = covariances.Kuf(self.inducing_variable, self.kernel, self.Z_old)\n        Kaa_cur = gpflow.utilities.add_noise_cov(self.kernel(self.Z_old),\n                                                 jitter)\n        Kaa = gpflow.utilities.add_noise_cov(self.Kaa_old, jitter)\n\n        err = self.Y - self.mean_function(self.X)\n\n        Sainv_ma = tf.linalg.solve(Saa, ma)\n        Sinv_y = self.Y / sigma2\n        c1 = tf.matmul(Kbf, Sinv_y)\n        c2 = tf.matmul(Kba, Sainv_ma)\n        c = c1 + c2\n\n        Lb = tf.linalg.cholesky(Kbb)\n        Lbinv_c = tf.linalg.triangular_solve(Lb, c, lower=True)\n        Lbinv_Kba = tf.linalg.triangular_solve(Lb, Kba, lower=True)\n        Lbinv_Kbf = tf.linalg.triangular_solve(Lb, Kbf, lower=True) / sigma\n        d1 = tf.matmul(Lbinv_Kbf, Lbinv_Kbf, transpose_b=True)\n\n        LSa = tf.linalg.cholesky(Saa)\n        Kab_Lbinv = tf.linalg.matrix_transpose(Lbinv_Kba)\n        LSainv_Kab_Lbinv = tf.linalg.triangular_solve(LSa,\n                                                      Kab_Lbinv,\n                                                      lower=True)\n        d2 = tf.matmul(LSainv_Kab_Lbinv, LSainv_Kab_Lbinv, transpose_a=True)\n\n        La = tf.linalg.cholesky(Kaa)\n        Lainv_Kab_Lbinv = tf.linalg.triangular_solve(La, Kab_Lbinv, lower=True)\n        d3 = tf.matmul(Lainv_Kab_Lbinv, Lainv_Kab_Lbinv, transpose_a=True)\n\n        D = tf.eye(Mb, dtype=gpflow.default_float()) + d1 + d2 - d3\n        D = gpflow.utilities.add_noise_cov(D, jitter)\n        LD = tf.linalg.cholesky(D)\n\n        LDinv_Lbinv_c = tf.linalg.triangular_solve(LD, Lbinv_c, lower=True)\n\n        return (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba,\n                LDinv_Lbinv_c, err, d1)\n\n    def maximum_log_likelihood_objective(self):\n        \"\"\"\n        Construct a tensorflow function to compute the bound on the marginal\n        likelihood. \n        \"\"\"\n\n        Mb = self.inducing_variable.num_inducing\n        Ma = self.M_old\n        jitter = gpflow.default_jitter()\n        # jitter = gpflow.utilities.to_default_float(1e-4)\n        sigma2 = self.likelihood.variance\n        sigma = tf.sqrt(sigma2)\n        N = self.num_data\n\n        Saa = self.Su_old\n        ma = self.mu_old\n\n        # a is old inducing points, b is new\n        # f is training points\n        Kfdiag = self.kernel(self.X, full_cov=False)\n        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba, LDinv_Lbinv_c,\n         err, Qff) = self._common_terms()\n\n        LSa = tf.linalg.cholesky(Saa)\n        Lainv_ma = tf.linalg.triangular_solve(LSa, ma, lower=True)\n\n        # constant term\n        bound = -0.5 * N * np.log(2 * np.pi)\n        # quadratic term\n        bound += -0.5 * tf.reduce_sum(tf.square(err)) / sigma2\n        # bound += -0.5 * tf.reduce_sum(ma * Sainv_ma)\n        bound += -0.5 * tf.reduce_sum(tf.square(Lainv_ma))\n        bound += 0.5 * tf.reduce_sum(tf.square(LDinv_Lbinv_c))\n        # log det term\n        bound += -0.5 * N * tf.reduce_sum(tf.math.log(sigma2))\n        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LD)))\n\n        # delta 1: trace term\n        bound += -0.5 * tf.reduce_sum(Kfdiag) / sigma2\n        bound += 0.5 * tf.reduce_sum(tf.linalg.diag_part(Qff))\n\n        # delta 2: a and b difference\n        bound += tf.reduce_sum(tf.math.log(tf.linalg.diag_part(La)))\n        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LSa)))\n\n        Kaadiff = Kaa_cur - tf.matmul(Lbinv_Kba, Lbinv_Kba, transpose_a=True)\n        Sainv_Kaadiff = tf.linalg.solve(Saa, Kaadiff)\n        Kainv_Kaadiff = tf.linalg.solve(Kaa, Kaadiff)\n\n        bound += -0.5 * tf.reduce_sum(\n            tf.linalg.diag_part(Sainv_Kaadiff) -\n            tf.linalg.diag_part(Kainv_Kaadiff))\n\n        return bound\n\n    def predict_f(self, Xnew, full_cov=False):\n        \"\"\"\n        Compute the mean and variance of the latent function at some new points\n        Xnew. \n        \"\"\"\n\n        # jitter = gpflow.default_jitter()\n        jitter = gpflow.utilities.to_default_float(1e-4)\n\n        # a is old inducing points, b is new\n        # f is training points\n        # s is test points\n        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)\n        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba, LDinv_Lbinv_c,\n         err, Qff) = self._common_terms()\n\n        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n        mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)\n\n        if full_cov:\n            Kss = self.kernel(Xnew) + jitter * tf.eye(\n                tf.shape(Xnew)[0], dtype=gpflow.default_float())\n            var1 = Kss\n            var2 = -tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n            var3 = tf.matmul(LDinv_Lbinv_Kbs,\n                             LDinv_Lbinv_Kbs,\n                             transpose_a=True)\n            var = var1 + var2 + var3\n        else:\n            var1 = self.kernel(Xnew, full_cov=False)\n            var2 = -tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n            var3 = tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n            var = var1 + var2 + var3\n\n        return mean + self.mean_function(Xnew), var\n</code></pre>"},{"location":"api/core/osgpr.html#sgptools.core.osgpr.OSGPR_VFE.init_Z","title":"<code>init_Z()</code>","text":"<p>Initializes the new set of inducing points (Z) for the OSGPR model. It combines a subset of the old inducing points (Z_old) with a subset of the current training data (X).</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (M, d); A NumPy array of the newly initialized inducing points,         combining old and new data-based points.</p> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>def init_Z(self) -&gt; np.ndarray:\n    \"\"\"\n    Initializes the new set of inducing points (Z) for the OSGPR model.\n    It combines a subset of the old inducing points (Z_old) with a subset\n    of the current training data (X).\n\n    Returns:\n        np.ndarray: (M, d); A NumPy array of the newly initialized inducing points,\n                    combining old and new data-based points.\n    \"\"\"\n    M = self.inducing_variable.Z.shape[0]\n    M_old = int(0.7 * M)  # Proportion of old inducing points to retain\n    M_new = M - M_old  # Proportion of new data points to select\n\n    # Randomly select M_old points from the old inducing points\n    old_Z = self.Z_old.numpy()[np.random.permutation(M)[0:M_old], :]\n\n    # Randomly select M_new points from the current training data\n    new_Z = self.X.numpy()[\n        np.random.permutation(self.X.shape[0])[0:M_new], :]\n\n    # Vertically stack the selected old and new points to form the new Z\n    Z = np.vstack((old_Z, new_Z))\n    return Z\n</code></pre>"},{"location":"api/core/osgpr.html#sgptools.core.osgpr.OSGPR_VFE.maximum_log_likelihood_objective","title":"<code>maximum_log_likelihood_objective()</code>","text":"<p>Construct a tensorflow function to compute the bound on the marginal likelihood.</p> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>def maximum_log_likelihood_objective(self):\n    \"\"\"\n    Construct a tensorflow function to compute the bound on the marginal\n    likelihood. \n    \"\"\"\n\n    Mb = self.inducing_variable.num_inducing\n    Ma = self.M_old\n    jitter = gpflow.default_jitter()\n    # jitter = gpflow.utilities.to_default_float(1e-4)\n    sigma2 = self.likelihood.variance\n    sigma = tf.sqrt(sigma2)\n    N = self.num_data\n\n    Saa = self.Su_old\n    ma = self.mu_old\n\n    # a is old inducing points, b is new\n    # f is training points\n    Kfdiag = self.kernel(self.X, full_cov=False)\n    (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba, LDinv_Lbinv_c,\n     err, Qff) = self._common_terms()\n\n    LSa = tf.linalg.cholesky(Saa)\n    Lainv_ma = tf.linalg.triangular_solve(LSa, ma, lower=True)\n\n    # constant term\n    bound = -0.5 * N * np.log(2 * np.pi)\n    # quadratic term\n    bound += -0.5 * tf.reduce_sum(tf.square(err)) / sigma2\n    # bound += -0.5 * tf.reduce_sum(ma * Sainv_ma)\n    bound += -0.5 * tf.reduce_sum(tf.square(Lainv_ma))\n    bound += 0.5 * tf.reduce_sum(tf.square(LDinv_Lbinv_c))\n    # log det term\n    bound += -0.5 * N * tf.reduce_sum(tf.math.log(sigma2))\n    bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LD)))\n\n    # delta 1: trace term\n    bound += -0.5 * tf.reduce_sum(Kfdiag) / sigma2\n    bound += 0.5 * tf.reduce_sum(tf.linalg.diag_part(Qff))\n\n    # delta 2: a and b difference\n    bound += tf.reduce_sum(tf.math.log(tf.linalg.diag_part(La)))\n    bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LSa)))\n\n    Kaadiff = Kaa_cur - tf.matmul(Lbinv_Kba, Lbinv_Kba, transpose_a=True)\n    Sainv_Kaadiff = tf.linalg.solve(Saa, Kaadiff)\n    Kainv_Kaadiff = tf.linalg.solve(Kaa, Kaadiff)\n\n    bound += -0.5 * tf.reduce_sum(\n        tf.linalg.diag_part(Sainv_Kaadiff) -\n        tf.linalg.diag_part(Kainv_Kaadiff))\n\n    return bound\n</code></pre>"},{"location":"api/core/osgpr.html#sgptools.core.osgpr.OSGPR_VFE.predict_f","title":"<code>predict_f(Xnew, full_cov=False)</code>","text":"<p>Compute the mean and variance of the latent function at some new points Xnew.</p> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>def predict_f(self, Xnew, full_cov=False):\n    \"\"\"\n    Compute the mean and variance of the latent function at some new points\n    Xnew. \n    \"\"\"\n\n    # jitter = gpflow.default_jitter()\n    jitter = gpflow.utilities.to_default_float(1e-4)\n\n    # a is old inducing points, b is new\n    # f is training points\n    # s is test points\n    Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)\n    (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba, LDinv_Lbinv_c,\n     err, Qff) = self._common_terms()\n\n    Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n    LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n    mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)\n\n    if full_cov:\n        Kss = self.kernel(Xnew) + jitter * tf.eye(\n            tf.shape(Xnew)[0], dtype=gpflow.default_float())\n        var1 = Kss\n        var2 = -tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n        var3 = tf.matmul(LDinv_Lbinv_Kbs,\n                         LDinv_Lbinv_Kbs,\n                         transpose_a=True)\n        var = var1 + var2 + var3\n    else:\n        var1 = self.kernel(Xnew, full_cov=False)\n        var2 = -tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n        var3 = tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n        var = var1 + var2 + var3\n\n    return mean + self.mean_function(Xnew), var\n</code></pre>"},{"location":"api/core/osgpr.html#sgptools.core.osgpr.OSGPR_VFE.update","title":"<code>update(data, inducing_variable=None, update_inducing=True)</code>","text":"<p>Configures the OSGPR model to adapt to a new batch of data. This method updates the model's data, its inducing points (optionally), and caches the posterior mean and covariance of the old inducing points to facilitate the streaming update equations.</p> <p>Note: After calling this update, the OSGPR model typically needs to be trained further using gradient-based optimization to fully incorporate the new data and optimize its parameters.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple (X, y) representing the new batch                                   of input data <code>X</code> (n, d) and corresponding labels <code>y</code> (n, 1).</p> required <code>inducing_variable</code> <code>Optional[ndarray]</code> <p>(m_new, d); Optional NumPy array for the new                                      set of inducing points. If None and <code>update_inducing</code>                                      is True, <code>init_Z</code> will be called to determine them.                                      Defaults to None.</p> <code>None</code> <code>update_inducing</code> <code>bool</code> <p>If True, the inducing points will be updated. If False,                     they will remain as they were before the update call.                     Defaults to True.</p> <code>True</code> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>def update(self, data, inducing_variable=None, update_inducing=True):\n    \"\"\"\n    Configures the OSGPR model to adapt to a new batch of data.\n    This method updates the model's data, its inducing points (optionally),\n    and caches the posterior mean and covariance of the *old* inducing points\n    to facilitate the streaming update equations.\n\n    Note: After calling this update, the OSGPR model typically needs to be\n    trained further using gradient-based optimization to fully incorporate\n    the new data and optimize its parameters.\n\n    Args:\n        data (Tuple[np.ndarray, np.ndarray]): A tuple (X, y) representing the new batch\n                                              of input data `X` (n, d) and corresponding labels `y` (n, 1).\n        inducing_variable (Optional[np.ndarray]): (m_new, d); Optional NumPy array for the new\n                                                 set of inducing points. If None and `update_inducing`\n                                                 is True, `init_Z` will be called to determine them.\n                                                 Defaults to None.\n        update_inducing (bool): If True, the inducing points will be updated. If False,\n                                they will remain as they were before the update call.\n                                Defaults to True.\n    \"\"\"\n    self.X, self.Y = self.data = gpflow.models.util.data_input_to_tensor(\n        data)\n    self.num_data = self.X.shape[0]\n\n    # Store the current inducing points as 'old' for the next update step\n    self.Z_old.assign(self.inducing_variable.Z)\n\n    # Update the inducing points based on `update_inducing` flag\n    if update_inducing:\n        if inducing_variable is None:\n            # If no explicit inducing_variable is provided, initialize new ones\n            new_Z_init = self.init_Z()\n        else:\n            # Use the explicitly provided inducing_variable\n            new_Z_init = inducing_variable\n        self.inducing_variable.Z.assign(\n            tf.constant(new_Z_init, dtype=self.inducing_variable.Z.dtype))\n    # If update_inducing is False, inducing_variable.Z retains its current value.\n\n    # Get posterior mean and covariance for the *old* inducing points using the current model state\n    mu_old, Su_old = self.predict_f(self.Z_old, full_cov=True)\n    self.mu_old.assign(mu_old)\n    self.Su_old.assign(Su_old)\n\n    # Get the prior covariance matrix for the *old* inducing points using the current kernel\n    Kaa_old = self.kernel(self.Z_old)\n    self.Kaa_old.assign(Kaa_old)\n</code></pre>"},{"location":"api/core/osgpr.html#sgptools.core.osgpr.init_osgpr","title":"<code>sgptools.core.osgpr.init_osgpr(X_train, num_inducing=10, lengthscales=1.0, variance=1.0, noise_variance=0.001, kernel=None, ndim=1)</code>","text":"<p>Initializes an Online Sparse Variational Gaussian Process Regression (OSGPR_VFE) model. This function first fits a standard Sparse Gaussian Process Regression (SGPR) model to a dummy dataset (representing initial data/environment bounds) to obtain an initial set of optimized inducing points and their corresponding posterior. These are then used to set up the <code>OSGPR_VFE</code> model for streaming updates.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>ndarray</code> <p>(n, d); Unlabeled random sampled training points.                   These points are primarily used to define the spatial bounds                   and for initial selection of inducing points. Their labels are                   set to zeros for the SGPR initialization.</p> required <code>num_inducing</code> <code>int</code> <p>The number of inducing points to use for the OSGPR model. Defaults to 10.</p> <code>10</code> <code>lengthscales</code> <code>Union[float, ndarray]</code> <p>Initial lengthscale(s) for the RBF kernel.                                      If a float, it's applied uniformly. If a NumPy array,                                      each element corresponds to a dimension. Defaults to 1.0.</p> <code>1.0</code> <code>variance</code> <code>float</code> <p>Initial variance (amplitude) for the RBF kernel. Defaults to 1.0.</p> <code>1.0</code> <code>noise_variance</code> <code>float</code> <p>Initial data noise variance for the Gaussian likelihood. Defaults to 0.001.</p> <code>0.001</code> <code>kernel</code> <code>Optional[Kernel]</code> <p>A pre-defined GPflow kernel function. If None,                          a <code>gpflow.kernels.SquaredExponential</code> (RBF) kernel is created                          with the provided <code>lengthscales</code> and <code>variance</code>. Defaults to None.</p> <code>None</code> <code>ndim</code> <code>int</code> <p>Number of output dimensions for the dummy training labels <code>y_train</code>. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>OSGPR_VFE</code> <code>OSGPR_VFE</code> <p>An initialized <code>OSGPR_VFE</code> model instance, ready to accept        new data batches via its <code>update</code> method.</p> Usage <pre><code>import numpy as np\n# from sgptools.core.osgpr import init_osgpr\n\n# Define some dummy training data to establish initial bounds\nX_initial_env = np.random.rand(100, 2) * 10\n\n# Initialize the OSGPR model\nonline_gp_model = init_osgpr(\n    X_initial_env,\n    num_inducing=50,\n    lengthscales=2.0,\n    variance=1.5,\n    noise_variance=0.01\n)\n\n# Example of updating the model with new data (typically in a loop)\n# new_X_batch = np.random.rand(10, 2) * 10\n# new_y_batch = np.sin(new_X_batch[:, 0:1]) + np.random.randn(10, 1) * 0.1\n# online_gp_model.update(data=(new_X_batch, new_y_batch))\n</code></pre> Source code in <code>sgptools/core/osgpr.py</code> <pre><code>def init_osgpr(X_train: np.ndarray,\n               num_inducing: int = 10,\n               lengthscales: Union[float, np.ndarray] = 1.0,\n               variance: float = 1.0,\n               noise_variance: float = 0.001,\n               kernel: Optional[gpflow.kernels.Kernel] = None,\n               ndim: int = 1) -&gt; OSGPR_VFE:\n    \"\"\"\n    Initializes an Online Sparse Variational Gaussian Process Regression (OSGPR_VFE) model.\n    This function first fits a standard Sparse Gaussian Process Regression (SGPR) model\n    to a dummy dataset (representing initial data/environment bounds) to obtain an\n    initial set of optimized inducing points and their corresponding posterior.\n    These are then used to set up the `OSGPR_VFE` model for streaming updates.\n\n    Args:\n        X_train (np.ndarray): (n, d); Unlabeled random sampled training points.\n                              These points are primarily used to define the spatial bounds\n                              and for initial selection of inducing points. Their labels are\n                              set to zeros for the SGPR initialization.\n        num_inducing (int): The number of inducing points to use for the OSGPR model. Defaults to 10.\n        lengthscales (Union[float, np.ndarray]): Initial lengthscale(s) for the RBF kernel.\n                                                 If a float, it's applied uniformly. If a NumPy array,\n                                                 each element corresponds to a dimension. Defaults to 1.0.\n        variance (float): Initial variance (amplitude) for the RBF kernel. Defaults to 1.0.\n        noise_variance (float): Initial data noise variance for the Gaussian likelihood. Defaults to 0.001.\n        kernel (Optional[gpflow.kernels.Kernel]): A pre-defined GPflow kernel function. If None,\n                                     a `gpflow.kernels.SquaredExponential` (RBF) kernel is created\n                                     with the provided `lengthscales` and `variance`. Defaults to None.\n        ndim (int): Number of output dimensions for the dummy training labels `y_train`. Defaults to 1.\n\n    Returns:\n        OSGPR_VFE: An initialized `OSGPR_VFE` model instance, ready to accept\n                   new data batches via its `update` method.\n\n    Usage:\n        ```python\n        import numpy as np\n        # from sgptools.core.osgpr import init_osgpr\n\n        # Define some dummy training data to establish initial bounds\n        X_initial_env = np.random.rand(100, 2) * 10\n\n        # Initialize the OSGPR model\n        online_gp_model = init_osgpr(\n            X_initial_env,\n            num_inducing=50,\n            lengthscales=2.0,\n            variance=1.5,\n            noise_variance=0.01\n        )\n\n        # Example of updating the model with new data (typically in a loop)\n        # new_X_batch = np.random.rand(10, 2) * 10\n        # new_y_batch = np.sin(new_X_batch[:, 0:1]) + np.random.randn(10, 1) * 0.1\n        # online_gp_model.update(data=(new_X_batch, new_y_batch))\n        ```\n    \"\"\"\n    if kernel is None:\n        # If no kernel is provided, initialize a SquaredExponential (RBF) kernel.\n        kernel = gpflow.kernels.SquaredExponential(lengthscales=lengthscales,\n                                                   variance=variance)\n\n    # Create a dummy y_train: SGPR needs labels, but for initialization purposes here,\n    # we use zeros as the actual labels will come in through online updates.\n    y_train_dummy = np.zeros((len(X_train), ndim), dtype=X_train.dtype)\n\n    # Select initial inducing points from X_train using get_inducing_pts utility\n    Z_init = get_inducing_pts(X_train, num_inducing)\n\n    # Initialize a standard SGPR model. This model helps in getting an initial\n    # posterior (mu, Su) for the inducing points (Z_init) under the given kernel\n    # and noise variance. This posterior then becomes the 'old' posterior for OSGPR_VFE.\n    init_sgpr_model = gpflow.models.SGPR(data=(X_train, y_train_dummy),\n                                         kernel=kernel,\n                                         inducing_variable=Z_init,\n                                         noise_variance=noise_variance)\n\n    # Extract optimized (or initial) inducing points from the SGPR model\n    Zopt_np = init_sgpr_model.inducing_variable.Z.numpy()\n\n    # Predict the mean (mu) and full covariance (Su) of the latent function\n    # at these initial inducing points (Zopt). This represents the 'old' posterior.\n    mu_old_tf, Su_old_tf_full_cov = init_sgpr_model.predict_f(tf.constant(\n        Zopt_np, dtype=X_train.dtype),\n                                                              full_cov=True)\n\n    # Kaa_old: Prior covariance matrix of the old inducing points\n    Kaa_old_tf = init_sgpr_model.kernel(\n        tf.constant(Zopt_np, dtype=X_train.dtype))\n\n    # Prepare dummy initial data for OSGPR_VFE. This data will be overwritten\n    # by the first actual `update` call.\n    dummy_X_online = np.zeros([2, X_train.shape[-1]], dtype=X_train.dtype)\n    dummy_y_online = np.zeros([2, ndim], dtype=X_train.dtype)\n\n    # Initialize the OSGPR_VFE model with the extracted parameters.\n    # The `Su_old_tf_full_cov` is expected to be a (1, M, M) tensor for single latent GP,\n    # so we extract the (M, M) covariance matrix `Su_old_tf_full_cov[0]`.\n    online_osgpr_model = OSGPR_VFE(\n        data=(tf.constant(dummy_X_online), tf.constant(dummy_y_online)),\n        kernel=init_sgpr_model.\n        kernel,  # Pass the kernel (potentially optimized by SGPR init)\n        mu_old=mu_old_tf,\n        Su_old=Su_old_tf_full_cov[0],\n        Kaa_old=Kaa_old_tf,\n        Z_old=tf.constant(Zopt_np, dtype=X_train.dtype),\n        Z=tf.constant(Zopt_np,\n                      dtype=X_train.dtype))  # New Z is same as old Z initially\n\n    # Assign the noise variance from the initial SGPR model to the OSGPR model's likelihood\n    online_osgpr_model.likelihood.variance.assign(\n        init_sgpr_model.likelihood.variance)\n\n    return online_osgpr_model\n</code></pre>"},{"location":"api/core/transformations.html","title":"Transformations","text":""},{"location":"api/core/transformations.html#sgptools.core.transformations.Transform","title":"<code>sgptools.core.transformations.Transform</code>","text":"<p>Base class for transformations applied to inducing points in sparse Gaussian process models. This class defines common interfaces for expanding inducing points (e.g., to model sensor fields of view or continuous paths) and aggregating kernel matrices. It also provides a base for adding constraint terms to the optimization objective.</p> Refer to the following papers for more details <ul> <li>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]</li> <li>Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]</li> </ul> Source code in <code>sgptools/core/transformations.py</code> <pre><code>class Transform:\n    \"\"\"\n    Base class for transformations applied to inducing points in sparse Gaussian process models.\n    This class defines common interfaces for expanding inducing points (e.g., to model\n    sensor fields of view or continuous paths) and aggregating kernel matrices.\n    It also provides a base for adding constraint terms to the optimization objective.\n\n    Refer to the following papers for more details:\n        - Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]\n        - Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]\n    \"\"\"\n\n    def __init__(self,\n                 aggregation_size: Optional[int] = None,\n                 constraint_weight: float = 1.0,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the base Transform class.\n\n        Args:\n            aggregation_size (Optional[int]): Number of consecutive inducing points to aggregate\n                                              when transforming kernel matrices. If None, no aggregation\n                                              is performed. Defaults to None.\n            constraint_weight (float): A scalar weight that controls the importance of the\n                                       constraint terms in the SGP's optimization objective function.\n                                       A higher weight means stronger enforcement of constraints.\n                                       Defaults to 1.0.\n            **kwargs (Any): Additional keyword arguments to be passed to the constructor.\n        \"\"\"\n        self.aggregation_size = aggregation_size\n        self.constraint_weight = constraint_weight\n\n    def expand(\n            self, Xu: Union[np.ndarray,\n                            tf.Tensor]) -&gt; Union[np.ndarray, tf.Tensor]:\n        \"\"\"\n        Applies an expansion transform to the inducing points.\n        In this base class, it simply returns the input inducing points unchanged.\n        Subclasses should override this method to implement specific expansion logic.\n\n        Args:\n            Xu (Union[np.ndarray, tf.Tensor]): The input inducing points.\n                                                Shape: (m, d) where `m` is the number of inducing points\n                                                and `d` is their dimensionality.\n\n        Returns:\n            Union[np.ndarray, tf.Tensor]: The expanded inducing points.\n        \"\"\"\n        return Xu\n\n    def aggregate(self, k: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Applies an aggregation transform to kernel matrices. This is typically used\n        to reduce the size of kernel matrices after expansion, by averaging or summing\n        over groups of expanded points. This can reduce computational cost for\n        matrix inversions (e.g., in `Kuu`).\n\n        Args:\n            k (tf.Tensor): The input kernel matrix.\n                           Can be (mp, mp) for `Kuu` (square matrix for inducing points\n                           against themselves), or (mp, n) for `Kuf` (rectangular matrix\n                           for inducing points against training data).\n                           `m` is the number of original inducing points.\n                           `p` is the number of points each inducing point is mapped to\n                           by the expansion transform.\n                           `n` is the number of training data points.\n\n        Returns:\n            tf.Tensor: The aggregated kernel matrix.\n                       Shape: (m, m) if input was (mp, mp), or (m, n) if input was (mp, n).\n        \"\"\"\n        if self.aggregation_size is None:\n            return k\n\n        # The aggregation logic assumes `k` has leading dimensions that are\n        # multiples of `self.aggregation_size`.\n        if k.shape[0] == k.shape[\n                1]:  # This is K(U, U) or K(U_expanded, U_expanded)\n            # Reshape for `tf.nn.avg_pool`: [batch, height, width, channels]\n            # Here, we treat the matrix as a 1-channel image.\n            k_reshaped = tf.expand_dims(tf.expand_dims(k, axis=0),\n                                        axis=-1)  # (1, mp, mp, 1)\n\n            # Apply average pooling. `ksize` and `strides` define the window size\n            # and movement for aggregation. This effectively averages blocks.\n            k_aggregated = tf.nn.avg_pool(\n                k_reshaped,\n                ksize=[1, self.aggregation_size, self.aggregation_size, 1],\n                strides=[1, self.aggregation_size, self.aggregation_size, 1],\n                padding='VALID')\n            # Squeeze back to (m, m)\n            k = tf.squeeze(k_aggregated, axis=[0, -1])\n        else:  # This is K(U, F) or K(U_expanded, F)\n            # Reshape for `tf.nn.avg_pool`: (1, mp, n) -&gt; (1, mp, n, 1) if channels are 1\n            # Or (1, mp, n) directly for 1D pooling if `n` is treated as a feature dimension.\n            # Here, we're pooling along the inducing point dimension.\n            k_reshaped = tf.expand_dims(k, axis=0)  # (1, mp, n)\n            k_aggregated = tf.nn.avg_pool(\n                k_reshaped,\n                ksize=[1, self.aggregation_size, 1],  # Pool along height (mp)\n                strides=[1, self.aggregation_size, 1],\n                padding='VALID')\n            # Squeeze back to (m, n)\n            k = tf.squeeze(k_aggregated, axis=[0])\n        return k\n\n    def constraints(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes constraint terms that are added to the SGP's optimization function (ELBO).\n        This base implementation returns a zero tensor, implying no constraints by default.\n        Subclasses should override this to implement specific constraints (e.g., path length budget).\n\n        Args:\n            Xu (tf.Tensor): The inducing points, from which to compute the constraints.\n                            Shape: (m, d).\n\n        Returns:\n            tf.Tensor: A scalar tensor representing the constraint penalty. Defaults to 0.0.\n        \"\"\"\n        return tf.constant(0.0, dtype=default_float())\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.Transform.__init__","title":"<code>__init__(aggregation_size=None, constraint_weight=1.0, **kwargs)</code>","text":"<p>Initializes the base Transform class.</p> <p>Parameters:</p> Name Type Description Default <code>aggregation_size</code> <code>Optional[int]</code> <p>Number of consecutive inducing points to aggregate                               when transforming kernel matrices. If None, no aggregation                               is performed. Defaults to None.</p> <code>None</code> <code>constraint_weight</code> <code>float</code> <p>A scalar weight that controls the importance of the                        constraint terms in the SGP's optimization objective function.                        A higher weight means stronger enforcement of constraints.                        Defaults to 1.0.</p> <code>1.0</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the constructor.</p> <code>{}</code> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def __init__(self,\n             aggregation_size: Optional[int] = None,\n             constraint_weight: float = 1.0,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the base Transform class.\n\n    Args:\n        aggregation_size (Optional[int]): Number of consecutive inducing points to aggregate\n                                          when transforming kernel matrices. If None, no aggregation\n                                          is performed. Defaults to None.\n        constraint_weight (float): A scalar weight that controls the importance of the\n                                   constraint terms in the SGP's optimization objective function.\n                                   A higher weight means stronger enforcement of constraints.\n                                   Defaults to 1.0.\n        **kwargs (Any): Additional keyword arguments to be passed to the constructor.\n    \"\"\"\n    self.aggregation_size = aggregation_size\n    self.constraint_weight = constraint_weight\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.Transform.aggregate","title":"<code>aggregate(k)</code>","text":"<p>Applies an aggregation transform to kernel matrices. This is typically used to reduce the size of kernel matrices after expansion, by averaging or summing over groups of expanded points. This can reduce computational cost for matrix inversions (e.g., in <code>Kuu</code>).</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>Tensor</code> <p>The input kernel matrix.            Can be (mp, mp) for <code>Kuu</code> (square matrix for inducing points            against themselves), or (mp, n) for <code>Kuf</code> (rectangular matrix            for inducing points against training data).            <code>m</code> is the number of original inducing points.            <code>p</code> is the number of points each inducing point is mapped to            by the expansion transform.            <code>n</code> is the number of training data points.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The aggregated kernel matrix.        Shape: (m, m) if input was (mp, mp), or (m, n) if input was (mp, n).</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def aggregate(self, k: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Applies an aggregation transform to kernel matrices. This is typically used\n    to reduce the size of kernel matrices after expansion, by averaging or summing\n    over groups of expanded points. This can reduce computational cost for\n    matrix inversions (e.g., in `Kuu`).\n\n    Args:\n        k (tf.Tensor): The input kernel matrix.\n                       Can be (mp, mp) for `Kuu` (square matrix for inducing points\n                       against themselves), or (mp, n) for `Kuf` (rectangular matrix\n                       for inducing points against training data).\n                       `m` is the number of original inducing points.\n                       `p` is the number of points each inducing point is mapped to\n                       by the expansion transform.\n                       `n` is the number of training data points.\n\n    Returns:\n        tf.Tensor: The aggregated kernel matrix.\n                   Shape: (m, m) if input was (mp, mp), or (m, n) if input was (mp, n).\n    \"\"\"\n    if self.aggregation_size is None:\n        return k\n\n    # The aggregation logic assumes `k` has leading dimensions that are\n    # multiples of `self.aggregation_size`.\n    if k.shape[0] == k.shape[\n            1]:  # This is K(U, U) or K(U_expanded, U_expanded)\n        # Reshape for `tf.nn.avg_pool`: [batch, height, width, channels]\n        # Here, we treat the matrix as a 1-channel image.\n        k_reshaped = tf.expand_dims(tf.expand_dims(k, axis=0),\n                                    axis=-1)  # (1, mp, mp, 1)\n\n        # Apply average pooling. `ksize` and `strides` define the window size\n        # and movement for aggregation. This effectively averages blocks.\n        k_aggregated = tf.nn.avg_pool(\n            k_reshaped,\n            ksize=[1, self.aggregation_size, self.aggregation_size, 1],\n            strides=[1, self.aggregation_size, self.aggregation_size, 1],\n            padding='VALID')\n        # Squeeze back to (m, m)\n        k = tf.squeeze(k_aggregated, axis=[0, -1])\n    else:  # This is K(U, F) or K(U_expanded, F)\n        # Reshape for `tf.nn.avg_pool`: (1, mp, n) -&gt; (1, mp, n, 1) if channels are 1\n        # Or (1, mp, n) directly for 1D pooling if `n` is treated as a feature dimension.\n        # Here, we're pooling along the inducing point dimension.\n        k_reshaped = tf.expand_dims(k, axis=0)  # (1, mp, n)\n        k_aggregated = tf.nn.avg_pool(\n            k_reshaped,\n            ksize=[1, self.aggregation_size, 1],  # Pool along height (mp)\n            strides=[1, self.aggregation_size, 1],\n            padding='VALID')\n        # Squeeze back to (m, n)\n        k = tf.squeeze(k_aggregated, axis=[0])\n    return k\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.Transform.constraints","title":"<code>constraints(Xu)</code>","text":"<p>Computes constraint terms that are added to the SGP's optimization function (ELBO). This base implementation returns a zero tensor, implying no constraints by default. Subclasses should override this to implement specific constraints (e.g., path length budget).</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>The inducing points, from which to compute the constraints.             Shape: (m, d).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: A scalar tensor representing the constraint penalty. Defaults to 0.0.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def constraints(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes constraint terms that are added to the SGP's optimization function (ELBO).\n    This base implementation returns a zero tensor, implying no constraints by default.\n    Subclasses should override this to implement specific constraints (e.g., path length budget).\n\n    Args:\n        Xu (tf.Tensor): The inducing points, from which to compute the constraints.\n                        Shape: (m, d).\n\n    Returns:\n        tf.Tensor: A scalar tensor representing the constraint penalty. Defaults to 0.0.\n    \"\"\"\n    return tf.constant(0.0, dtype=default_float())\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.Transform.expand","title":"<code>expand(Xu)</code>","text":"<p>Applies an expansion transform to the inducing points. In this base class, it simply returns the input inducing points unchanged. Subclasses should override this method to implement specific expansion logic.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Union[ndarray, Tensor]</code> <p>The input inducing points.                                 Shape: (m, d) where <code>m</code> is the number of inducing points                                 and <code>d</code> is their dimensionality.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, tf.Tensor]: The expanded inducing points.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def expand(\n        self, Xu: Union[np.ndarray,\n                        tf.Tensor]) -&gt; Union[np.ndarray, tf.Tensor]:\n    \"\"\"\n    Applies an expansion transform to the inducing points.\n    In this base class, it simply returns the input inducing points unchanged.\n    Subclasses should override this method to implement specific expansion logic.\n\n    Args:\n        Xu (Union[np.ndarray, tf.Tensor]): The input inducing points.\n                                            Shape: (m, d) where `m` is the number of inducing points\n                                            and `d` is their dimensionality.\n\n    Returns:\n        Union[np.ndarray, tf.Tensor]: The expanded inducing points.\n    \"\"\"\n    return Xu\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform","title":"<code>sgptools.core.transformations.IPPTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Transform to model Informative Path Planning (IPP) problems for single or multiple robots. It handles continuous sensing, non-point fields of view (FoV), and distance constraints.</p> <ul> <li>For point sensing (discrete waypoints), set <code>sampling_rate = 2</code>.</li> <li>For continuous sensing along paths, set <code>sampling_rate &gt; 2</code> to interpolate     additional points between waypoints for information gathering.</li> <li>For continuous sensing with aggregation for computational efficiency,     set <code>sampling_rate &gt; 2</code> and <code>aggregate_fov = True</code>. This averages     covariances from interpolated points, potentially diminishing solution quality slightly.</li> <li>If using a non-point FoV model (e.g., <code>SquareTransform</code>) with continuous sampling,     only the FoV inducing points are aggregated.</li> <li>For multi-robot scenarios, set <code>num_robots &gt; 1</code>.</li> <li>For online IPP where some visited waypoints are fixed, use <code>update_Xu_fixed</code>     to freeze these waypoints from further optimization.</li> </ul> Source code in <code>sgptools/core/transformations.py</code> <pre><code>class IPPTransform(Transform):\n    \"\"\"\n    Transform to model Informative Path Planning (IPP) problems for single or multiple robots.\n    It handles continuous sensing, non-point fields of view (FoV), and distance constraints.\n\n    * For point sensing (discrete waypoints), set `sampling_rate = 2`.\n    * For continuous sensing along paths, set `sampling_rate &gt; 2` to interpolate\n        additional points between waypoints for information gathering.\n    * For continuous sensing with aggregation for computational efficiency,\n        set `sampling_rate &gt; 2` and `aggregate_fov = True`. This averages\n        covariances from interpolated points, potentially diminishing solution quality slightly.\n    * If using a non-point FoV model (e.g., `SquareTransform`) with continuous sampling,\n        only the FoV inducing points are aggregated.\n    * For multi-robot scenarios, set `num_robots &gt; 1`.\n    * For online IPP where some visited waypoints are fixed, use `update_Xu_fixed`\n        to freeze these waypoints from further optimization.\n    \"\"\"\n\n    def __init__(self,\n                 sampling_rate: int = 2,\n                 distance_budget: Optional[float] = None,\n                 num_robots: int = 1,\n                 Xu_fixed: Optional[np.ndarray] = None,\n                 num_dim: int = 2,\n                 sensor_model: Optional[Transform] = None,\n                 aggregate_fov: bool = False,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the IPPTransform.\n\n        Args:\n            sampling_rate (int): Number of points to sample along each segment between two\n                                 consecutive inducing points. `sampling_rate=2` implies\n                                 only the two endpoints are used (point sensing).\n                                 `sampling_rate &gt; 2` implies continuous sensing via interpolation.\n                                 Must be $\\ge 2$. Defaults to 2.\n            distance_budget (Optional[float]): The maximum allowable total path length for each robot.\n                                               If None, no distance constraint is applied. Defaults to None.\n            num_robots (int): The number of robots or agents involved in the IPP problem. Defaults to 1.\n            Xu_fixed (Optional[np.ndarray]): (num_robots, num_visited, num_dim);\n                                            An array of pre-defined, fixed waypoints that should\n                                            not be optimized (e.g., already visited locations in online IPP).\n                                            If None, all waypoints are optimizable. Defaults to None.\n            num_dim (int): The dimensionality of the inducing points (e.g., 2 for (x,y), 3 for (x,y,angle)).\n                           Defaults to 2.\n            sensor_model (Optional[Transform]): A `Transform` object that defines a non-point\n                                                Field of View (FoV) for the sensor (e.g., `SquareTransform`).\n                                                If None, a point sensor model is assumed. Defaults to None.\n            aggregate_fov (bool): If True, and `sampling_rate &gt; 2` (continuous sensing is enabled),\n                                  or if `sensor_model` is provided, aggregation will be enabled.\n                                  This reduces computation by averaging expanded points' covariances.\n                                  Defaults to False.\n            **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n        Raises:\n            ValueError: If `sampling_rate` is less than 2.\n\n        Usage:\n            ```python\n            # Single robot, point sensing\n            transform_point = IPPTransform(num_robots=1, num_dim=2, sampling_rate=2)\n\n            # Single robot, continuous sensing\n            transform_continuous = IPPTransform(num_robots=1, num_dim=2, sampling_rate=10)\n\n            # Multi-robot, continuous sensing with distance budget\n            transform_multi_budget = IPPTransform(num_robots=2, num_dim=2, sampling_rate=5, distance_budget=50.0, constraint_weight=100.0)\n            ```\n        \"\"\"\n        super().__init__(**kwargs)\n        if sampling_rate &lt; 2:\n            raise ValueError(\n                'Sampling rate must be greater than or equal to 2.')\n\n        self.sampling_rate = sampling_rate\n        self.distance_budget = distance_budget\n        self.num_robots = num_robots\n        self.num_dim = num_dim\n        self.sensor_model = sensor_model\n\n        # Enable aggregation if `aggregate_fov` is True, potentially leveraging the sensor_model's aggregation\n        if aggregate_fov:\n            if self.sensor_model is not None:\n                # If a sensor model exists, let it handle its own aggregation settings.\n                # This assumes `sensor_model` has an `enable_aggregation` method.\n                if hasattr(self.sensor_model, 'enable_aggregation'):\n                    self.sensor_model.enable_aggregation()\n            elif self.sampling_rate &gt; 2:\n                # If no specific sensor model but continuous sensing, aggregate based on sampling rate.\n                self.aggregation_size = self.sampling_rate\n\n        # Initialize TensorFlow Variable for fixed waypoints if provided, for online IPP.\n        if Xu_fixed is not None:\n            # Store number of fixed waypoints per robot\n            self.num_fixed = Xu_fixed.shape[1]  \n            self.Xu_fixed = tf.Variable(\n                Xu_fixed,\n                shape=tf.TensorShape(None),\n                trainable=False,  # Fixed points are not optimized\n                dtype=default_float())\n        else:\n            self.Xu_fixed = None\n\n    def update_Xu_fixed(self, Xu_fixed: np.ndarray) -&gt; None:\n        \"\"\"\n        Updates the set of visited (fixed) waypoints for online IPP scenarios.\n        These waypoints will not be optimized in subsequent steps.\n\n        Args:\n            Xu_fixed (np.ndarray): A NumPy array of shape (num_robots, num_visited_waypoints, num_dim)\n                                   representing the new set of fixed waypoints.\n        \"\"\"\n        # Store number of fixed waypoints per robot\n        self.num_fixed = Xu_fixed.shape[1]  \n        if self.Xu_fixed is not None:\n            self.Xu_fixed.assign(tf.constant(Xu_fixed, dtype=default_float()))\n        else:\n            self.Xu_fixed = tf.Variable(Xu_fixed,\n                                        shape=tf.TensorShape(None),\n                                        trainable=False,\n                                        dtype=default_float())\n\n    def expand(self,\n               Xu: tf.Tensor,\n               expand_sensor_model: bool = True) -&gt; tf.Tensor:\n        \"\"\"\n        Applies the expansion transform to the inducing points based on the IPP settings.\n        This can involve:\n        1. Adding fixed (already visited) waypoints.\n        2. Interpolating points between waypoints for continuous sensing.\n        3. Expanding each point into a sensor's Field of View (FoV) if a `sensor_model` is present.\n\n        Args:\n            Xu (tf.Tensor): The current set of optimizable inducing points.\n                            Shape: (num_robots * num_optimizable_waypoints, num_dim).\n                            Note: `num_dim` might include angle if `sensor_model` requires it.\n            expand_sensor_model (bool): If True, applies the `sensor_model`'s expansion\n                                        (if a `sensor_model` is configured). If False,\n                                        only the path interpolation and fixed point handling\n                                        are performed, useful for internal calculations like distance.\n                                        Defaults to True.\n\n        Returns:\n            tf.Tensor: The expanded inducing points, ready for kernel computations.\n                       Shape: (total_expanded_points, d_output), where `d_output`\n                       is typically 2 for (x,y) coordinates used in the kernel.\n        \"\"\"\n        # If using single-robot offline IPP with point sensing, return inducing points as is.\n        if self.sampling_rate == 2 and self.Xu_fixed is None and self.sensor_model is None:\n            return Xu\n\n        # Reshape Xu to (num_robots, num_waypoints_per_robot, num_dim)\n        Xu = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n        # If using online IPP, add visited waypoints that won't be optimized anymore\n        if self.Xu_fixed is not None:\n            Xu = tf.concat([self.Xu_fixed, Xu[:, self.num_fixed:]], axis=1)\n\n        if not expand_sensor_model:\n            return tf.reshape(Xu, (-1, self.num_dim))\n\n        # Interpolate additional inducing points between waypoints to approximate\n        # the continuous data sensing model\n        if self.sampling_rate &gt; 2:\n            Xu = tf.linspace(Xu[:, :-1], Xu[:, 1:], self.sampling_rate)\n            Xu = tf.transpose(Xu, perm=[1, 2, 0, 3])\n            Xu = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n        # If a sensor model is defined and `expand_sensor_model` is True,\n        # apply the sensor model's expansion for each robot.\n        if self.sensor_model is not None:\n            Xu_ = []\n            for i in range(self.num_robots):\n                Xu_.append(self.sensor_model.expand(Xu[i]))\n            Xu = tf.concat(Xu_, axis=0)\n            return Xu\n\n        Xu = tf.reshape(Xu, (-1, self.num_dim))\n        return Xu\n\n    def aggregate(self, k: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Applies the aggregation transform to kernel matrices.\n        If a `sensor_model` is defined, it delegates aggregation to the sensor model.\n        Otherwise, it uses the base class's aggregation logic (which depends on `self.aggregation_size`).\n\n        Args:\n            k (tf.Tensor): The input kernel matrix (e.g., K_expanded_expanded, K_expanded_training).\n\n        Returns:\n            tf.Tensor: The aggregated kernel matrix.\n        \"\"\"\n        if self.sensor_model is not None:\n            return self.sensor_model.aggregate(k)\n        else:\n            return super().aggregate(k)\n\n    def constraints(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the distance constraint term that is added to the SGP's optimization function.\n        Each robot's path length is constrained by `distance_budget`. A penalty is applied\n        if the path length exceeds the budget.\n\n        Args:\n            Xu (tf.Tensor): The inducing points (waypoints) from which to compute path lengths.\n                            Shape: (num_robots * num_waypoints, num_dim).\n\n        Returns:\n            tf.Tensor: A scalar tensor representing the total distance constraint penalty.\n                       This value is negative, and its magnitude increases with constraint violation.\n        \"\"\"\n        if self.distance_budget is None:\n            return tf.constant(0.0, dtype=default_float())  # No distance constraint\n        else:\n            # Expand Xu without sensor model to get the true path points for distance calculation.\n            # Xu is the optimizable part; self.expand will add fixed points if any.\n            Xu_for_distance = self.expand(Xu, expand_sensor_model=False)\n\n            # Calculate distances for each robot's path\n            individual_robot_distances = self.distance(Xu_for_distance)\n\n            # Compute the positive violation for each robot's path\n            violations = individual_robot_distances - self.distance_budget\n\n            # Apply ReLU to ensure only positive violations contribute to the penalty\n            # Sum all violations and apply the constraint weight\n            penalty = -tf.reduce_sum(\n                tf.nn.relu(violations)) * self.constraint_weight\n            return penalty\n\n    def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the total path length(s) incurred by sequentially visiting the inducing points.\n        For multiple robots, returns a tensor of individual path lengths.\n\n        Args:\n            Xu (tf.Tensor): The inducing points (waypoints) from which to compute the path lengths.\n                            Shape: (total_waypoints, num_dim). This input is typically already\n                            expanded to include fixed points if `Xu_fixed` is used.\n\n        Returns:\n            tf.Tensor: A scalar tensor if `num_robots=1`, or a 1D tensor of floats\n                       (shape: `(num_robots,)`) representing individual path lengths.\n        \"\"\"\n        # Reshape to (num_robots, num_waypoints_per_robot, num_dim)\n        Xu_reshaped = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n        if self.sensor_model is not None:\n            # If a sensor model is present, delegate distance calculation to it,\n            # as it might have specific logic for its FoV's contribution to distance.\n            dists: List[tf.Tensor] = []\n            for i in range(self.num_robots):\n                # Pass each robot's path (which includes position and potentially angle)\n                dists.append(self.sensor_model.distance(Xu_reshaped[i]))\n            return tf.concat(\n                dists, axis=0)  # Concatenate distances if multiple robots\n        else:\n            # For point/continuous sensing without a special FoV model:\n            # Calculate Euclidean distance between consecutive waypoints.\n            # Assuming first two dimensions are (x,y) for distance calculation.\n            # `Xu_reshaped[:, 1:, :2]` are points from the second to last.\n            # `Xu_reshaped[:, :-1, :2]` are points from the first to second to last.\n            segment_distances = tf.norm(Xu_reshaped[:, 1:, :2] -\n                                        Xu_reshaped[:, :-1, :2],\n                                        axis=-1)\n            total_distances = tf.reduce_sum(\n                segment_distances, axis=1)  # Sum distances for each robot\n            return total_distances\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.__init__","title":"<code>__init__(sampling_rate=2, distance_budget=None, num_robots=1, Xu_fixed=None, num_dim=2, sensor_model=None, aggregate_fov=False, **kwargs)</code>","text":"<p>Initializes the IPPTransform.</p> <p>Parameters:</p> Name Type Description Default <code>sampling_rate</code> <code>int</code> <p>Number of points to sample along each segment between two                  consecutive inducing points. <code>sampling_rate=2</code> implies                  only the two endpoints are used (point sensing).                  <code>sampling_rate &gt; 2</code> implies continuous sensing via interpolation.                  Must be \\(\\ge 2\\). Defaults to 2.</p> <code>2</code> <code>distance_budget</code> <code>Optional[float]</code> <p>The maximum allowable total path length for each robot.                                If None, no distance constraint is applied. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>The number of robots or agents involved in the IPP problem. Defaults to 1.</p> <code>1</code> <code>Xu_fixed</code> <code>Optional[ndarray]</code> <p>(num_robots, num_visited, num_dim);                             An array of pre-defined, fixed waypoints that should                             not be optimized (e.g., already visited locations in online IPP).                             If None, all waypoints are optimizable. Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>int</code> <p>The dimensionality of the inducing points (e.g., 2 for (x,y), 3 for (x,y,angle)).            Defaults to 2.</p> <code>2</code> <code>sensor_model</code> <code>Optional[Transform]</code> <p>A <code>Transform</code> object that defines a non-point                                 Field of View (FoV) for the sensor (e.g., <code>SquareTransform</code>).                                 If None, a point sensor model is assumed. Defaults to None.</p> <code>None</code> <code>aggregate_fov</code> <code>bool</code> <p>If True, and <code>sampling_rate &gt; 2</code> (continuous sensing is enabled),                   or if <code>sensor_model</code> is provided, aggregation will be enabled.                   This reduces computation by averaging expanded points' covariances.                   Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the base <code>Transform</code> constructor.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>sampling_rate</code> is less than 2.</p> Usage <pre><code># Single robot, point sensing\ntransform_point = IPPTransform(num_robots=1, num_dim=2, sampling_rate=2)\n\n# Single robot, continuous sensing\ntransform_continuous = IPPTransform(num_robots=1, num_dim=2, sampling_rate=10)\n\n# Multi-robot, continuous sensing with distance budget\ntransform_multi_budget = IPPTransform(num_robots=2, num_dim=2, sampling_rate=5, distance_budget=50.0, constraint_weight=100.0)\n</code></pre> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def __init__(self,\n             sampling_rate: int = 2,\n             distance_budget: Optional[float] = None,\n             num_robots: int = 1,\n             Xu_fixed: Optional[np.ndarray] = None,\n             num_dim: int = 2,\n             sensor_model: Optional[Transform] = None,\n             aggregate_fov: bool = False,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the IPPTransform.\n\n    Args:\n        sampling_rate (int): Number of points to sample along each segment between two\n                             consecutive inducing points. `sampling_rate=2` implies\n                             only the two endpoints are used (point sensing).\n                             `sampling_rate &gt; 2` implies continuous sensing via interpolation.\n                             Must be $\\ge 2$. Defaults to 2.\n        distance_budget (Optional[float]): The maximum allowable total path length for each robot.\n                                           If None, no distance constraint is applied. Defaults to None.\n        num_robots (int): The number of robots or agents involved in the IPP problem. Defaults to 1.\n        Xu_fixed (Optional[np.ndarray]): (num_robots, num_visited, num_dim);\n                                        An array of pre-defined, fixed waypoints that should\n                                        not be optimized (e.g., already visited locations in online IPP).\n                                        If None, all waypoints are optimizable. Defaults to None.\n        num_dim (int): The dimensionality of the inducing points (e.g., 2 for (x,y), 3 for (x,y,angle)).\n                       Defaults to 2.\n        sensor_model (Optional[Transform]): A `Transform` object that defines a non-point\n                                            Field of View (FoV) for the sensor (e.g., `SquareTransform`).\n                                            If None, a point sensor model is assumed. Defaults to None.\n        aggregate_fov (bool): If True, and `sampling_rate &gt; 2` (continuous sensing is enabled),\n                              or if `sensor_model` is provided, aggregation will be enabled.\n                              This reduces computation by averaging expanded points' covariances.\n                              Defaults to False.\n        **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n    Raises:\n        ValueError: If `sampling_rate` is less than 2.\n\n    Usage:\n        ```python\n        # Single robot, point sensing\n        transform_point = IPPTransform(num_robots=1, num_dim=2, sampling_rate=2)\n\n        # Single robot, continuous sensing\n        transform_continuous = IPPTransform(num_robots=1, num_dim=2, sampling_rate=10)\n\n        # Multi-robot, continuous sensing with distance budget\n        transform_multi_budget = IPPTransform(num_robots=2, num_dim=2, sampling_rate=5, distance_budget=50.0, constraint_weight=100.0)\n        ```\n    \"\"\"\n    super().__init__(**kwargs)\n    if sampling_rate &lt; 2:\n        raise ValueError(\n            'Sampling rate must be greater than or equal to 2.')\n\n    self.sampling_rate = sampling_rate\n    self.distance_budget = distance_budget\n    self.num_robots = num_robots\n    self.num_dim = num_dim\n    self.sensor_model = sensor_model\n\n    # Enable aggregation if `aggregate_fov` is True, potentially leveraging the sensor_model's aggregation\n    if aggregate_fov:\n        if self.sensor_model is not None:\n            # If a sensor model exists, let it handle its own aggregation settings.\n            # This assumes `sensor_model` has an `enable_aggregation` method.\n            if hasattr(self.sensor_model, 'enable_aggregation'):\n                self.sensor_model.enable_aggregation()\n        elif self.sampling_rate &gt; 2:\n            # If no specific sensor model but continuous sensing, aggregate based on sampling rate.\n            self.aggregation_size = self.sampling_rate\n\n    # Initialize TensorFlow Variable for fixed waypoints if provided, for online IPP.\n    if Xu_fixed is not None:\n        # Store number of fixed waypoints per robot\n        self.num_fixed = Xu_fixed.shape[1]  \n        self.Xu_fixed = tf.Variable(\n            Xu_fixed,\n            shape=tf.TensorShape(None),\n            trainable=False,  # Fixed points are not optimized\n            dtype=default_float())\n    else:\n        self.Xu_fixed = None\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.aggregate","title":"<code>aggregate(k)</code>","text":"<p>Applies the aggregation transform to kernel matrices. If a <code>sensor_model</code> is defined, it delegates aggregation to the sensor model. Otherwise, it uses the base class's aggregation logic (which depends on <code>self.aggregation_size</code>).</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>Tensor</code> <p>The input kernel matrix (e.g., K_expanded_expanded, K_expanded_training).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The aggregated kernel matrix.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def aggregate(self, k: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Applies the aggregation transform to kernel matrices.\n    If a `sensor_model` is defined, it delegates aggregation to the sensor model.\n    Otherwise, it uses the base class's aggregation logic (which depends on `self.aggregation_size`).\n\n    Args:\n        k (tf.Tensor): The input kernel matrix (e.g., K_expanded_expanded, K_expanded_training).\n\n    Returns:\n        tf.Tensor: The aggregated kernel matrix.\n    \"\"\"\n    if self.sensor_model is not None:\n        return self.sensor_model.aggregate(k)\n    else:\n        return super().aggregate(k)\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.constraints","title":"<code>constraints(Xu)</code>","text":"<p>Computes the distance constraint term that is added to the SGP's optimization function. Each robot's path length is constrained by <code>distance_budget</code>. A penalty is applied if the path length exceeds the budget.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>The inducing points (waypoints) from which to compute path lengths.             Shape: (num_robots * num_waypoints, num_dim).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: A scalar tensor representing the total distance constraint penalty.        This value is negative, and its magnitude increases with constraint violation.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def constraints(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the distance constraint term that is added to the SGP's optimization function.\n    Each robot's path length is constrained by `distance_budget`. A penalty is applied\n    if the path length exceeds the budget.\n\n    Args:\n        Xu (tf.Tensor): The inducing points (waypoints) from which to compute path lengths.\n                        Shape: (num_robots * num_waypoints, num_dim).\n\n    Returns:\n        tf.Tensor: A scalar tensor representing the total distance constraint penalty.\n                   This value is negative, and its magnitude increases with constraint violation.\n    \"\"\"\n    if self.distance_budget is None:\n        return tf.constant(0.0, dtype=default_float())  # No distance constraint\n    else:\n        # Expand Xu without sensor model to get the true path points for distance calculation.\n        # Xu is the optimizable part; self.expand will add fixed points if any.\n        Xu_for_distance = self.expand(Xu, expand_sensor_model=False)\n\n        # Calculate distances for each robot's path\n        individual_robot_distances = self.distance(Xu_for_distance)\n\n        # Compute the positive violation for each robot's path\n        violations = individual_robot_distances - self.distance_budget\n\n        # Apply ReLU to ensure only positive violations contribute to the penalty\n        # Sum all violations and apply the constraint weight\n        penalty = -tf.reduce_sum(\n            tf.nn.relu(violations)) * self.constraint_weight\n        return penalty\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.distance","title":"<code>distance(Xu)</code>","text":"<p>Computes the total path length(s) incurred by sequentially visiting the inducing points. For multiple robots, returns a tensor of individual path lengths.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>The inducing points (waypoints) from which to compute the path lengths.             Shape: (total_waypoints, num_dim). This input is typically already             expanded to include fixed points if <code>Xu_fixed</code> is used.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: A scalar tensor if <code>num_robots=1</code>, or a 1D tensor of floats        (shape: <code>(num_robots,)</code>) representing individual path lengths.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the total path length(s) incurred by sequentially visiting the inducing points.\n    For multiple robots, returns a tensor of individual path lengths.\n\n    Args:\n        Xu (tf.Tensor): The inducing points (waypoints) from which to compute the path lengths.\n                        Shape: (total_waypoints, num_dim). This input is typically already\n                        expanded to include fixed points if `Xu_fixed` is used.\n\n    Returns:\n        tf.Tensor: A scalar tensor if `num_robots=1`, or a 1D tensor of floats\n                   (shape: `(num_robots,)`) representing individual path lengths.\n    \"\"\"\n    # Reshape to (num_robots, num_waypoints_per_robot, num_dim)\n    Xu_reshaped = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n    if self.sensor_model is not None:\n        # If a sensor model is present, delegate distance calculation to it,\n        # as it might have specific logic for its FoV's contribution to distance.\n        dists: List[tf.Tensor] = []\n        for i in range(self.num_robots):\n            # Pass each robot's path (which includes position and potentially angle)\n            dists.append(self.sensor_model.distance(Xu_reshaped[i]))\n        return tf.concat(\n            dists, axis=0)  # Concatenate distances if multiple robots\n    else:\n        # For point/continuous sensing without a special FoV model:\n        # Calculate Euclidean distance between consecutive waypoints.\n        # Assuming first two dimensions are (x,y) for distance calculation.\n        # `Xu_reshaped[:, 1:, :2]` are points from the second to last.\n        # `Xu_reshaped[:, :-1, :2]` are points from the first to second to last.\n        segment_distances = tf.norm(Xu_reshaped[:, 1:, :2] -\n                                    Xu_reshaped[:, :-1, :2],\n                                    axis=-1)\n        total_distances = tf.reduce_sum(\n            segment_distances, axis=1)  # Sum distances for each robot\n        return total_distances\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.expand","title":"<code>expand(Xu, expand_sensor_model=True)</code>","text":"<p>Applies the expansion transform to the inducing points based on the IPP settings. This can involve: 1. Adding fixed (already visited) waypoints. 2. Interpolating points between waypoints for continuous sensing. 3. Expanding each point into a sensor's Field of View (FoV) if a <code>sensor_model</code> is present.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>The current set of optimizable inducing points.             Shape: (num_robots * num_optimizable_waypoints, num_dim).             Note: <code>num_dim</code> might include angle if <code>sensor_model</code> requires it.</p> required <code>expand_sensor_model</code> <code>bool</code> <p>If True, applies the <code>sensor_model</code>'s expansion                         (if a <code>sensor_model</code> is configured). If False,                         only the path interpolation and fixed point handling                         are performed, useful for internal calculations like distance.                         Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The expanded inducing points, ready for kernel computations.        Shape: (total_expanded_points, d_output), where <code>d_output</code>        is typically 2 for (x,y) coordinates used in the kernel.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def expand(self,\n           Xu: tf.Tensor,\n           expand_sensor_model: bool = True) -&gt; tf.Tensor:\n    \"\"\"\n    Applies the expansion transform to the inducing points based on the IPP settings.\n    This can involve:\n    1. Adding fixed (already visited) waypoints.\n    2. Interpolating points between waypoints for continuous sensing.\n    3. Expanding each point into a sensor's Field of View (FoV) if a `sensor_model` is present.\n\n    Args:\n        Xu (tf.Tensor): The current set of optimizable inducing points.\n                        Shape: (num_robots * num_optimizable_waypoints, num_dim).\n                        Note: `num_dim` might include angle if `sensor_model` requires it.\n        expand_sensor_model (bool): If True, applies the `sensor_model`'s expansion\n                                    (if a `sensor_model` is configured). If False,\n                                    only the path interpolation and fixed point handling\n                                    are performed, useful for internal calculations like distance.\n                                    Defaults to True.\n\n    Returns:\n        tf.Tensor: The expanded inducing points, ready for kernel computations.\n                   Shape: (total_expanded_points, d_output), where `d_output`\n                   is typically 2 for (x,y) coordinates used in the kernel.\n    \"\"\"\n    # If using single-robot offline IPP with point sensing, return inducing points as is.\n    if self.sampling_rate == 2 and self.Xu_fixed is None and self.sensor_model is None:\n        return Xu\n\n    # Reshape Xu to (num_robots, num_waypoints_per_robot, num_dim)\n    Xu = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n    # If using online IPP, add visited waypoints that won't be optimized anymore\n    if self.Xu_fixed is not None:\n        Xu = tf.concat([self.Xu_fixed, Xu[:, self.num_fixed:]], axis=1)\n\n    if not expand_sensor_model:\n        return tf.reshape(Xu, (-1, self.num_dim))\n\n    # Interpolate additional inducing points between waypoints to approximate\n    # the continuous data sensing model\n    if self.sampling_rate &gt; 2:\n        Xu = tf.linspace(Xu[:, :-1], Xu[:, 1:], self.sampling_rate)\n        Xu = tf.transpose(Xu, perm=[1, 2, 0, 3])\n        Xu = tf.reshape(Xu, (self.num_robots, -1, self.num_dim))\n\n    # If a sensor model is defined and `expand_sensor_model` is True,\n    # apply the sensor model's expansion for each robot.\n    if self.sensor_model is not None:\n        Xu_ = []\n        for i in range(self.num_robots):\n            Xu_.append(self.sensor_model.expand(Xu[i]))\n        Xu = tf.concat(Xu_, axis=0)\n        return Xu\n\n    Xu = tf.reshape(Xu, (-1, self.num_dim))\n    return Xu\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.IPPTransform.update_Xu_fixed","title":"<code>update_Xu_fixed(Xu_fixed)</code>","text":"<p>Updates the set of visited (fixed) waypoints for online IPP scenarios. These waypoints will not be optimized in subsequent steps.</p> <p>Parameters:</p> Name Type Description Default <code>Xu_fixed</code> <code>ndarray</code> <p>A NumPy array of shape (num_robots, num_visited_waypoints, num_dim)                    representing the new set of fixed waypoints.</p> required Source code in <code>sgptools/core/transformations.py</code> <pre><code>def update_Xu_fixed(self, Xu_fixed: np.ndarray) -&gt; None:\n    \"\"\"\n    Updates the set of visited (fixed) waypoints for online IPP scenarios.\n    These waypoints will not be optimized in subsequent steps.\n\n    Args:\n        Xu_fixed (np.ndarray): A NumPy array of shape (num_robots, num_visited_waypoints, num_dim)\n                               representing the new set of fixed waypoints.\n    \"\"\"\n    # Store number of fixed waypoints per robot\n    self.num_fixed = Xu_fixed.shape[1]  \n    if self.Xu_fixed is not None:\n        self.Xu_fixed.assign(tf.constant(Xu_fixed, dtype=default_float()))\n    else:\n        self.Xu_fixed = tf.Variable(Xu_fixed,\n                                    shape=tf.TensorShape(None),\n                                    trainable=False,\n                                    dtype=default_float())\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareTransform","title":"<code>sgptools.core.transformations.SquareTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Non-point Transform to model a square Field of View (FoV) for a sensor. This transform expands each inducing point (waypoint with position and orientation) into a grid of points approximating a square area, which is then used in kernel computations. This typically applies to single-robot cases as part of an <code>IPPTransform</code>.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>class SquareTransform(Transform):\n    \"\"\"\n    Non-point Transform to model a square Field of View (FoV) for a sensor.\n    This transform expands each inducing point (waypoint with position and orientation)\n    into a grid of points approximating a square area, which is then used in kernel computations.\n    This typically applies to single-robot cases as part of an `IPPTransform`.\n    \"\"\"\n\n    def __init__(self,\n                 side_length: float,\n                 pts_per_side: int,\n                 aggregate_fov: bool = False,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the SquareTransform for a square FoV.\n\n        Args:\n            side_length (float): The side length of the square FoV.\n            pts_per_side (int): The number of points to sample along each side of the square.\n                                A `pts_per_side` of 3 will create a 3x3 grid of 9 points to approximate the FoV.\n            aggregate_fov (bool): If True, aggregation will be enabled for the expanded FoV points.\n                                  This averages covariances from the FoV points to reduce computational cost.\n                                  Defaults to False.\n            **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n        Usage:\n            ```python\n            # Create a square FoV of side length 10.0, approximated by a 5x5 grid of points\n            square_fov_transform = SquareTransform(length=10.0, pts_per_side=5, aggregate_fov=True)\n            ```\n        \"\"\"\n        super().__init__(**kwargs)\n        self.side_length = side_length\n        self.pts_per_side = pts_per_side\n        # Calculate the spacing between points along each side\n        self.side_length_factor = side_length / (self.pts_per_side)\n\n        if aggregate_fov:\n            self.enable_aggregation()\n\n    def enable_aggregation(self, size: Optional[int] = None) -&gt; None:\n        \"\"\"\n        Enables FoV covariance aggregation. This reduces the covariance matrix inversion\n        cost by effectively reducing the covariance matrix size.\n\n        Args:\n            size (Optional[int]): If None, all the interpolated inducing points within the FoV\n                                  (i.e., `pts_per_side^2` points) are aggregated into a single aggregated point.\n                                  Alternatively, the number of inducing points to aggregate can be\n                                  explicitly defined using this variable (e.g., if a custom\n                                  aggregation strategy is desired that groups `size` points).\n                                  Defaults to None.\n        \"\"\"\n        if size is None:\n            self.aggregation_size = self.pts_per_side**2  # Aggregate all points within a FoV\n        else:\n            self.aggregation_size = size\n\n    def expand(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Applies the expansion transformation to the inducing points, modeling a square FoV.\n        Each input inducing point, which includes position (x, y) and orientation (theta),\n        is expanded into a grid of `pts_per_side` x `pts_per_side` points representing the FoV.\n\n        Args:\n            Xu (tf.Tensor): Inducing points in the position and orientation space.\n                            Shape: (m, 3) where `m` is the number of inducing points,\n                            and `3` corresponds to (x, y, angle in radians).\n\n        Returns:\n            tf.Tensor: The expanded inducing points in 2D input space (x,y).\n                       Shape: (m * pts_per_side * pts_per_side, 2).\n                       `m` is the number of original inducing points.\n                       `pts_per_side * pts_per_side` is the number of points each inducing\n                       point is mapped to in order to form the FoV.\n        \"\"\"\n        # Split Xu into x, y coordinates and orientation (theta)\n        x_coords, y_coords, angles = tf.split(Xu, num_or_size_splits=3, axis=1)\n        x = tf.reshape(x_coords, [\n            -1,\n        ])  # Flatten to (m,)\n        y = tf.reshape(y_coords, [\n            -1,\n        ])\n        theta = tf.reshape(angles, [\n            -1,\n        ])\n\n        points: List[tf.Tensor] = []\n        # Iterate to create `pts_per_side` lines forming the square grid.\n        # The loop runs from -floor(pts_per_side/2) to ceil(pts_per_side/2) to center the grid.\n        for i in range(-int(np.floor((self.pts_per_side - 1) / 2)),\n                       int(np.ceil((self.pts_per_side - 1) / 2)) + 1):\n            # Calculate start and end points for each line segment of the square grid.\n            # `(i * self.side_length_factor)` shifts the line perpendicular to the orientation `theta`.\n            # `self.side_length/2` extends the line segment along the orientation `theta`.\n\n            # Start point (x,y) for the current line\n            start_x = x + (i * self.side_length_factor) * tf.cos(\n                theta + np.pi / 2) - self.side_length / 2 * tf.cos(theta)\n            start_y = y + (i * self.side_length_factor) * tf.sin(\n                theta + np.pi / 2) - self.side_length / 2 * tf.sin(theta)\n\n            # End point (x,y) for the current line\n            end_x = x + (i * self.side_length_factor) * tf.cos(\n                theta + np.pi / 2) + self.side_length / 2 * tf.cos(theta)\n            end_y = y + (i * self.side_length_factor) * tf.sin(\n                theta + np.pi / 2) + self.side_length / 2 * tf.sin(theta)\n\n            # Stack start and end points for linspace\n            line_starts = tf.stack([start_x, start_y], axis=-1)  # (m, 2)\n            line_ends = tf.stack([end_x, end_y], axis=-1)  # (m, 2)\n\n            # Generate `self.pts_per_side` points along each line segment.\n            # `axis=1` ensures interpolation is done column-wise for each (start, end) pair.\n            # The result is (m, pts_per_side, 2) for each `i`.\n            points.append(\n                tf.linspace(line_starts, line_ends, self.pts_per_side, axis=1))\n\n        # Concatenate all generated line segments.\n        # `tf.concat` will stack them along a new axis, forming (num_lines, m, pts_per_side, 2)\n        xy = tf.concat(\n            points, axis=1\n        )  # (m, pts_per_side * pts_per_side, 2) after the transpose in the original code.\n\n        xy = tf.reshape(xy, (-1, 2))\n        return xy\n\n    def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the Euclidean distance incurred by sequentially visiting the inducing points.\n        For a Square FoV, the distance is typically only based on the (x,y) movement,\n        ignoring the angle.\n\n        Args:\n            Xu (tf.Tensor): Inducing points.\n                            Shape: (m, 3) where `m` is the number of inducing points,\n                            and `3` corresponds to (x, y, angle).\n\n        Returns:\n            tf.Tensor: A scalar tensor representing the total path length.\n        \"\"\"\n        # Reshape to (number_of_points, 3) and take only the (x,y) coordinates\n        Xu_xy = tf.reshape(\n            Xu, (-1, self.num_dim))[:, :2]  # Assuming num_dim is 3 (x,y,angle)\n\n        if Xu_xy.shape[0] &lt; 2:\n            return tf.constant(0.0, dtype=default_float())\n\n        # Calculate Euclidean distance between consecutive (x,y) points\n        segment_distances = tf.norm(Xu_xy[1:] - Xu_xy[:-1], axis=-1)\n        total_distance = tf.reduce_sum(segment_distances, axis=0)\n        return total_distance\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareTransform.__init__","title":"<code>__init__(side_length, pts_per_side, aggregate_fov=False, **kwargs)</code>","text":"<p>Initializes the SquareTransform for a square FoV.</p> <p>Parameters:</p> Name Type Description Default <code>side_length</code> <code>float</code> <p>The side length of the square FoV.</p> required <code>pts_per_side</code> <code>int</code> <p>The number of points to sample along each side of the square.                 A <code>pts_per_side</code> of 3 will create a 3x3 grid of 9 points to approximate the FoV.</p> required <code>aggregate_fov</code> <code>bool</code> <p>If True, aggregation will be enabled for the expanded FoV points.                   This averages covariances from the FoV points to reduce computational cost.                   Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the base <code>Transform</code> constructor.</p> <code>{}</code> Usage <pre><code># Create a square FoV of side length 10.0, approximated by a 5x5 grid of points\nsquare_fov_transform = SquareTransform(length=10.0, pts_per_side=5, aggregate_fov=True)\n</code></pre> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def __init__(self,\n             side_length: float,\n             pts_per_side: int,\n             aggregate_fov: bool = False,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the SquareTransform for a square FoV.\n\n    Args:\n        side_length (float): The side length of the square FoV.\n        pts_per_side (int): The number of points to sample along each side of the square.\n                            A `pts_per_side` of 3 will create a 3x3 grid of 9 points to approximate the FoV.\n        aggregate_fov (bool): If True, aggregation will be enabled for the expanded FoV points.\n                              This averages covariances from the FoV points to reduce computational cost.\n                              Defaults to False.\n        **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n    Usage:\n        ```python\n        # Create a square FoV of side length 10.0, approximated by a 5x5 grid of points\n        square_fov_transform = SquareTransform(length=10.0, pts_per_side=5, aggregate_fov=True)\n        ```\n    \"\"\"\n    super().__init__(**kwargs)\n    self.side_length = side_length\n    self.pts_per_side = pts_per_side\n    # Calculate the spacing between points along each side\n    self.side_length_factor = side_length / (self.pts_per_side)\n\n    if aggregate_fov:\n        self.enable_aggregation()\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareTransform.distance","title":"<code>distance(Xu)</code>","text":"<p>Computes the Euclidean distance incurred by sequentially visiting the inducing points. For a Square FoV, the distance is typically only based on the (x,y) movement, ignoring the angle.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>Inducing points.             Shape: (m, 3) where <code>m</code> is the number of inducing points,             and <code>3</code> corresponds to (x, y, angle).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: A scalar tensor representing the total path length.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the Euclidean distance incurred by sequentially visiting the inducing points.\n    For a Square FoV, the distance is typically only based on the (x,y) movement,\n    ignoring the angle.\n\n    Args:\n        Xu (tf.Tensor): Inducing points.\n                        Shape: (m, 3) where `m` is the number of inducing points,\n                        and `3` corresponds to (x, y, angle).\n\n    Returns:\n        tf.Tensor: A scalar tensor representing the total path length.\n    \"\"\"\n    # Reshape to (number_of_points, 3) and take only the (x,y) coordinates\n    Xu_xy = tf.reshape(\n        Xu, (-1, self.num_dim))[:, :2]  # Assuming num_dim is 3 (x,y,angle)\n\n    if Xu_xy.shape[0] &lt; 2:\n        return tf.constant(0.0, dtype=default_float())\n\n    # Calculate Euclidean distance between consecutive (x,y) points\n    segment_distances = tf.norm(Xu_xy[1:] - Xu_xy[:-1], axis=-1)\n    total_distance = tf.reduce_sum(segment_distances, axis=0)\n    return total_distance\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareTransform.enable_aggregation","title":"<code>enable_aggregation(size=None)</code>","text":"<p>Enables FoV covariance aggregation. This reduces the covariance matrix inversion cost by effectively reducing the covariance matrix size.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Optional[int]</code> <p>If None, all the interpolated inducing points within the FoV                   (i.e., <code>pts_per_side^2</code> points) are aggregated into a single aggregated point.                   Alternatively, the number of inducing points to aggregate can be                   explicitly defined using this variable (e.g., if a custom                   aggregation strategy is desired that groups <code>size</code> points).                   Defaults to None.</p> <code>None</code> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def enable_aggregation(self, size: Optional[int] = None) -&gt; None:\n    \"\"\"\n    Enables FoV covariance aggregation. This reduces the covariance matrix inversion\n    cost by effectively reducing the covariance matrix size.\n\n    Args:\n        size (Optional[int]): If None, all the interpolated inducing points within the FoV\n                              (i.e., `pts_per_side^2` points) are aggregated into a single aggregated point.\n                              Alternatively, the number of inducing points to aggregate can be\n                              explicitly defined using this variable (e.g., if a custom\n                              aggregation strategy is desired that groups `size` points).\n                              Defaults to None.\n    \"\"\"\n    if size is None:\n        self.aggregation_size = self.pts_per_side**2  # Aggregate all points within a FoV\n    else:\n        self.aggregation_size = size\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareTransform.expand","title":"<code>expand(Xu)</code>","text":"<p>Applies the expansion transformation to the inducing points, modeling a square FoV. Each input inducing point, which includes position (x, y) and orientation (theta), is expanded into a grid of <code>pts_per_side</code> x <code>pts_per_side</code> points representing the FoV.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>Inducing points in the position and orientation space.             Shape: (m, 3) where <code>m</code> is the number of inducing points,             and <code>3</code> corresponds to (x, y, angle in radians).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The expanded inducing points in 2D input space (x,y).        Shape: (m * pts_per_side * pts_per_side, 2).        <code>m</code> is the number of original inducing points.        <code>pts_per_side * pts_per_side</code> is the number of points each inducing        point is mapped to in order to form the FoV.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def expand(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Applies the expansion transformation to the inducing points, modeling a square FoV.\n    Each input inducing point, which includes position (x, y) and orientation (theta),\n    is expanded into a grid of `pts_per_side` x `pts_per_side` points representing the FoV.\n\n    Args:\n        Xu (tf.Tensor): Inducing points in the position and orientation space.\n                        Shape: (m, 3) where `m` is the number of inducing points,\n                        and `3` corresponds to (x, y, angle in radians).\n\n    Returns:\n        tf.Tensor: The expanded inducing points in 2D input space (x,y).\n                   Shape: (m * pts_per_side * pts_per_side, 2).\n                   `m` is the number of original inducing points.\n                   `pts_per_side * pts_per_side` is the number of points each inducing\n                   point is mapped to in order to form the FoV.\n    \"\"\"\n    # Split Xu into x, y coordinates and orientation (theta)\n    x_coords, y_coords, angles = tf.split(Xu, num_or_size_splits=3, axis=1)\n    x = tf.reshape(x_coords, [\n        -1,\n    ])  # Flatten to (m,)\n    y = tf.reshape(y_coords, [\n        -1,\n    ])\n    theta = tf.reshape(angles, [\n        -1,\n    ])\n\n    points: List[tf.Tensor] = []\n    # Iterate to create `pts_per_side` lines forming the square grid.\n    # The loop runs from -floor(pts_per_side/2) to ceil(pts_per_side/2) to center the grid.\n    for i in range(-int(np.floor((self.pts_per_side - 1) / 2)),\n                   int(np.ceil((self.pts_per_side - 1) / 2)) + 1):\n        # Calculate start and end points for each line segment of the square grid.\n        # `(i * self.side_length_factor)` shifts the line perpendicular to the orientation `theta`.\n        # `self.side_length/2` extends the line segment along the orientation `theta`.\n\n        # Start point (x,y) for the current line\n        start_x = x + (i * self.side_length_factor) * tf.cos(\n            theta + np.pi / 2) - self.side_length / 2 * tf.cos(theta)\n        start_y = y + (i * self.side_length_factor) * tf.sin(\n            theta + np.pi / 2) - self.side_length / 2 * tf.sin(theta)\n\n        # End point (x,y) for the current line\n        end_x = x + (i * self.side_length_factor) * tf.cos(\n            theta + np.pi / 2) + self.side_length / 2 * tf.cos(theta)\n        end_y = y + (i * self.side_length_factor) * tf.sin(\n            theta + np.pi / 2) + self.side_length / 2 * tf.sin(theta)\n\n        # Stack start and end points for linspace\n        line_starts = tf.stack([start_x, start_y], axis=-1)  # (m, 2)\n        line_ends = tf.stack([end_x, end_y], axis=-1)  # (m, 2)\n\n        # Generate `self.pts_per_side` points along each line segment.\n        # `axis=1` ensures interpolation is done column-wise for each (start, end) pair.\n        # The result is (m, pts_per_side, 2) for each `i`.\n        points.append(\n            tf.linspace(line_starts, line_ends, self.pts_per_side, axis=1))\n\n    # Concatenate all generated line segments.\n    # `tf.concat` will stack them along a new axis, forming (num_lines, m, pts_per_side, 2)\n    xy = tf.concat(\n        points, axis=1\n    )  # (m, pts_per_side * pts_per_side, 2) after the transpose in the original code.\n\n    xy = tf.reshape(xy, (-1, 2))\n    return xy\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareHeightTransform","title":"<code>sgptools.core.transformations.SquareHeightTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Non-point Transform to model a height-dependent square Field of View (FoV). The size of the square FoV changes with the 'height' (z-dimension) of the sensor. This transform expands each inducing point (waypoint with x, y, z coordinates) into a grid of points approximating a square area whose size depends on 'z'.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>class SquareHeightTransform(Transform):\n    \"\"\"\n    Non-point Transform to model a height-dependent square Field of View (FoV).\n    The size of the square FoV changes with the 'height' (z-dimension) of the sensor.\n    This transform expands each inducing point (waypoint with x, y, z coordinates)\n    into a grid of points approximating a square area whose size depends on 'z'.\n    \"\"\"\n\n    def __init__(self,\n                 pts_per_side: int,\n                 aggregate_fov: bool = False,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the SquareHeightTransform for a height-dependent square FoV.\n\n        Args:\n            pts_per_side (int): The number of points to sample along each side of the square FoV.\n                            A `pts_per_side` of 3 will create a 3x3 grid of 9 points to approximate the FoV.\n            aggregate_fov (bool): If True, aggregation will be enabled for the expanded FoV points.\n                                  This averages covariances from the FoV points to reduce computational cost.\n                                  Defaults to False.\n            **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n        Usage:\n            ```python\n            # Create a height-dependent square FoV approximated by a 7x7 grid\n            square_height_fov_transform = SquareHeightTransform(pts_per_side=7, aggregate_fov=True)\n            ```\n        \"\"\"\n        super().__init__(**kwargs)\n        self.pts_per_side = pts_per_side\n\n        if aggregate_fov:\n            self.enable_aggregation()\n\n    def enable_aggregation(self, size: Optional[int] = None) -&gt; None:\n        \"\"\"\n        Enables FoV covariance aggregation, which reduces the covariance matrix inversion\n        cost by effectively reducing the covariance matrix size.\n\n        Args:\n            size (Optional[int]): If None, all the interpolated inducing points within the FoV\n                                  (i.e., `pts_per_side^2` points) are aggregated into a single aggregated point.\n                                  Alternatively, the number of inducing points to aggregate can be\n                                  explicitly defined using this variable. Defaults to None.\n        \"\"\"\n        if size is None:\n            self.aggregation_size = self.pts_per_side**2\n        else:\n            self.aggregation_size = size\n\n    def expand(self, Xu):\n        \"\"\"\n        Applies the expansion transform to the inducing points\n\n        Args:\n            Xu (ndarray): (m, 3); Inducing points in the 3D position space.\n                        `m` is the number of inducing points,\n                        `3` is the dimension of the space (x, y, z)\n\n        Returns:\n            Xu (ndarray): (mp, 2); Inducing points in input space.\n                        `p` is the number of points each inducing point is mapped \n                        to in order to form the FoV.\n        \"\"\"\n        x, y, h = tf.split(Xu, num_or_size_splits=3, axis=1)\n        x = tf.reshape(x, [\n            -1,\n        ])\n        y = tf.reshape(y, [\n            -1,\n        ])\n        h = tf.reshape(h, [\n            -1,\n        ])\n\n        delta = h / (self.pts_per_side - 1)\n\n        pts = []\n        for i in range(self.pts_per_side):\n            line_starts = [x - h / 2, y - (h / 2) + (delta * i)]\n            line_ends = [x + h / 2, y - (h / 2) + (delta * i)]\n            pts.append(\n                tf.linspace(line_starts, line_ends, self.pts_per_side, axis=1))\n        xy = tf.concat(pts, axis=1)\n        xy = tf.transpose(xy, [2, 1, 0])\n        xy = tf.reshape(xy, [-1, 2])\n        xy = self._reshape(xy, tf.shape(Xu)[0])\n        return xy\n\n    def _reshape(self, X: tf.Tensor, num_inducing: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Reorders the expanded inducing points.\n\n        Args:\n            X (tf.Tensor): Expanded inducing points.\n            num_inducing (tf.Tensor): Original number of inducing points.\n\n        Returns:\n            tf.Tensor: Reordered expanded inducing points.\n        \"\"\"\n        X = tf.reshape(\n            X, (num_inducing, -1, self.pts_per_side, self.pts_per_side, 2))\n        X = tf.transpose(X, (0, 2, 1, 3, 4))\n        X = tf.reshape(X, (-1, 2))\n        return X\n\n    def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the Euclidean distance incurred by sequentially visiting the inducing points.\n        For a height-dependent Square FoV, the distance is typically only based on the\n        (x,y,z) movement.\n\n        Args:\n            Xu (tf.Tensor): Inducing points.\n                            Shape: (m, 3) where `m` is the number of inducing points,\n                            and `3` corresponds to (x, y, z).\n\n        Returns:\n            tf.Tensor: A scalar tensor representing the total path length.\n        \"\"\"\n        # Reshape to (number_of_points, 3)\n        Xu_xyz = tf.reshape(Xu, (-1, 3))\n\n        # Calculate Euclidean distance between consecutive (x,y,z) points\n        segment_distances = tf.norm(Xu_xyz[1:] - Xu_xyz[:-1], axis=-1)\n        total_distance = tf.reduce_sum(segment_distances, axis=0)\n        return total_distance\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareHeightTransform.__init__","title":"<code>__init__(pts_per_side, aggregate_fov=False, **kwargs)</code>","text":"<p>Initializes the SquareHeightTransform for a height-dependent square FoV.</p> <p>Parameters:</p> Name Type Description Default <code>pts_per_side</code> <code>int</code> <p>The number of points to sample along each side of the square FoV.             A <code>pts_per_side</code> of 3 will create a 3x3 grid of 9 points to approximate the FoV.</p> required <code>aggregate_fov</code> <code>bool</code> <p>If True, aggregation will be enabled for the expanded FoV points.                   This averages covariances from the FoV points to reduce computational cost.                   Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the base <code>Transform</code> constructor.</p> <code>{}</code> Usage <pre><code># Create a height-dependent square FoV approximated by a 7x7 grid\nsquare_height_fov_transform = SquareHeightTransform(pts_per_side=7, aggregate_fov=True)\n</code></pre> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def __init__(self,\n             pts_per_side: int,\n             aggregate_fov: bool = False,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the SquareHeightTransform for a height-dependent square FoV.\n\n    Args:\n        pts_per_side (int): The number of points to sample along each side of the square FoV.\n                        A `pts_per_side` of 3 will create a 3x3 grid of 9 points to approximate the FoV.\n        aggregate_fov (bool): If True, aggregation will be enabled for the expanded FoV points.\n                              This averages covariances from the FoV points to reduce computational cost.\n                              Defaults to False.\n        **kwargs (Any): Additional keyword arguments passed to the base `Transform` constructor.\n\n    Usage:\n        ```python\n        # Create a height-dependent square FoV approximated by a 7x7 grid\n        square_height_fov_transform = SquareHeightTransform(pts_per_side=7, aggregate_fov=True)\n        ```\n    \"\"\"\n    super().__init__(**kwargs)\n    self.pts_per_side = pts_per_side\n\n    if aggregate_fov:\n        self.enable_aggregation()\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareHeightTransform.distance","title":"<code>distance(Xu)</code>","text":"<p>Computes the Euclidean distance incurred by sequentially visiting the inducing points. For a height-dependent Square FoV, the distance is typically only based on the (x,y,z) movement.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>Tensor</code> <p>Inducing points.             Shape: (m, 3) where <code>m</code> is the number of inducing points,             and <code>3</code> corresponds to (x, y, z).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: A scalar tensor representing the total path length.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def distance(self, Xu: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the Euclidean distance incurred by sequentially visiting the inducing points.\n    For a height-dependent Square FoV, the distance is typically only based on the\n    (x,y,z) movement.\n\n    Args:\n        Xu (tf.Tensor): Inducing points.\n                        Shape: (m, 3) where `m` is the number of inducing points,\n                        and `3` corresponds to (x, y, z).\n\n    Returns:\n        tf.Tensor: A scalar tensor representing the total path length.\n    \"\"\"\n    # Reshape to (number_of_points, 3)\n    Xu_xyz = tf.reshape(Xu, (-1, 3))\n\n    # Calculate Euclidean distance between consecutive (x,y,z) points\n    segment_distances = tf.norm(Xu_xyz[1:] - Xu_xyz[:-1], axis=-1)\n    total_distance = tf.reduce_sum(segment_distances, axis=0)\n    return total_distance\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareHeightTransform.enable_aggregation","title":"<code>enable_aggregation(size=None)</code>","text":"<p>Enables FoV covariance aggregation, which reduces the covariance matrix inversion cost by effectively reducing the covariance matrix size.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Optional[int]</code> <p>If None, all the interpolated inducing points within the FoV                   (i.e., <code>pts_per_side^2</code> points) are aggregated into a single aggregated point.                   Alternatively, the number of inducing points to aggregate can be                   explicitly defined using this variable. Defaults to None.</p> <code>None</code> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def enable_aggregation(self, size: Optional[int] = None) -&gt; None:\n    \"\"\"\n    Enables FoV covariance aggregation, which reduces the covariance matrix inversion\n    cost by effectively reducing the covariance matrix size.\n\n    Args:\n        size (Optional[int]): If None, all the interpolated inducing points within the FoV\n                              (i.e., `pts_per_side^2` points) are aggregated into a single aggregated point.\n                              Alternatively, the number of inducing points to aggregate can be\n                              explicitly defined using this variable. Defaults to None.\n    \"\"\"\n    if size is None:\n        self.aggregation_size = self.pts_per_side**2\n    else:\n        self.aggregation_size = size\n</code></pre>"},{"location":"api/core/transformations.html#sgptools.core.transformations.SquareHeightTransform.expand","title":"<code>expand(Xu)</code>","text":"<p>Applies the expansion transform to the inducing points</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>ndarray</code> <p>(m, 3); Inducing points in the 3D position space.         <code>m</code> is the number of inducing points,         <code>3</code> is the dimension of the space (x, y, z)</p> required <p>Returns:</p> Name Type Description <code>Xu</code> <code>ndarray</code> <p>(mp, 2); Inducing points in input space.         <code>p</code> is the number of points each inducing point is mapped          to in order to form the FoV.</p> Source code in <code>sgptools/core/transformations.py</code> <pre><code>def expand(self, Xu):\n    \"\"\"\n    Applies the expansion transform to the inducing points\n\n    Args:\n        Xu (ndarray): (m, 3); Inducing points in the 3D position space.\n                    `m` is the number of inducing points,\n                    `3` is the dimension of the space (x, y, z)\n\n    Returns:\n        Xu (ndarray): (mp, 2); Inducing points in input space.\n                    `p` is the number of points each inducing point is mapped \n                    to in order to form the FoV.\n    \"\"\"\n    x, y, h = tf.split(Xu, num_or_size_splits=3, axis=1)\n    x = tf.reshape(x, [\n        -1,\n    ])\n    y = tf.reshape(y, [\n        -1,\n    ])\n    h = tf.reshape(h, [\n        -1,\n    ])\n\n    delta = h / (self.pts_per_side - 1)\n\n    pts = []\n    for i in range(self.pts_per_side):\n        line_starts = [x - h / 2, y - (h / 2) + (delta * i)]\n        line_ends = [x + h / 2, y - (h / 2) + (delta * i)]\n        pts.append(\n            tf.linspace(line_starts, line_ends, self.pts_per_side, axis=1))\n    xy = tf.concat(pts, axis=1)\n    xy = tf.transpose(xy, [2, 1, 0])\n    xy = tf.reshape(xy, [-1, 2])\n    xy = self._reshape(xy, tf.shape(Xu)[0])\n    return xy\n</code></pre>"},{"location":"api/kernels/index.html","title":"<code>kernels</code>: Kernel Functions","text":"<p>This module contains kernel functions for the Gaussian Process models. This includes all kernel functions in gpflow, and advanced, non-stationary kernels. Use the <code>get_kernel</code> method to retrieve a kernel class by its string name.</p> <ul> <li> <p><code>Attentive</code>: A non-stationary kernel that uses a neural network to learn attention weights for a mixture of RBF kernels. This allows the model to adapt its assumptions about the data's correlation structure across the input space.</p> </li> <li> <p><code>NeuralSpectral</code>: Another non-stationary kernel that employs Multilayer perceptrons (MLPs) to learn the frequency, lengthscale, and variance of a spectral mixture. This provides a flexible way to model complex, non-stationary data.</p> </li> <li> <p><code>gpflow.kernels</code>: All available kernels in gpflow's kernels module.</p> </li> </ul>"},{"location":"api/kernels/index.html#sgptools.kernels.get_kernel","title":"<code>sgptools.kernels.get_kernel(kernel)</code>","text":"<p>Retrieves a Kernel class from the <code>KERNELS</code> dictionary based on its string name.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>str</code> <p>The name of the kernel to retrieve. The name must be a key           in the <code>KERNELS</code> dictionary. Includes all available kernels in gpflow.           e.g., 'NeuralSpectralKernel', 'AttentiveKernel', 'RBF'.</p> required <p>Returns:</p> Type Description <code>Type[Kernel]</code> <p>Type[Kernel]: The kernel class corresponding to the provided kernel name.           This class can then be instantiated to create a kernel object.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the provided <code>kernel</code> name does not exist in the <code>KERNELS</code> dictionary.</p> Usage <pre><code>from sgptools.kernels import get_kernel\nimport gpflow\nimport numpy as np\n\n# --- Select and instantiate a kernel ---\n# 1. Get the RBF kernel class\nRBFKernelClass = get_kernel('RBF')\n# 2. Instantiate the kernel with specific parameters\nrbf_kernel = RBFKernelClass(lengthscales=1.2)\n\n# --- Or for a more complex custom kernel ---\nNeuralKernelClass = get_kernel('NeuralSpectral')\nneural_kernel = NeuralKernelClass(input_dim=2, Q=3, hidden_sizes=[32, 32])\n\n# --- Example of using the kernel in a GPR model ---\n# Dummy data\nX = np.random.rand(10, 1)\nY = np.sin(X) + np.random.randn(*X.shape)*0.1\n# Create a model with the selected RBF kernel\nmodel = gpflow.models.GPR(data=(X, Y), kernel=rbf_kernel)\n</code></pre> Source code in <code>sgptools/kernels/__init__.py</code> <pre><code>def get_kernel(kernel: str) -&gt; Type[gpflow.kernels.Kernel]:\n    \"\"\"\n    Retrieves a Kernel class from the `KERNELS` dictionary based on its string name.\n\n    Args:\n        kernel (str): The name of the kernel to retrieve. The name must be a key\n                      in the `KERNELS` dictionary. Includes all available kernels in gpflow.\n                      e.g., 'NeuralSpectralKernel', 'AttentiveKernel', 'RBF'.\n\n    Returns:\n        Type[Kernel]: The kernel class corresponding to the provided kernel name.\n                      This class can then be instantiated to create a kernel object.\n\n    Raises:\n        KeyError: If the provided `kernel` name does not exist in the `KERNELS` dictionary.\n\n    Usage:\n        ```python\n        from sgptools.kernels import get_kernel\n        import gpflow\n        import numpy as np\n\n        # --- Select and instantiate a kernel ---\n        # 1. Get the RBF kernel class\n        RBFKernelClass = get_kernel('RBF')\n        # 2. Instantiate the kernel with specific parameters\n        rbf_kernel = RBFKernelClass(lengthscales=1.2)\n\n        # --- Or for a more complex custom kernel ---\n        NeuralKernelClass = get_kernel('NeuralSpectral')\n        neural_kernel = NeuralKernelClass(input_dim=2, Q=3, hidden_sizes=[32, 32])\n\n        # --- Example of using the kernel in a GPR model ---\n        # Dummy data\n        X = np.random.rand(10, 1)\n        Y = np.sin(X) + np.random.randn(*X.shape)*0.1\n        # Create a model with the selected RBF kernel\n        model = gpflow.models.GPR(data=(X, Y), kernel=rbf_kernel)\n        ```\n    \"\"\"\n    if kernel not in KERNELS:\n        raise KeyError(f\"Kernel '{kernel}' not found. Available options: {list(KERNELS.keys())}\")\n    return KERNELS[kernel]\n</code></pre>"},{"location":"api/kernels/attentive.html","title":"Attentive Kernel","text":""},{"location":"api/kernels/attentive.html#sgptools.kernels.attentive.Attentive","title":"<code>sgptools.kernels.attentive.Attentive</code>","text":"<p>               Bases: <code>Kernel</code></p> <p>Attentive Kernel function (non-stationary kernel function).</p> <p>This kernel uses a Multi-Layer Perceptron (MLP) to learn attention weights for a mixture of RBF kernel components, making it adapt to local data characteristics. It is based on the implementation from Weizhe-Chen/attentive_kernels.</p> Refer to the following paper for more details <ul> <li>AK: Attentive Kernel for Information Gathering [Chen et al., 2022]</li> </ul> <p>Attributes:</p> Name Type Description <code>_free_amplitude</code> <code>Variable</code> <p>The amplitude (variance) parameter of the kernel.</p> <code>lengthscales</code> <code>Variable</code> <p>Fixed lengthscales for each RBF mixture component.</p> <code>num_lengthscales</code> <code>int</code> <p>Number of RBF mixture components.</p> <code>nn</code> <code>NN</code> <p>The Neural Network (MLP) used to generate attention representations.</p> Source code in <code>sgptools/kernels/attentive.py</code> <pre><code>class Attentive(gpflow.kernels.Kernel):\n    \"\"\"\n    Attentive Kernel function (non-stationary kernel function).\n\n    This kernel uses a Multi-Layer Perceptron (MLP) to learn attention weights\n    for a mixture of RBF kernel components, making it adapt to local data\n    characteristics. It is based on the implementation from\n    [Weizhe-Chen/attentive_kernels](https://github.com/Weizhe-Chen/attentive_kernels).\n\n    Refer to the following paper for more details:\n        - AK: Attentive Kernel for Information Gathering [Chen et al., 2022]\n\n    Attributes:\n        _free_amplitude (tf.Variable): The amplitude (variance) parameter of the kernel.\n        lengthscales (tf.Variable): Fixed lengthscales for each RBF mixture component.\n        num_lengthscales (int): Number of RBF mixture components.\n        nn (NN): The Neural Network (MLP) used to generate attention representations.\n    \"\"\"\n\n    def __init__(self,\n                 lengthscales: Union[List[float], np.ndarray] = None,\n                 hidden_sizes: List[int] = None,\n                 amplitude: float = 1.0,\n                 num_dim: int = 2):\n        \"\"\"\n        Initializes the Attentive Kernel.\n\n        Args:\n            lengthscales (Union[List[float], np.ndarray]): A list or NumPy array of\n                                                        lengthscale values to be used in the\n                                                        RBF mixture components. These lengthscales\n                                                        are not trained by the optimizer.\n            hidden_sizes (List[int]): A list where each element specifies the number of hidden units\n                                      in a layer of the MLPs. The length of this list determines\n                                      the number of hidden layers. Defaults to [10, 10].\n            amplitude (float): Initial amplitude (variance) of the kernel function.\n                               This parameter is trainable. Defaults to 1.0.\n            num_dim (int): The dimensionality of the input data points (e.g., 2 for 2D data).\n                           Defaults to 2.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            from sgptools.kernels.attentive import Attentive\n\n            # Example: 10 fixed lengthscales ranging from 0.01 to 2.0\n            l_scales = np.linspace(0.01, 2.0, 10).astype(np.float32)\n\n            # Initialize Attentive Kernel for 2D data\n            kernel = Attentive(lengthscales=l_scales, hidden_sizes=[10, 10], num_dim=2)\n\n            # You can then use this kernel in a GPflow model:\n            # model = gpflow.models.GPR(data=(X_train, Y_train), kernel=kernel, noise_variance=0.1)\n            # optimize_model(model)\n            ```\n        \"\"\"\n        super().__init__()\n        if lengthscales is None:\n            lengthscales = np.linspace(0.01, 2.0, 10)\n\n        if hidden_sizes is None:\n            hidden_sizes = [10, 10]  # Default if not provided\n        else:\n            hidden_sizes = list(hidden_sizes)\n\n        with self.name_scope:\n            self.num_lengthscales = len(lengthscales)\n            self._free_amplitude = tf.Variable(amplitude,\n                                               shape=[],\n                                               trainable=True,\n                                               dtype=default_float())\n            # Lengthscales are treated as fixed parameters in this implementation\n            self.lengthscales = tf.Variable(\n                tf.cast(lengthscales, default_float()),\n                shape=[self.num_lengthscales],\n                trainable=False,  # Not trainable\n                dtype=default_float())\n\n            # The neural network maps input dimensions to the number of lengthscales\n            # to produce attention weights for each RBF component.\n            # Structure: input_dim -&gt; dim_hidden -&gt; dim_hidden -&gt; num_lengthscales\n            self.nn = NN([num_dim] + hidden_sizes + [self.num_lengthscales],\n                         output_activation_fn='softplus')\n\n    @tf.autograph.experimental.do_not_convert\n    def get_representations(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes normalized latent representations for input data points `X` using the MLP.\n        These representations are used to calculate attention weights for the kernel mixture.\n\n        Args:\n            X (tf.Tensor): (N, D); Input data points. `N` is the number of points,\n                           `D` is the input dimensionality (`num_dim`).\n\n        Returns:\n            tf.Tensor: (N, num_lengthscales); Normalized latent representations for each input point.\n        \"\"\"\n        Z = self.nn(X)\n        # Normalize the representations to have unit L2-norm along the last axis.\n        # This is common in attention mechanisms.\n        representations = Z / tf.norm(Z, axis=1, keepdims=True)\n        return representations\n\n    @tf.autograph.experimental.do_not_convert\n    def K(self, X: tf.Tensor, X2: Optional[tf.Tensor] = None) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the covariance matrix between input data points `X` and `X2`.\n        If `X2` is None, it computes the covariance matrix `K(X, X)`.\n\n        The covariance is calculated as a weighted sum of RBF kernels, where\n        the weights are derived from the attention representations generated by the MLP.\n\n        Formula (simplified):\n        $K(X, X') = \\text{amplitude} \\times \\text{attention}(X, X') \\times \\sum_{i=1}^{Q} \\text{RBF}(||X-X'||, \\text{lengthscale}_i) \\times \\text{attention_lengthscale}_i(X,X')$\n        where $\\text{attention}(X, X') = \\text{representation}(X) \\cdot \\text{representation}(X')^T$.\n\n        Args:\n            X (tf.Tensor): (N1, D); Input data points. `N1` is the number of points,\n                           `D` is the input dimensionality.\n            X2 (Optional[tf.Tensor]): (N2, D); Optional second set of input data points.\n                                     If None, `X` is used as `X2`. `N2` is the number of points.\n\n        Returns:\n            tf.Tensor: (N1, N2); The computed covariance matrix.\n        \"\"\"\n        if X2 is None:\n            X2_internal = X\n        else:\n            X2_internal = X2\n\n        # Compute pairwise Euclidean distances between X and X2\n        dist = cdist(X,\n                     X2_internal)  # This returns (N1, N2) Euclidean distances\n\n        # Get normalized latent representations for X and X2\n        repre1 = self.get_representations(X)  # (N1, num_lengthscales)\n        repre2 = self.get_representations(\n            X2_internal)  # (N2, num_lengthscales)\n\n        # Function to compute a single mixture component for the kernel\n        # This function is mapped over each lengthscale index 'i'\n        def get_mixture_component(i: tf.Tensor) -&gt; tf.Tensor:\n            \"\"\"\n            Computes a single RBF mixture component, incorporating attention\n            based on the i-th dimension of the representations.\n            \"\"\"\n            # attention_lengthscales: (N1, N2) matrix\n            # This term scales the RBF based on similarity in the i-th latent dimension.\n            attention_lengthscales = tf.tensordot(repre1[:, i],\n                                                  repre2[:, i],\n                                                  axes=0)\n\n            # rbf(dist, self.lengthscales[i]) computes the RBF kernel for the current lengthscale\n            # Element-wise multiplication with attention_lengthscales applies the attention.\n            cov_mat_component = rbf(\n                dist, self.lengthscales[i]) * attention_lengthscales\n            return cov_mat_component\n\n        # tf.map_fn applies `get_mixture_component` to each lengthscale index.\n        # The result `cov_mat_per_ls` will be (num_lengthscales, N1, N2).\n        cov_mat_per_ls = tf.map_fn(fn=get_mixture_component,\n                                   elems=tf.range(self.num_lengthscales,\n                                                  dtype=tf.int64),\n                                   fn_output_signature=dist.dtype)\n\n        # Sum all mixture components along the first axis to get (N1, N2)\n        cov_mat_summed_components = tf.math.reduce_sum(cov_mat_per_ls, axis=0)\n\n        # Overall attention term based on the dot product of representations\n        # (N1, num_lengthscales) @ (num_lengthscales, N2) -&gt; (N1, N2)\n        attention_inputs = tf.matmul(repre1, repre2, transpose_b=True)\n\n        # Final covariance: Apply the learned amplitude and the overall attention\n        # Element-wise multiplication to scale the summed RBF components\n        final_cov_mat = self._free_amplitude * attention_inputs * cov_mat_summed_components\n\n        return final_cov_mat\n\n    @tf.autograph.experimental.do_not_convert\n    def K_diag(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the diagonal of the covariance matrix `K(X, X)`.\n\n        Args:\n            X (tf.Tensor): (N, D); Input data points. `N` is the number of points.\n\n        Returns:\n            tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the\n                        covariance matrix.\n        \"\"\"\n        return self._free_amplitude * tf.ones((X.shape[0], ), dtype=X.dtype)\n</code></pre>"},{"location":"api/kernels/attentive.html#sgptools.kernels.attentive.Attentive.K","title":"<code>K(X, X2=None)</code>","text":"<p>Computes the covariance matrix between input data points <code>X</code> and <code>X2</code>. If <code>X2</code> is None, it computes the covariance matrix <code>K(X, X)</code>.</p> <p>The covariance is calculated as a weighted sum of RBF kernels, where the weights are derived from the attention representations generated by the MLP.</p> <p>Formula (simplified): \\(K(X, X') =     ext{amplitude}  imes    ext{attention}(X, X')   imes \\sum_{i=1}^{Q}     ext{RBF}(||X-X'||,      ext{lengthscale}_i)     imes    ext{attention_lengthscale}_i(X,X')\\) where $ ext{attention}(X, X') =         ext{representation}(X) \\cdot    ext{representation}(X')^T$.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N1, D); Input data points. <code>N1</code> is the number of points,            <code>D</code> is the input dimensionality.</p> required <code>X2</code> <code>Optional[Tensor]</code> <p>(N2, D); Optional second set of input data points.                      If None, <code>X</code> is used as <code>X2</code>. <code>N2</code> is the number of points.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N1, N2); The computed covariance matrix.</p> Source code in <code>sgptools/kernels/attentive.py</code> <pre><code>@tf.autograph.experimental.do_not_convert\ndef K(self, X: tf.Tensor, X2: Optional[tf.Tensor] = None) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the covariance matrix between input data points `X` and `X2`.\n    If `X2` is None, it computes the covariance matrix `K(X, X)`.\n\n    The covariance is calculated as a weighted sum of RBF kernels, where\n    the weights are derived from the attention representations generated by the MLP.\n\n    Formula (simplified):\n    $K(X, X') = \\text{amplitude} \\times \\text{attention}(X, X') \\times \\sum_{i=1}^{Q} \\text{RBF}(||X-X'||, \\text{lengthscale}_i) \\times \\text{attention_lengthscale}_i(X,X')$\n    where $\\text{attention}(X, X') = \\text{representation}(X) \\cdot \\text{representation}(X')^T$.\n\n    Args:\n        X (tf.Tensor): (N1, D); Input data points. `N1` is the number of points,\n                       `D` is the input dimensionality.\n        X2 (Optional[tf.Tensor]): (N2, D); Optional second set of input data points.\n                                 If None, `X` is used as `X2`. `N2` is the number of points.\n\n    Returns:\n        tf.Tensor: (N1, N2); The computed covariance matrix.\n    \"\"\"\n    if X2 is None:\n        X2_internal = X\n    else:\n        X2_internal = X2\n\n    # Compute pairwise Euclidean distances between X and X2\n    dist = cdist(X,\n                 X2_internal)  # This returns (N1, N2) Euclidean distances\n\n    # Get normalized latent representations for X and X2\n    repre1 = self.get_representations(X)  # (N1, num_lengthscales)\n    repre2 = self.get_representations(\n        X2_internal)  # (N2, num_lengthscales)\n\n    # Function to compute a single mixture component for the kernel\n    # This function is mapped over each lengthscale index 'i'\n    def get_mixture_component(i: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes a single RBF mixture component, incorporating attention\n        based on the i-th dimension of the representations.\n        \"\"\"\n        # attention_lengthscales: (N1, N2) matrix\n        # This term scales the RBF based on similarity in the i-th latent dimension.\n        attention_lengthscales = tf.tensordot(repre1[:, i],\n                                              repre2[:, i],\n                                              axes=0)\n\n        # rbf(dist, self.lengthscales[i]) computes the RBF kernel for the current lengthscale\n        # Element-wise multiplication with attention_lengthscales applies the attention.\n        cov_mat_component = rbf(\n            dist, self.lengthscales[i]) * attention_lengthscales\n        return cov_mat_component\n\n    # tf.map_fn applies `get_mixture_component` to each lengthscale index.\n    # The result `cov_mat_per_ls` will be (num_lengthscales, N1, N2).\n    cov_mat_per_ls = tf.map_fn(fn=get_mixture_component,\n                               elems=tf.range(self.num_lengthscales,\n                                              dtype=tf.int64),\n                               fn_output_signature=dist.dtype)\n\n    # Sum all mixture components along the first axis to get (N1, N2)\n    cov_mat_summed_components = tf.math.reduce_sum(cov_mat_per_ls, axis=0)\n\n    # Overall attention term based on the dot product of representations\n    # (N1, num_lengthscales) @ (num_lengthscales, N2) -&gt; (N1, N2)\n    attention_inputs = tf.matmul(repre1, repre2, transpose_b=True)\n\n    # Final covariance: Apply the learned amplitude and the overall attention\n    # Element-wise multiplication to scale the summed RBF components\n    final_cov_mat = self._free_amplitude * attention_inputs * cov_mat_summed_components\n\n    return final_cov_mat\n</code></pre>"},{"location":"api/kernels/attentive.html#sgptools.kernels.attentive.Attentive.K_diag","title":"<code>K_diag(X)</code>","text":"<p>Computes the diagonal of the covariance matrix <code>K(X, X)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N, D); Input data points. <code>N</code> is the number of points.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the         covariance matrix.</p> Source code in <code>sgptools/kernels/attentive.py</code> <pre><code>@tf.autograph.experimental.do_not_convert\ndef K_diag(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the diagonal of the covariance matrix `K(X, X)`.\n\n    Args:\n        X (tf.Tensor): (N, D); Input data points. `N` is the number of points.\n\n    Returns:\n        tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the\n                    covariance matrix.\n    \"\"\"\n    return self._free_amplitude * tf.ones((X.shape[0], ), dtype=X.dtype)\n</code></pre>"},{"location":"api/kernels/attentive.html#sgptools.kernels.attentive.Attentive.__init__","title":"<code>__init__(lengthscales=None, hidden_sizes=None, amplitude=1.0, num_dim=2)</code>","text":"<p>Initializes the Attentive Kernel.</p> <p>Parameters:</p> Name Type Description Default <code>lengthscales</code> <code>Union[List[float], ndarray]</code> <p>A list or NumPy array of                                         lengthscale values to be used in the                                         RBF mixture components. These lengthscales                                         are not trained by the optimizer.</p> <code>None</code> <code>hidden_sizes</code> <code>List[int]</code> <p>A list where each element specifies the number of hidden units                       in a layer of the MLPs. The length of this list determines                       the number of hidden layers. Defaults to [10, 10].</p> <code>None</code> <code>amplitude</code> <code>float</code> <p>Initial amplitude (variance) of the kernel function.                This parameter is trainable. Defaults to 1.0.</p> <code>1.0</code> <code>num_dim</code> <code>int</code> <p>The dimensionality of the input data points (e.g., 2 for 2D data).            Defaults to 2.</p> <code>2</code> Usage <pre><code>import gpflow\nimport numpy as np\nfrom sgptools.kernels.attentive import Attentive\n\n# Example: 10 fixed lengthscales ranging from 0.01 to 2.0\nl_scales = np.linspace(0.01, 2.0, 10).astype(np.float32)\n\n# Initialize Attentive Kernel for 2D data\nkernel = Attentive(lengthscales=l_scales, hidden_sizes=[10, 10], num_dim=2)\n\n# You can then use this kernel in a GPflow model:\n# model = gpflow.models.GPR(data=(X_train, Y_train), kernel=kernel, noise_variance=0.1)\n# optimize_model(model)\n</code></pre> Source code in <code>sgptools/kernels/attentive.py</code> <pre><code>def __init__(self,\n             lengthscales: Union[List[float], np.ndarray] = None,\n             hidden_sizes: List[int] = None,\n             amplitude: float = 1.0,\n             num_dim: int = 2):\n    \"\"\"\n    Initializes the Attentive Kernel.\n\n    Args:\n        lengthscales (Union[List[float], np.ndarray]): A list or NumPy array of\n                                                    lengthscale values to be used in the\n                                                    RBF mixture components. These lengthscales\n                                                    are not trained by the optimizer.\n        hidden_sizes (List[int]): A list where each element specifies the number of hidden units\n                                  in a layer of the MLPs. The length of this list determines\n                                  the number of hidden layers. Defaults to [10, 10].\n        amplitude (float): Initial amplitude (variance) of the kernel function.\n                           This parameter is trainable. Defaults to 1.0.\n        num_dim (int): The dimensionality of the input data points (e.g., 2 for 2D data).\n                       Defaults to 2.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        from sgptools.kernels.attentive import Attentive\n\n        # Example: 10 fixed lengthscales ranging from 0.01 to 2.0\n        l_scales = np.linspace(0.01, 2.0, 10).astype(np.float32)\n\n        # Initialize Attentive Kernel for 2D data\n        kernel = Attentive(lengthscales=l_scales, hidden_sizes=[10, 10], num_dim=2)\n\n        # You can then use this kernel in a GPflow model:\n        # model = gpflow.models.GPR(data=(X_train, Y_train), kernel=kernel, noise_variance=0.1)\n        # optimize_model(model)\n        ```\n    \"\"\"\n    super().__init__()\n    if lengthscales is None:\n        lengthscales = np.linspace(0.01, 2.0, 10)\n\n    if hidden_sizes is None:\n        hidden_sizes = [10, 10]  # Default if not provided\n    else:\n        hidden_sizes = list(hidden_sizes)\n\n    with self.name_scope:\n        self.num_lengthscales = len(lengthscales)\n        self._free_amplitude = tf.Variable(amplitude,\n                                           shape=[],\n                                           trainable=True,\n                                           dtype=default_float())\n        # Lengthscales are treated as fixed parameters in this implementation\n        self.lengthscales = tf.Variable(\n            tf.cast(lengthscales, default_float()),\n            shape=[self.num_lengthscales],\n            trainable=False,  # Not trainable\n            dtype=default_float())\n\n        # The neural network maps input dimensions to the number of lengthscales\n        # to produce attention weights for each RBF component.\n        # Structure: input_dim -&gt; dim_hidden -&gt; dim_hidden -&gt; num_lengthscales\n        self.nn = NN([num_dim] + hidden_sizes + [self.num_lengthscales],\n                     output_activation_fn='softplus')\n</code></pre>"},{"location":"api/kernels/attentive.html#sgptools.kernels.attentive.Attentive.get_representations","title":"<code>get_representations(X)</code>","text":"<p>Computes normalized latent representations for input data points <code>X</code> using the MLP. These representations are used to calculate attention weights for the kernel mixture.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N, D); Input data points. <code>N</code> is the number of points,            <code>D</code> is the input dimensionality (<code>num_dim</code>).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N, num_lengthscales); Normalized latent representations for each input point.</p> Source code in <code>sgptools/kernels/attentive.py</code> <pre><code>@tf.autograph.experimental.do_not_convert\ndef get_representations(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes normalized latent representations for input data points `X` using the MLP.\n    These representations are used to calculate attention weights for the kernel mixture.\n\n    Args:\n        X (tf.Tensor): (N, D); Input data points. `N` is the number of points,\n                       `D` is the input dimensionality (`num_dim`).\n\n    Returns:\n        tf.Tensor: (N, num_lengthscales); Normalized latent representations for each input point.\n    \"\"\"\n    Z = self.nn(X)\n    # Normalize the representations to have unit L2-norm along the last axis.\n    # This is common in attention mechanisms.\n    representations = Z / tf.norm(Z, axis=1, keepdims=True)\n    return representations\n</code></pre>"},{"location":"api/kernels/neural_network.html","title":"Neural Network","text":"<p>               Bases: <code>Module</code></p> <p>A Multi-Layer Perceptron (MLP) model that is compatible with GPFlow, allowing its parameters (weights and biases) to be optimized as part of a GPflow model (e.g., within a custom kernel).</p> <p>The network consists of multiple fully connected (dense) layers with specified activation functions.</p> <p>Attributes:</p> Name Type Description <code>dims</code> <code>List[int]</code> <p>List of layer sizes, including input and output dimensions.</p> <code>activation_fn</code> <code>Callable</code> <p>Activation function for hidden layers.</p> <code>output_activation_fn</code> <code>Callable</code> <p>Activation function for the output layer.</p> <code>_weights</code> <code>List[Variable]</code> <p>List of TensorFlow Variable for weights of each layer.</p> <code>_biases</code> <code>List[Variable]</code> <p>List of TensorFlow Variable for biases of each layer.</p> Source code in <code>sgptools/kernels/neural_network.py</code> <pre><code>class NN(gpflow.base.Module):\n    \"\"\"\n    A Multi-Layer Perceptron (MLP) model that is compatible with GPFlow,\n    allowing its parameters (weights and biases) to be optimized as part of\n    a GPflow model (e.g., within a custom kernel).\n\n    The network consists of multiple fully connected (dense) layers with\n    specified activation functions.\n\n    Attributes:\n        dims (List[int]): List of layer sizes, including input and output dimensions.\n        activation_fn (Callable): Activation function for hidden layers.\n        output_activation_fn (Callable): Activation function for the output layer.\n        _weights (List[tf.Variable]): List of TensorFlow Variable for weights of each layer.\n        _biases (List[tf.Variable]): List of TensorFlow Variable for biases of each layer.\n    \"\"\"\n\n    def __init__(self,\n                 dims: List[int],\n                 activation_fn: Union[str, Callable] = 'selu',\n                 output_activation_fn: Union[str, Callable] = 'softmax'):\n        \"\"\"\n        Initializes the Multi-Layer Perceptron (MLP).\n\n        Args:\n            dims (List[int]): A list of integers specifying the size of each layer.\n                              The first element is the input dimension, the last is\n                              the output dimension, and intermediate elements are\n                              hidden layer sizes.\n                              Example: `[input_dim, hidden1_dim, hidden2_dim, output_dim]`\n            activation_fn (Union[str, Callable]): The activation function to use for hidden layers.\n                                                  Can be a string (e.g., 'relu', 'tanh', 'selu')\n                                                  or a callable TensorFlow activation function.\n                                                  Defaults to 'selu'.\n            output_activation_fn (Union[str, Callable]): The activation function to use for the output layer.\n                                                        Can be a string (e.g., 'softmax', 'sigmoid', 'softplus')\n                                                        or a callable TensorFlow activation function.\n                                                        Defaults to 'softplus'.\n\n        Usage:\n            ```python\n            from sgptools.kernels.neural_network import NN\n            import tensorflow as tf\n            import numpy as np\n\n            # Example: A simple MLP with one hidden layer\n            mlp = NN(dims=[2, 10, 1], activation_fn='tanh', output_activation_fn='sigmoid')\n\n            # Input data\n            input_data = tf.constant(np.random.rand(5, 2), dtype=tf.float32)\n\n            # Pass input through the network\n            output = mlp(input_data)\n            ```\n        \"\"\"\n        super().__init__()\n        self.dims = dims\n        # Get TensorFlow activation functions from strings or use provided callables\n        self.activation_fn = tf.keras.activations.get(\n            activation_fn) if isinstance(activation_fn, str) else activation_fn\n        self.output_activation_fn = tf.keras.activations.get(\n            output_activation_fn) if isinstance(output_activation_fn,\n                                                str) else output_activation_fn\n\n        self._weights: List[tf.Variable] = []\n        self._biases: List[tf.Variable] = []\n\n        # Create weights and biases for each layer\n        for i, (dim_in, dim_out) in enumerate(zip(dims[:-1], dims[1:])):\n            # Use Xavier initialization for weights\n            weight_init = xavier(dim_in, dim_out)\n            self._weights.append(\n                tf.Variable(weight_init, dtype=default_float(), name=f'W_{i}'))\n\n            # Initialize biases to zeros\n            bias_init = np.zeros(dim_out, dtype=default_float())\n            self._biases.append(\n                tf.Variable(bias_init, dtype=default_float(), name=f'b_{i}'))\n\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Performs a forward pass through the MLP.\n\n        Args:\n            X (tf.Tensor): (N, D_in); The input tensor to the MLP. `N` is the batch size,\n                           `D_in` is the input dimension of the network.\n\n        Returns:\n            tf.Tensor: (N, D_out); The output tensor from the MLP. `D_out` is the output\n                       dimension of the network.\n        \"\"\"\n        # Process through hidden layers\n        # The loop runs for (num_layers - 1) iterations, covering all hidden layers\n        # and the input-to-first-hidden layer transition.\n        for i in range(len(self.dims) -\n                       2):  # Iterate up to second to last layer\n            W = self._weights[i]\n            b = self._biases[i]\n            X = self.activation_fn(tf.matmul(X, W) + b)\n\n        # Process through the last layer (output layer)\n        W_last = self._weights[-1]  # Weights for the last layer\n        b_last = self._biases[-1]  # Biases for the last layer\n        X = self.output_activation_fn(tf.matmul(X, W_last) + b_last)\n\n        return X\n</code></pre>"},{"location":"api/kernels/neural_network.html#sgptools.kernels.neural_network.NN.__call__","title":"<code>__call__(X)</code>","text":"<p>Performs a forward pass through the MLP.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N, D_in); The input tensor to the MLP. <code>N</code> is the batch size,            <code>D_in</code> is the input dimension of the network.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N, D_out); The output tensor from the MLP. <code>D_out</code> is the output        dimension of the network.</p> Source code in <code>sgptools/kernels/neural_network.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Performs a forward pass through the MLP.\n\n    Args:\n        X (tf.Tensor): (N, D_in); The input tensor to the MLP. `N` is the batch size,\n                       `D_in` is the input dimension of the network.\n\n    Returns:\n        tf.Tensor: (N, D_out); The output tensor from the MLP. `D_out` is the output\n                   dimension of the network.\n    \"\"\"\n    # Process through hidden layers\n    # The loop runs for (num_layers - 1) iterations, covering all hidden layers\n    # and the input-to-first-hidden layer transition.\n    for i in range(len(self.dims) -\n                   2):  # Iterate up to second to last layer\n        W = self._weights[i]\n        b = self._biases[i]\n        X = self.activation_fn(tf.matmul(X, W) + b)\n\n    # Process through the last layer (output layer)\n    W_last = self._weights[-1]  # Weights for the last layer\n    b_last = self._biases[-1]  # Biases for the last layer\n    X = self.output_activation_fn(tf.matmul(X, W_last) + b_last)\n\n    return X\n</code></pre>"},{"location":"api/kernels/neural_network.html#sgptools.kernels.neural_network.NN.__init__","title":"<code>__init__(dims, activation_fn='selu', output_activation_fn='softmax')</code>","text":"<p>Initializes the Multi-Layer Perceptron (MLP).</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>List[int]</code> <p>A list of integers specifying the size of each layer.               The first element is the input dimension, the last is               the output dimension, and intermediate elements are               hidden layer sizes.               Example: <code>[input_dim, hidden1_dim, hidden2_dim, output_dim]</code></p> required <code>activation_fn</code> <code>Union[str, Callable]</code> <p>The activation function to use for hidden layers.                                   Can be a string (e.g., 'relu', 'tanh', 'selu')                                   or a callable TensorFlow activation function.                                   Defaults to 'selu'.</p> <code>'selu'</code> <code>output_activation_fn</code> <code>Union[str, Callable]</code> <p>The activation function to use for the output layer.                                         Can be a string (e.g., 'softmax', 'sigmoid', 'softplus')                                         or a callable TensorFlow activation function.                                         Defaults to 'softplus'.</p> <code>'softmax'</code> Usage <pre><code>from sgptools.kernels.neural_network import NN\nimport tensorflow as tf\nimport numpy as np\n\n# Example: A simple MLP with one hidden layer\nmlp = NN(dims=[2, 10, 1], activation_fn='tanh', output_activation_fn='sigmoid')\n\n# Input data\ninput_data = tf.constant(np.random.rand(5, 2), dtype=tf.float32)\n\n# Pass input through the network\noutput = mlp(input_data)\n</code></pre> Source code in <code>sgptools/kernels/neural_network.py</code> <pre><code>def __init__(self,\n             dims: List[int],\n             activation_fn: Union[str, Callable] = 'selu',\n             output_activation_fn: Union[str, Callable] = 'softmax'):\n    \"\"\"\n    Initializes the Multi-Layer Perceptron (MLP).\n\n    Args:\n        dims (List[int]): A list of integers specifying the size of each layer.\n                          The first element is the input dimension, the last is\n                          the output dimension, and intermediate elements are\n                          hidden layer sizes.\n                          Example: `[input_dim, hidden1_dim, hidden2_dim, output_dim]`\n        activation_fn (Union[str, Callable]): The activation function to use for hidden layers.\n                                              Can be a string (e.g., 'relu', 'tanh', 'selu')\n                                              or a callable TensorFlow activation function.\n                                              Defaults to 'selu'.\n        output_activation_fn (Union[str, Callable]): The activation function to use for the output layer.\n                                                    Can be a string (e.g., 'softmax', 'sigmoid', 'softplus')\n                                                    or a callable TensorFlow activation function.\n                                                    Defaults to 'softplus'.\n\n    Usage:\n        ```python\n        from sgptools.kernels.neural_network import NN\n        import tensorflow as tf\n        import numpy as np\n\n        # Example: A simple MLP with one hidden layer\n        mlp = NN(dims=[2, 10, 1], activation_fn='tanh', output_activation_fn='sigmoid')\n\n        # Input data\n        input_data = tf.constant(np.random.rand(5, 2), dtype=tf.float32)\n\n        # Pass input through the network\n        output = mlp(input_data)\n        ```\n    \"\"\"\n    super().__init__()\n    self.dims = dims\n    # Get TensorFlow activation functions from strings or use provided callables\n    self.activation_fn = tf.keras.activations.get(\n        activation_fn) if isinstance(activation_fn, str) else activation_fn\n    self.output_activation_fn = tf.keras.activations.get(\n        output_activation_fn) if isinstance(output_activation_fn,\n                                            str) else output_activation_fn\n\n    self._weights: List[tf.Variable] = []\n    self._biases: List[tf.Variable] = []\n\n    # Create weights and biases for each layer\n    for i, (dim_in, dim_out) in enumerate(zip(dims[:-1], dims[1:])):\n        # Use Xavier initialization for weights\n        weight_init = xavier(dim_in, dim_out)\n        self._weights.append(\n            tf.Variable(weight_init, dtype=default_float(), name=f'W_{i}'))\n\n        # Initialize biases to zeros\n        bias_init = np.zeros(dim_out, dtype=default_float())\n        self._biases.append(\n            tf.Variable(bias_init, dtype=default_float(), name=f'b_{i}'))\n</code></pre>"},{"location":"api/kernels/neural_spectral.html","title":"Neural Kernel","text":""},{"location":"api/kernels/neural_spectral.html#sgptools.kernels.neural_spectral.NeuralSpectral","title":"<code>sgptools.kernels.neural_spectral.NeuralSpectral</code>","text":"<p>               Bases: <code>Kernel</code></p> <p>Neural Spectral Kernel function (non-stationary kernel function). This kernel models non-stationarity by using multiple Multi-Layer Perceptrons (MLPs) to map input locations to frequency, lengthscale, and variance parameters for a mixture of spectral components.</p> <p>Based on the implementation from this repo.</p> Refer to the following papers for more details <ul> <li>Neural Non-Stationary Spectral Kernel [Remes et al., 2018]</li> </ul> <p>Attributes:</p> Name Type Description <code>input_dim</code> <code>int</code> <p>Dimensionality of the input data points.</p> <code>Q</code> <code>int</code> <p>Number of MLP mixture components used in the kernel function.</p> <code>num_hidden</code> <code>int</code> <p>Number of hidden layers in each MLP.</p> <code>freq</code> <code>List[NN]</code> <p>List of MLPs, one for each component, predicting frequencies.</p> <code>length</code> <code>List[NN]</code> <p>List of MLPs, one for each component, predicting lengthscales.</p> <code>var</code> <code>List[NN]</code> <p>List of MLPs, one for each component, predicting variances.</p> Source code in <code>sgptools/kernels/neural_spectral.py</code> <pre><code>class NeuralSpectral(gpflow.kernels.Kernel):\n    \"\"\"\n    Neural Spectral Kernel function (non-stationary kernel function).\n    This kernel models non-stationarity by using multiple Multi-Layer Perceptrons (MLPs)\n    to map input locations to frequency, lengthscale, and variance parameters for a\n    mixture of spectral components.\n\n    Based on the implementation from this [repo](https://github.com/sremes/nssm-gp/tree/master?tab=readme-ov-file).\n\n    Refer to the following papers for more details:\n        - Neural Non-Stationary Spectral Kernel [Remes et al., 2018]\n\n    Attributes:\n        input_dim (int): Dimensionality of the input data points.\n        Q (int): Number of MLP mixture components used in the kernel function.\n        num_hidden (int): Number of hidden layers in each MLP.\n        freq (List[NN]): List of MLPs, one for each component, predicting frequencies.\n        length (List[NN]): List of MLPs, one for each component, predicting lengthscales.\n        var (List[NN]): List of MLPs, one for each component, predicting variances.\n    \"\"\"\n\n    def __init__(self,\n                 input_dim: int = 2,\n                 active_dims: Optional[List[int]] = None,\n                 Q: int = 1,\n                 hidden_sizes: List[int] = None):\n        \"\"\"\n        Initializes the Neural Spectral Kernel.\n\n        Args:\n            input_dim (int): Number of dimensions of the input data points (e.g., 2 for 2D data).\n            active_dims (Optional[List[int]]): A list of indices specifying which input dimensions\n                                                the kernel operates on. If None, all dimensions are active.\n                                                Defaults to None.\n            Q (int): The number of MLP mixture components used in the kernel function.\n                     Each component has its own set of MLPs for frequency, lengthscale, and variance.\n                     Defaults to 1.\n            hidden_sizes (List[int]): A list where each element specifies the number of hidden units\n                                      in a layer of the MLPs. The length of this list determines\n                                      the number of hidden layers. Defaults to [32, 32].\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            from sgptools.kernels.neural_spectral import NeuralSpectral\n\n            # Initialize a Neural Spectral Kernel for 2D data with 3 mixture components\n            # and MLPs with 2 hidden layers of 64 units each.\n            kernel = NeuralSpectral(input_dim=2, Q=3, hidden_sizes=[64, 64])\n\n            # You can then use this kernel in a GPflow model:\n            # model = gpflow.models.SGPR(data=(X_train, Y_train), kernel=kernel, ...)\n            ```\n        \"\"\"\n        super().__init__(active_dims=active_dims)\n\n        if hidden_sizes is None:\n            hidden_sizes = [32, 32]  # Default if not provided\n        else:\n            hidden_sizes = list(hidden_sizes)\n\n        self.input_dim = input_dim\n        self.Q = Q\n        self.num_hidden = len(hidden_sizes)\n\n        # Initialize lists of MLPs for each component\n        self.freq: List[NN] = []\n        self.length: List[NN] = []\n        self.var: List[NN] = []\n\n        # Create Q sets of MLPs\n        for q in range(self.Q):\n            # MLP for frequency: maps input_dim -&gt; hidden_sizes -&gt; input_dim\n            # Output activation 'softplus' ensures positive frequencies.\n            freq_nn = NN([input_dim] + hidden_sizes + [input_dim],\n                         output_activation_fn='softplus')\n\n            # MLP for lengthscale: maps input_dim -&gt; hidden_sizes -&gt; input_dim\n            # Output activation 'softplus' ensures positive lengthscales.\n            length_nn = NN([input_dim] + hidden_sizes + [input_dim],\n                           output_activation_fn='softplus')\n\n            # MLP for variance: maps input_dim -&gt; hidden_sizes -&gt; 1 (scalar variance)\n            # Output activation 'softplus' ensures positive variances.\n            var_nn = NN([input_dim] + hidden_sizes + [1],\n                        output_activation_fn='softplus')\n\n            self.freq.append(freq_nn)\n            self.length.append(length_nn)\n            self.var.append(var_nn)\n\n    @tf.autograph.experimental.do_not_convert\n    def K(self, X: tf.Tensor, X2: Optional[tf.Tensor] = None) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the covariance matrix between/amongst the input variables `X` and `X2`.\n        If `X2` is None, the function computes `K(X, X)` (a symmetric covariance matrix).\n        Otherwise, it computes `K(X, X2)` (a cross-covariance matrix).\n\n        The kernel is a sum over `Q` mixture components, where each component's\n        parameters (frequency, lengthscale, variance) are determined by MLPs\n        based on the input locations.\n\n        Args:\n            X (tf.Tensor): (N1, D); First set of input variables to compute covariance from.\n                           `N1` is the number of points, `D` is the dimensionality.\n            X2 (Optional[tf.Tensor]): (N2, D); Optional second set of input variables.\n                                     If provided, computes cross-covariance `K(X, X2)`.\n                                     If None, computes auto-covariance `K(X, X)`.\n\n        Returns:\n            tf.Tensor: (N1, N2); The computed covariance matrix. If `X2` is None, the\n                       diagonal of `K(X, X)` is jittered for numerical stability.\n        \"\"\"\n        if X2 is None:\n            X2_internal = X\n            equal = True  # Flag to add jitter to diagonal for K(X,X)\n        else:\n            X2_internal = X2\n            equal = False\n\n        kern = tf.constant(0.0, dtype=default_float())  # Initialize kernel sum\n\n        for q in range(self.Q):\n            # Compute latent function values (frequencies, lengthscales, variances)\n            # by passing input locations through the MLPs.\n            freq_X, freq_X2 = self.freq[q](X), self.freq[q](\n                X2_internal)  # (N, D) frequencies\n            lens_X, lens_X2 = self.length[q](X), self.length[q](\n                X2_internal)  # (N, D) lengthscales\n            var_X, var_X2 = self.var[q](X), self.var[q](\n                X2_internal)  # (N, 1) variances\n\n            # Compute length-scale term (E) - based on inverse lengthscales and distances\n            Xr = tf.expand_dims(X, 1)  # (N1, 1, D)\n            X2r = tf.expand_dims(X2_internal, 0)  # (1, N2, D)\n            l1 = tf.expand_dims(lens_X, 1)  # (N1, 1, D)\n            l2 = tf.expand_dims(lens_X2, 0)  # (1, N2, D)\n\n            L = tf.square(l1) + tf.square(\n                l2)  # (N1, N2, D) - sum of squared lengthscales\n\n            # D term: Squared difference scaled by L, summed over dimensions\n            D_term = tf.square(Xr - X2r) / L  # (N1, N2, D)\n            D_term = tf.reduce_sum(D_term, 2)  # (N1, N2) - sum over dimensions\n\n            # Determinant term: Product over dimensions of (2 * l1 * l2 / L)^(1/2)\n            det_term = tf.sqrt(2 * l1 * l2 / L)  # (N1, N2, D)\n            det_term = tf.reduce_prod(det_term,\n                                      2)  # (N1, N2) - product over dimensions\n\n            # E term: Combine determinant and exponential of D_term\n            E = det_term * tf.exp(-D_term)  # (N1, N2)\n\n            # Compute cosine term (COS) - based on frequencies and dot products with X\n            # (N1, D) * (N1, D) -&gt; sum over D -&gt; (N1, 1)\n            muX = (tf.reduce_sum(freq_X * X, 1, keepdims=True) - tf.transpose(\n                tf.reduce_sum(freq_X2 * X2_internal, 1, keepdims=True)))\n            COS = tf.cos(2 * np.pi * muX)  # (N1, N2)\n\n            # Compute kernel variance term (WW) - outer product of variance predictions\n            WW = tf.matmul(var_X, var_X2,\n                           transpose_b=True)  # (N1, 1) @ (1, N2) -&gt; (N1, N2)\n\n            # Compute the q'th kernel component and add to total kernel\n            kern += WW * E * COS\n\n        # Add jitter to the diagonal for K(X,X) matrices for numerical stability\n        if equal:\n            return robust_kernel(kern, tf.shape(X)[0])\n        else:\n            return kern\n\n    @tf.autograph.experimental.do_not_convert\n    def K_diag(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the diagonal of the covariance matrix `K(X, X)`.\n        For the Neural Spectral Kernel, this is `sum_q(var_q(X)^2) + jitter`.\n\n        Args:\n            X (tf.Tensor): (N, D); Input data points. `N` is the number of points.\n\n        Returns:\n            tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the\n                        covariance matrix.\n        \"\"\"\n        kd = default_jitter()  # Initialize with a small jitter\n        for q in range(self.Q):\n            # Sum of squared variance predictions from each MLP component\n            kd += tf.square(self.var[q](X))\n        return tf.squeeze(\n            kd)  # Remove singleton dimension (e.g., (N, 1) -&gt; (N,))\n</code></pre>"},{"location":"api/kernels/neural_spectral.html#sgptools.kernels.neural_spectral.NeuralSpectral.K","title":"<code>K(X, X2=None)</code>","text":"<p>Computes the covariance matrix between/amongst the input variables <code>X</code> and <code>X2</code>. If <code>X2</code> is None, the function computes <code>K(X, X)</code> (a symmetric covariance matrix). Otherwise, it computes <code>K(X, X2)</code> (a cross-covariance matrix).</p> <p>The kernel is a sum over <code>Q</code> mixture components, where each component's parameters (frequency, lengthscale, variance) are determined by MLPs based on the input locations.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N1, D); First set of input variables to compute covariance from.            <code>N1</code> is the number of points, <code>D</code> is the dimensionality.</p> required <code>X2</code> <code>Optional[Tensor]</code> <p>(N2, D); Optional second set of input variables.                      If provided, computes cross-covariance <code>K(X, X2)</code>.                      If None, computes auto-covariance <code>K(X, X)</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N1, N2); The computed covariance matrix. If <code>X2</code> is None, the        diagonal of <code>K(X, X)</code> is jittered for numerical stability.</p> Source code in <code>sgptools/kernels/neural_spectral.py</code> <pre><code>@tf.autograph.experimental.do_not_convert\ndef K(self, X: tf.Tensor, X2: Optional[tf.Tensor] = None) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the covariance matrix between/amongst the input variables `X` and `X2`.\n    If `X2` is None, the function computes `K(X, X)` (a symmetric covariance matrix).\n    Otherwise, it computes `K(X, X2)` (a cross-covariance matrix).\n\n    The kernel is a sum over `Q` mixture components, where each component's\n    parameters (frequency, lengthscale, variance) are determined by MLPs\n    based on the input locations.\n\n    Args:\n        X (tf.Tensor): (N1, D); First set of input variables to compute covariance from.\n                       `N1` is the number of points, `D` is the dimensionality.\n        X2 (Optional[tf.Tensor]): (N2, D); Optional second set of input variables.\n                                 If provided, computes cross-covariance `K(X, X2)`.\n                                 If None, computes auto-covariance `K(X, X)`.\n\n    Returns:\n        tf.Tensor: (N1, N2); The computed covariance matrix. If `X2` is None, the\n                   diagonal of `K(X, X)` is jittered for numerical stability.\n    \"\"\"\n    if X2 is None:\n        X2_internal = X\n        equal = True  # Flag to add jitter to diagonal for K(X,X)\n    else:\n        X2_internal = X2\n        equal = False\n\n    kern = tf.constant(0.0, dtype=default_float())  # Initialize kernel sum\n\n    for q in range(self.Q):\n        # Compute latent function values (frequencies, lengthscales, variances)\n        # by passing input locations through the MLPs.\n        freq_X, freq_X2 = self.freq[q](X), self.freq[q](\n            X2_internal)  # (N, D) frequencies\n        lens_X, lens_X2 = self.length[q](X), self.length[q](\n            X2_internal)  # (N, D) lengthscales\n        var_X, var_X2 = self.var[q](X), self.var[q](\n            X2_internal)  # (N, 1) variances\n\n        # Compute length-scale term (E) - based on inverse lengthscales and distances\n        Xr = tf.expand_dims(X, 1)  # (N1, 1, D)\n        X2r = tf.expand_dims(X2_internal, 0)  # (1, N2, D)\n        l1 = tf.expand_dims(lens_X, 1)  # (N1, 1, D)\n        l2 = tf.expand_dims(lens_X2, 0)  # (1, N2, D)\n\n        L = tf.square(l1) + tf.square(\n            l2)  # (N1, N2, D) - sum of squared lengthscales\n\n        # D term: Squared difference scaled by L, summed over dimensions\n        D_term = tf.square(Xr - X2r) / L  # (N1, N2, D)\n        D_term = tf.reduce_sum(D_term, 2)  # (N1, N2) - sum over dimensions\n\n        # Determinant term: Product over dimensions of (2 * l1 * l2 / L)^(1/2)\n        det_term = tf.sqrt(2 * l1 * l2 / L)  # (N1, N2, D)\n        det_term = tf.reduce_prod(det_term,\n                                  2)  # (N1, N2) - product over dimensions\n\n        # E term: Combine determinant and exponential of D_term\n        E = det_term * tf.exp(-D_term)  # (N1, N2)\n\n        # Compute cosine term (COS) - based on frequencies and dot products with X\n        # (N1, D) * (N1, D) -&gt; sum over D -&gt; (N1, 1)\n        muX = (tf.reduce_sum(freq_X * X, 1, keepdims=True) - tf.transpose(\n            tf.reduce_sum(freq_X2 * X2_internal, 1, keepdims=True)))\n        COS = tf.cos(2 * np.pi * muX)  # (N1, N2)\n\n        # Compute kernel variance term (WW) - outer product of variance predictions\n        WW = tf.matmul(var_X, var_X2,\n                       transpose_b=True)  # (N1, 1) @ (1, N2) -&gt; (N1, N2)\n\n        # Compute the q'th kernel component and add to total kernel\n        kern += WW * E * COS\n\n    # Add jitter to the diagonal for K(X,X) matrices for numerical stability\n    if equal:\n        return robust_kernel(kern, tf.shape(X)[0])\n    else:\n        return kern\n</code></pre>"},{"location":"api/kernels/neural_spectral.html#sgptools.kernels.neural_spectral.NeuralSpectral.K_diag","title":"<code>K_diag(X)</code>","text":"<p>Computes the diagonal of the covariance matrix <code>K(X, X)</code>. For the Neural Spectral Kernel, this is <code>sum_q(var_q(X)^2) + jitter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>(N, D); Input data points. <code>N</code> is the number of points.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the         covariance matrix.</p> Source code in <code>sgptools/kernels/neural_spectral.py</code> <pre><code>@tf.autograph.experimental.do_not_convert\ndef K_diag(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the diagonal of the covariance matrix `K(X, X)`.\n    For the Neural Spectral Kernel, this is `sum_q(var_q(X)^2) + jitter`.\n\n    Args:\n        X (tf.Tensor): (N, D); Input data points. `N` is the number of points.\n\n    Returns:\n        tf.Tensor: (N,); A 1D tensor representing the diagonal elements of the\n                    covariance matrix.\n    \"\"\"\n    kd = default_jitter()  # Initialize with a small jitter\n    for q in range(self.Q):\n        # Sum of squared variance predictions from each MLP component\n        kd += tf.square(self.var[q](X))\n    return tf.squeeze(\n        kd)  # Remove singleton dimension (e.g., (N, 1) -&gt; (N,))\n</code></pre>"},{"location":"api/kernels/neural_spectral.html#sgptools.kernels.neural_spectral.NeuralSpectral.__init__","title":"<code>__init__(input_dim=2, active_dims=None, Q=1, hidden_sizes=None)</code>","text":"<p>Initializes the Neural Spectral Kernel.</p> <p>Parameters:</p> Name Type Description Default <code>input_dim</code> <code>int</code> <p>Number of dimensions of the input data points (e.g., 2 for 2D data).</p> <code>2</code> <code>active_dims</code> <code>Optional[List[int]]</code> <p>A list of indices specifying which input dimensions                                 the kernel operates on. If None, all dimensions are active.                                 Defaults to None.</p> <code>None</code> <code>Q</code> <code>int</code> <p>The number of MLP mixture components used in the kernel function.      Each component has its own set of MLPs for frequency, lengthscale, and variance.      Defaults to 1.</p> <code>1</code> <code>hidden_sizes</code> <code>List[int]</code> <p>A list where each element specifies the number of hidden units                       in a layer of the MLPs. The length of this list determines                       the number of hidden layers. Defaults to [32, 32].</p> <code>None</code> Usage <pre><code>import gpflow\nimport numpy as np\nfrom sgptools.kernels.neural_spectral import NeuralSpectral\n\n# Initialize a Neural Spectral Kernel for 2D data with 3 mixture components\n# and MLPs with 2 hidden layers of 64 units each.\nkernel = NeuralSpectral(input_dim=2, Q=3, hidden_sizes=[64, 64])\n\n# You can then use this kernel in a GPflow model:\n# model = gpflow.models.SGPR(data=(X_train, Y_train), kernel=kernel, ...)\n</code></pre> Source code in <code>sgptools/kernels/neural_spectral.py</code> <pre><code>def __init__(self,\n             input_dim: int = 2,\n             active_dims: Optional[List[int]] = None,\n             Q: int = 1,\n             hidden_sizes: List[int] = None):\n    \"\"\"\n    Initializes the Neural Spectral Kernel.\n\n    Args:\n        input_dim (int): Number of dimensions of the input data points (e.g., 2 for 2D data).\n        active_dims (Optional[List[int]]): A list of indices specifying which input dimensions\n                                            the kernel operates on. If None, all dimensions are active.\n                                            Defaults to None.\n        Q (int): The number of MLP mixture components used in the kernel function.\n                 Each component has its own set of MLPs for frequency, lengthscale, and variance.\n                 Defaults to 1.\n        hidden_sizes (List[int]): A list where each element specifies the number of hidden units\n                                  in a layer of the MLPs. The length of this list determines\n                                  the number of hidden layers. Defaults to [32, 32].\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        from sgptools.kernels.neural_spectral import NeuralSpectral\n\n        # Initialize a Neural Spectral Kernel for 2D data with 3 mixture components\n        # and MLPs with 2 hidden layers of 64 units each.\n        kernel = NeuralSpectral(input_dim=2, Q=3, hidden_sizes=[64, 64])\n\n        # You can then use this kernel in a GPflow model:\n        # model = gpflow.models.SGPR(data=(X_train, Y_train), kernel=kernel, ...)\n        ```\n    \"\"\"\n    super().__init__(active_dims=active_dims)\n\n    if hidden_sizes is None:\n        hidden_sizes = [32, 32]  # Default if not provided\n    else:\n        hidden_sizes = list(hidden_sizes)\n\n    self.input_dim = input_dim\n    self.Q = Q\n    self.num_hidden = len(hidden_sizes)\n\n    # Initialize lists of MLPs for each component\n    self.freq: List[NN] = []\n    self.length: List[NN] = []\n    self.var: List[NN] = []\n\n    # Create Q sets of MLPs\n    for q in range(self.Q):\n        # MLP for frequency: maps input_dim -&gt; hidden_sizes -&gt; input_dim\n        # Output activation 'softplus' ensures positive frequencies.\n        freq_nn = NN([input_dim] + hidden_sizes + [input_dim],\n                     output_activation_fn='softplus')\n\n        # MLP for lengthscale: maps input_dim -&gt; hidden_sizes -&gt; input_dim\n        # Output activation 'softplus' ensures positive lengthscales.\n        length_nn = NN([input_dim] + hidden_sizes + [input_dim],\n                       output_activation_fn='softplus')\n\n        # MLP for variance: maps input_dim -&gt; hidden_sizes -&gt; 1 (scalar variance)\n        # Output activation 'softplus' ensures positive variances.\n        var_nn = NN([input_dim] + hidden_sizes + [1],\n                    output_activation_fn='softplus')\n\n        self.freq.append(freq_nn)\n        self.length.append(length_nn)\n        self.var.append(var_nn)\n</code></pre>"},{"location":"api/kernels/neural_spectral.html#sgptools.kernels.neural_spectral.init_neural_kernel","title":"<code>sgptools.kernels.neural_spectral.init_neural_kernel(X_train, Y_train, inducing_variable, Q, n_inits=1, hidden_sizes=None)</code>","text":"<p>Helper function to initialize a Sparse Gaussian Process Regression (SGPR) model with a Neural Spectral Kernel. This function can perform multiple random initializations and return the model with the best initial Evidence Lower Bound (ELBO).</p> Refer to the original paper for more details <ul> <li>Neural Non-Stationary Spectral Kernel [Remes et al., 2018]</li> </ul> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>ndarray</code> <p>(n, d); Input training set points.</p> required <code>Y_train</code> <code>ndarray</code> <p>(n, 1); Training set labels.</p> required <code>inducing_variable</code> <code>ndarray</code> <p>(m, d); Initial inducing points. These are passed                             directly to the SGPR model.</p> required <code>Q</code> <code>int</code> <p>The number of MLP mixture components for the Neural Spectral Kernel.</p> required <code>n_inits</code> <code>int</code> <p>Number of times to randomly initialize the kernel's MLPs and            compute the initial ELBO. The model with the highest ELBO            among these initializations is returned. Defaults to 1.</p> <code>1</code> <code>hidden_sizes</code> <code>Optional[List[int]]</code> <p>List of integers specifying the number of hidden                                 units in each MLP layer. If None, [32, 32] is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SGPR</code> <code>SGPR</code> <p>The SGPR model instance initialized with the Neural Spectral Kernel   that yielded the best initial ELBO.</p> Usage <pre><code>import numpy as np\nimport gpflow\nfrom sgptools.kernels.neural_spectral import init_neural_kernel\nfrom sgptools.utils.misc import get_inducing_pts # For initial inducing points\n\n# Dummy data\nX_train_data = np.random.rand(100, 2).astype(np.float32)\nY_train_data = (np.sin(X_train_data[:, 0]) + np.cos(X_train_data[:, 1]))[:, None].astype(np.float32)\n\n# Initial inducing points (e.g., subset of training data or k-means centers)\ninitial_inducing_points = get_inducing_pts(X_train_data, num_inducing=20)\n\n# Initialize the SGPR model with Neural Spectral Kernel\n# Try 3 random initializations for the MLPs.\nmodel_ns_kernel = init_neural_kernel(\n    X_train=X_train_data,\n    Y_train=Y_train_data,\n    inducing_variable=initial_inducing_points,\n    Q=5,              # 5 mixture components\n    n_inits=3,        # 3 initializations\n    hidden_sizes=[16, 16] # Custom hidden layer sizes\n)\n\n# You would typically optimize this model further using optimize_model:\n# from sgptools.utils.gpflow import optimize_model\n# optimize_model(model_ns_kernel)\n</code></pre> Source code in <code>sgptools/kernels/neural_spectral.py</code> <pre><code>def init_neural_kernel(X_train: np.ndarray,\n                       Y_train: np.ndarray,\n                       inducing_variable: np.ndarray,\n                       Q: int,\n                       n_inits: int = 1,\n                       hidden_sizes: Optional[List[int]] = None) -&gt; SGPR:\n    \"\"\"\n    Helper function to initialize a Sparse Gaussian Process Regression (SGPR) model\n    with a Neural Spectral Kernel. This function can perform multiple random\n    initializations and return the model with the best initial Evidence Lower Bound (ELBO).\n\n    Refer to the original paper for more details:\n        - Neural Non-Stationary Spectral Kernel [Remes et al., 2018]\n\n    Args:\n        X_train (np.ndarray): (n, d); Input training set points.\n        Y_train (np.ndarray): (n, 1); Training set labels.\n        inducing_variable (np.ndarray): (m, d); Initial inducing points. These are passed\n                                        directly to the SGPR model.\n        Q (int): The number of MLP mixture components for the Neural Spectral Kernel.\n        n_inits (int): Number of times to randomly initialize the kernel's MLPs and\n                       compute the initial ELBO. The model with the highest ELBO\n                       among these initializations is returned. Defaults to 1.\n        hidden_sizes (Optional[List[int]]): List of integers specifying the number of hidden\n                                            units in each MLP layer. If None, [32, 32] is used.\n\n    Returns:\n        SGPR: The SGPR model instance initialized with the Neural Spectral Kernel\n              that yielded the best initial ELBO.\n\n    Usage:\n        ```python\n        import numpy as np\n        import gpflow\n        from sgptools.kernels.neural_spectral import init_neural_kernel\n        from sgptools.utils.misc import get_inducing_pts # For initial inducing points\n\n        # Dummy data\n        X_train_data = np.random.rand(100, 2).astype(np.float32)\n        Y_train_data = (np.sin(X_train_data[:, 0]) + np.cos(X_train_data[:, 1]))[:, None].astype(np.float32)\n\n        # Initial inducing points (e.g., subset of training data or k-means centers)\n        initial_inducing_points = get_inducing_pts(X_train_data, num_inducing=20)\n\n        # Initialize the SGPR model with Neural Spectral Kernel\n        # Try 3 random initializations for the MLPs.\n        model_ns_kernel = init_neural_kernel(\n            X_train=X_train_data,\n            Y_train=Y_train_data,\n            inducing_variable=initial_inducing_points,\n            Q=5,              # 5 mixture components\n            n_inits=3,        # 3 initializations\n            hidden_sizes=[16, 16] # Custom hidden layer sizes\n        )\n\n        # You would typically optimize this model further using optimize_model:\n        # from sgptools.utils.gpflow import optimize_model\n        # optimize_model(model_ns_kernel)\n        ```\n    \"\"\"\n    # Convert NumPy arrays to TensorFlow tensors\n    X_train_tf, Y_train_tf = data_input_to_tensor((X_train, Y_train))\n\n    best_loglik = -np.inf  # Track the best ELBO found\n    best_m: Optional[SGPR] = None  # Store the best model\n\n    N, input_dim = X_train_tf.shape  # Get number of data points and input dimensionality\n\n    for k_init_idx in range(n_inits):\n        # Create a new NeuralSpectralKernel instance for each initialization\n        current_kernel = NeuralSpectral(input_dim=input_dim,\n                                        Q=Q,\n                                        hidden_sizes=hidden_sizes)\n\n        # Create an SGPR model with the current kernel initialization\n        model = SGPR(data=(X_train_tf, Y_train_tf),\n                     inducing_variable=inducing_variable,\n                     kernel=current_kernel)\n\n        # Compute the initial ELBO (Evidence Lower Bound)\n        loglik = model.elbo()\n\n        # Check if the current initialization is better than previous ones\n        if loglik &gt; best_loglik:\n            best_loglik = loglik\n            # Deepcopy the model to save its state, as it will be deleted/overwritten in next iteration\n            # This requires gpflow.utilities.traversal.deepcopy or similar for GPflow models\n            # For simplicity, we directly assign here, assuming shallow copy is sufficient\n            # or that the user will optimize it later. For robust best model saving, a deepcopy is safer.\n            best_m = model\n\n        # Explicitly delete the model and run garbage collection to free memory\n        # (important if n_inits is large and models are complex)\n        del model\n        gc.collect()\n\n    return best_m\n</code></pre>"},{"location":"api/methods/index.html","title":"<code>methods</code>: Optimization Algorithms","text":"<p>This module provides various algorithms to optimize the sensor placements or paths. Use the <code>get_methods</code> method to retrieve an optimization method class by its string name.</p> <ul> <li> <p><code>ContinuousSGP</code>: This method directly optimizes the inducing points of the <code>AugmentedSGPR</code> model to maximize the Evidence Lower Bound (ELBO). This is the main SGP-based optimization approach proposed in the papers associated with this library.</p> </li> <li> <p><code>GreedySGP</code> and <code>GreedyObjective</code>: These implement greedy algorithms for sensor placement. <code>GreedySGP</code> iteratively selects inducing points to maximize the SGP's ELBO, while <code>GreedyObjective</code> uses a more general objective function like Mutual Information.</p> </li> <li> <p><code>BayesianOpt</code>: This method uses Bayesian Optimization, a powerful black-box optimization algorithm, to find the best sensor locations by maximizing a general objective function.</p> </li> <li> <p><code>CMA</code>: This method uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES), a powerful black-box optimization algorithm, to find the best sensor locations by maximizing a general objective function.</p> </li> <li> <p><code>DifferentiableObjective</code>: This method leverages TensorFlow's automatic differentiation to directly optimize the objective function with respect to the sensor locations. This can be more efficient than black-box methods for smooth objective functions. However, the method is also more prone to getting stuck in local minima.</p> </li> </ul>"},{"location":"api/methods/index.html#sgptools.methods.get_method","title":"<code>sgptools.methods.get_method(method)</code>","text":"<p>Retrieves an optimization method class by its string name.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The name of the optimization method (e.g., 'ContinuousSGP', 'CMA').</p> required <p>Returns:</p> Type Description <code>Type[Method]</code> <p>Type[Method]: The class of the requested optimization method.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the method name is not found.</p> Usage <pre><code># To get the ContinuousSGP class\nContinuousSGPClass = get_method('ContinuousSGP')\n# You can then instantiate it:\n# CSGP_instance = ContinuousSGPClass(...)\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def get_method(method: str) -&gt; Type[Method]:\n    \"\"\"\n    Retrieves an optimization method class by its string name.\n\n    Args:\n        method (str): The name of the optimization method (e.g., 'ContinuousSGP', 'CMA').\n\n    Returns:\n        Type[Method]: The class of the requested optimization method.\n\n    Raises:\n        KeyError: If the method name is not found.\n\n    Usage:\n        ```python\n        # To get the ContinuousSGP class\n        ContinuousSGPClass = get_method('ContinuousSGP')\n        # You can then instantiate it:\n        # CSGP_instance = ContinuousSGPClass(...)\n        ```\n    \"\"\"\n    if method not in METHODS:\n        raise KeyError(f\"Method '{method}' not found. Available methods: {', '.join(METHODS.keys())}\")\n    return METHODS[method]\n</code></pre>"},{"location":"api/methods/bayesian_opt.html","title":"BayesianOpt","text":""},{"location":"api/methods/bayesian_opt.html#sgptools.methods.BayesianOpt","title":"<code>sgptools.methods.BayesianOpt</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path optimization using Bayesian Optimization.</p> <p>This method optimizes a given objective function (e.g., Mutual Information) by sampling and evaluating points in the search space, building a surrogate model, and using an acquisition function to guide further sampling.</p> Refer to the following papers for more details <ul> <li>UAV route planning for active disease classification [Vivaldini et al., 2019]</li> <li>Occupancy map building through Bayesian exploration [Francis et al., 2019]</li> </ul> <p>Attributes:</p> Name Type Description <code>objective</code> <code>Objective</code> <p>The objective function to be optimized.</p> <code>transform</code> <code>Optional[Transform]</code> <p>Transform object applied to inducing points.</p> <code>pbounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Dictionary defining the search space bounds.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class BayesianOpt(Method):\n    \"\"\"\n    Implements informative sensor placement/path optimization using Bayesian Optimization.\n\n    This method optimizes a given objective function (e.g., Mutual Information)\n    by sampling and evaluating points in the search space, building a surrogate\n    model, and using an acquisition function to guide further sampling.\n\n    Refer to the following papers for more details:\n        - UAV route planning for active disease classification [Vivaldini et al., 2019]\n        - Occupancy map building through Bayesian exploration [Francis et al., 2019]\n\n    Attributes:\n        objective (Objective): The objective function to be optimized.\n        transform (Optional[Transform]): Transform object applied to inducing points.\n        pbounds (Dict[str, Tuple[float, float]]): Dictionary defining the search space bounds.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 objective: Union[str, Objective] = 'SLogMI',\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the BayesianOpt optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations to optimize.\n            X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 Defaults to None.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                         or an instance of an objective class. Defaults to 'SLogMI'.\n            **kwargs: Additional keyword arguments passed to the objective function.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        self.transform = transform\n\n        if isinstance(objective, str):\n            self.objective = get_objective(objective)(X_objective, kernel,\n                                                      noise_variance, **kwargs)\n        else:\n            self.objective = objective\n\n        # Use the boundaries of the X_objective area as the search space limits\n        pbounds_dims: List[Tuple[float, float]] = []\n        for i in range(self.num_dim):\n            pbounds_dims.append(\n                (np.min(X_objective[:, i]), np.max(X_objective[:, i])))\n        self.pbounds: Dict[str, Tuple[float, float]] = {}\n        for i in range(self.num_dim * self.num_sensing * self.num_robots):\n            self.pbounds[f'x{i}'] = pbounds_dims[i % self.num_dim]\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the objective function.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.objective.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.objective.kernel), \\\n               self.objective.noise_variance\n\n    def optimize(self,\n                 max_steps: int = 50,\n                 init_points: int = 10,\n                 verbose: bool = False,\n                 seed: Optional[int] = None,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes the sensor placement/path using Bayesian Optimization.\n\n        Args:\n            max_steps (int): Maximum number of optimization steps (iterations). Defaults to 50.\n            init_points (int): Number of random exploration steps before Bayesian Optimization starts. Defaults to 10.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            seed (Optional[int]): Random seed for reproducibility. Defaults to None.\n            **kwargs: Additional keyword arguments for the optimizer.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            bo_method = BayesianOpt(\n                num_sensing=10,\n                X_objective=X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                transform=IPPTransform(num_robots=1), # Example transform\n                X_candidates=candidates\n            )\n            optimized_solution = bo_method.optimize(max_steps=50, init_points=10)\n            ```\n        \"\"\"\n        verbose = 1 if verbose else 0\n        optimizer = BayesianOptimization(f=self._objective,\n                                         pbounds=self.pbounds,\n                                         verbose=verbose,\n                                         random_state=seed,\n                                         allow_duplicate_points=True)\n        optimizer.maximize(init_points=init_points, n_iter=max_steps)\n\n        sol: List[float] = []\n        for i in range(self.num_dim * self.num_sensing * self.num_robots):\n            sol.append(optimizer.max['params'][f'x{i}'])\n\n        sol_np = np.array(sol).reshape(-1, self.num_dim)\n        if self.transform is not None:\n            try:\n                sol_np = self.transform.expand(sol_np,\n                                               expand_sensor_model=False)\n            except TypeError:\n                pass\n\n            if not isinstance(sol_np, np.ndarray):\n                sol_np = sol_np.numpy()\n\n        # Map solution locations to candidates set locations if X_candidates is provided\n        if self.X_candidates is not None:\n            sol_np = cont2disc(sol_np, self.X_candidates)\n\n        sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n        return sol_np\n\n    def _objective(self, **kwargs: float) -&gt; float:\n        \"\"\"\n        Internal objective function to be maximized by the Bayesian Optimization.\n\n        This function reshapes the input parameters from the optimizer, applies\n        any specified transformations, calculates the objective value, and\n        applies a penalty for constraint violations.\n\n        Args:\n            **kwargs: Keyword arguments where keys are 'x0', 'x1', ..., representing\n                      the flattened sensor placement coordinates.\n\n        Returns:\n            float: The objective value (reward - constraint penalty) to be maximized.\n        \"\"\"\n        X_list: List[float] = []\n        for i in range(len(kwargs)):\n            X_list.append(kwargs[f'x{i}'])\n        X = np.array(X_list).reshape(-1, self.num_dim)\n\n        constraint_penality: float = 0.0\n        if self.transform is not None:\n            X_expanded = self.transform.expand(X)\n            constraint_penality = self.transform.constraints(X)\n            reward = self.objective(X_expanded)  # maximize\n        else:\n            reward = self.objective(X)  # maximize\n\n        reward += constraint_penality  # minimize (large negative value when constraint is unsatisfied)\n        return reward.numpy()\n</code></pre>"},{"location":"api/methods/bayesian_opt.html#sgptools.methods.BayesianOpt.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, objective='SLogMI', **kwargs)</code>","text":"<p>Initializes the BayesianOpt optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to optimize.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>objective</code> <code>Union[str, Objective]</code> <p>The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')                          or an instance of an objective class. Defaults to 'SLogMI'.</p> <code>'SLogMI'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the objective function.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             objective: Union[str, Objective] = 'SLogMI',\n             **kwargs: Any):\n    \"\"\"\n    Initializes the BayesianOpt optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations to optimize.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             Defaults to None.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                     or an instance of an objective class. Defaults to 'SLogMI'.\n        **kwargs: Additional keyword arguments passed to the objective function.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    self.transform = transform\n\n    if isinstance(objective, str):\n        self.objective = get_objective(objective)(X_objective, kernel,\n                                                  noise_variance, **kwargs)\n    else:\n        self.objective = objective\n\n    # Use the boundaries of the X_objective area as the search space limits\n    pbounds_dims: List[Tuple[float, float]] = []\n    for i in range(self.num_dim):\n        pbounds_dims.append(\n            (np.min(X_objective[:, i]), np.max(X_objective[:, i])))\n    self.pbounds: Dict[str, Tuple[float, float]] = {}\n    for i in range(self.num_dim * self.num_sensing * self.num_robots):\n        self.pbounds[f'x{i}'] = pbounds_dims[i % self.num_dim]\n</code></pre>"},{"location":"api/methods/bayesian_opt.html#sgptools.methods.BayesianOpt.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the objective.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.objective.kernel), \\\n           self.objective.noise_variance\n</code></pre>"},{"location":"api/methods/bayesian_opt.html#sgptools.methods.BayesianOpt.optimize","title":"<code>optimize(max_steps=50, init_points=10, verbose=False, seed=None, **kwargs)</code>","text":"<p>Optimizes the sensor placement/path using Bayesian Optimization.</p> <p>Parameters:</p> Name Type Description Default <code>max_steps</code> <code>int</code> <p>Maximum number of optimization steps (iterations). Defaults to 50.</p> <code>50</code> <code>init_points</code> <code>int</code> <p>Number of random exploration steps before Bayesian Optimization starts. Defaults to 10.</p> <code>10</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducibility. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the optimizer.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\nbo_method = BayesianOpt(\n    num_sensing=10,\n    X_objective=X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    transform=IPPTransform(num_robots=1), # Example transform\n    X_candidates=candidates\n)\noptimized_solution = bo_method.optimize(max_steps=50, init_points=10)\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             max_steps: int = 50,\n             init_points: int = 10,\n             verbose: bool = False,\n             seed: Optional[int] = None,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes the sensor placement/path using Bayesian Optimization.\n\n    Args:\n        max_steps (int): Maximum number of optimization steps (iterations). Defaults to 50.\n        init_points (int): Number of random exploration steps before Bayesian Optimization starts. Defaults to 10.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        seed (Optional[int]): Random seed for reproducibility. Defaults to None.\n        **kwargs: Additional keyword arguments for the optimizer.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        bo_method = BayesianOpt(\n            num_sensing=10,\n            X_objective=X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            transform=IPPTransform(num_robots=1), # Example transform\n            X_candidates=candidates\n        )\n        optimized_solution = bo_method.optimize(max_steps=50, init_points=10)\n        ```\n    \"\"\"\n    verbose = 1 if verbose else 0\n    optimizer = BayesianOptimization(f=self._objective,\n                                     pbounds=self.pbounds,\n                                     verbose=verbose,\n                                     random_state=seed,\n                                     allow_duplicate_points=True)\n    optimizer.maximize(init_points=init_points, n_iter=max_steps)\n\n    sol: List[float] = []\n    for i in range(self.num_dim * self.num_sensing * self.num_robots):\n        sol.append(optimizer.max['params'][f'x{i}'])\n\n    sol_np = np.array(sol).reshape(-1, self.num_dim)\n    if self.transform is not None:\n        try:\n            sol_np = self.transform.expand(sol_np,\n                                           expand_sensor_model=False)\n        except TypeError:\n            pass\n\n        if not isinstance(sol_np, np.ndarray):\n            sol_np = sol_np.numpy()\n\n    # Map solution locations to candidates set locations if X_candidates is provided\n    if self.X_candidates is not None:\n        sol_np = cont2disc(sol_np, self.X_candidates)\n\n    sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n    return sol_np\n</code></pre>"},{"location":"api/methods/bayesian_opt.html#sgptools.methods.BayesianOpt.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the objective function.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.objective.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/cma.html","title":"CMA","text":""},{"location":"api/methods/cma.html#sgptools.methods.CMA","title":"<code>sgptools.methods.CMA</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path optimization using CMA-ES (Covariance Matrix Adaptation Evolution Strategy).</p> <p>CMA-ES is a powerful black-box optimization algorithm for non-convex problems.</p> Refer to the following paper for more details <ul> <li>Adaptive Continuous-Space Informative Path Planning for Online Environmental Monitoring [Hitz et al., 2017]</li> </ul> <p>Attributes:</p> Name Type Description <code>objective</code> <code>Objective</code> <p>The objective function to be minimized/maximized.</p> <code>transform</code> <code>Optional[Transform]</code> <p>Transform object applied to inducing points.</p> <code>X_init</code> <code>ndarray</code> <p>Initial solution guess for the optimization.</p> <code>pbounds</code> <code>MultiPoint</code> <p>The convex hull of the objective area, used implicitly for bounds.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class CMA(Method):\n    \"\"\"\n    Implements informative sensor placement/path optimization using CMA-ES (Covariance Matrix Adaptation Evolution Strategy).\n\n    CMA-ES is a powerful black-box optimization algorithm for non-convex problems.\n\n    Refer to the following paper for more details:\n        - Adaptive Continuous-Space Informative Path Planning for Online Environmental Monitoring [Hitz et al., 2017]\n\n    Attributes:\n        objective (Objective): The objective function to be minimized/maximized.\n        transform (Optional[Transform]): Transform object applied to inducing points.\n        X_init (np.ndarray): Initial solution guess for the optimization.\n        pbounds (geometry.MultiPoint): The convex hull of the objective area, used implicitly for bounds.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 objective: Union[str, Objective] = 'SLogMI',\n                 X_init: Optional[np.ndarray] = None,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the CMA-ES optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations to optimize.\n            X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 Defaults to None.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                         or an instance of an objective class. Defaults to 'SLogMI'.\n            X_init (Optional[np.ndarray]): (num_sensing * num_robots, num_dim); Initial guess for sensing locations.\n                                            If None, initial points are randomly selected from X_objective.\n            **kwargs: Additional keyword arguments passed to the objective function.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        self.transform = transform\n        if X_init is None:\n            X_init = get_inducing_pts(X_objective,\n                                      num_sensing * self.num_robots)\n        else:\n            # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n            self.num_dim = X_init.shape[-1]\n\n        self.X_init: np.ndarray = X_init.reshape(-1)  # Flattened initial guess\n\n        if isinstance(objective, str):\n            self.objective = get_objective(objective)(X_objective, kernel,\n                                                      noise_variance, **kwargs)\n        else:\n            self.objective = objective\n\n        # Use the boundaries of the X_objective area as the search space limits\n        self.pbounds = geometry.MultiPoint([[p[0], p[1]]\n                                            for p in X_objective]).convex_hull\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the objective function.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.objective.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.objective.kernel), \\\n               self.objective.noise_variance\n\n    def optimize(self,\n                 max_steps: int = 500,\n                 tol: float = 1e-6,\n                 verbose: bool = False,\n                 seed: Optional[int] = None,\n                 restarts: int = 5,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes the sensor placement/path using CMA-ES.\n\n        Args:\n            max_steps (int): Maximum number of optimization steps (function evaluations). Defaults to 500.\n            tol (float): Tolerance for termination. Defaults to 1e-6.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            seed (Optional[int]): Random seed for reproducibility. Defaults to None.\n            restarts (int): Number of restarts for CMA-ES. Defaults to 5.\n            **kwargs: Additional keyword arguments for CMA-ES.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            cma_method = CMA(\n                num_sensing=10,\n                X_objective=X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                transform=IPPTransform(num_robots=1), # Example transform\n                X_candidates=candidates\n            )\n            optimized_solution = cma_method.optimize(max_steps=1000)\n            ```\n        \"\"\"\n        sigma0 = 1.0\n        verbose = 1 if verbose else 0\n        sol, _ = cma.fmin2(self._objective,\n                           self.X_init,\n                           sigma0,\n                           options={\n                               'maxfevals': max_steps,\n                               'verb_disp': verbose,\n                               'tolfun': tol,\n                               'seed': seed\n                           },\n                           restarts=restarts)\n\n        sol_np = np.array(sol).reshape(-1, self.num_dim)\n        if self.transform is not None:\n            try:\n                sol_np = self.transform.expand(sol_np,\n                                               expand_sensor_model=False)\n            except TypeError:\n                pass\n            if not isinstance(sol_np, np.ndarray):\n                sol_np = sol_np.numpy()\n\n        # Map solution locations to candidates set locations if X_candidates is provided\n        if self.X_candidates is not None:\n            sol_np = cont2disc(sol_np, self.X_candidates)\n\n        sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n        return sol_np\n\n    def _objective(self, X: np.ndarray) -&gt; float:\n        \"\"\"\n        Internal objective function to be minimized by CMA-ES.\n\n        This function reshapes the input array, applies any specified transformations,\n        calculates the objective value, and applies a penalty for constraint violations.\n        Note: CMA-ES minimizes, so the reward (which is to be maximized) is returned as negative.\n\n        Args:\n            X (np.ndarray): (num_sensing * num_robots * num_dim); Flattened array of\n                            current solution sensor placement locations.\n\n        Returns:\n            float: The negative objective value (-reward + constraint penalty) to be minimized.\n        \"\"\"\n        X_reshaped = np.array(X).reshape(-1, self.num_dim)\n        constraint_penality: float = 0.0\n        if self.transform is not None:\n            X_expanded = self.transform.expand(X_reshaped)\n            constraint_penality = self.transform.constraints(X_reshaped)\n            reward = self.objective(X_expanded)  # maximize\n        else:\n            reward = self.objective(X_reshaped)  # maximize\n        if not np.isfinite(reward):\n            reward = -1e6 # CMA does not like inf values\n        reward += constraint_penality  # minimize (large negative value when constraint is unsatisfied)\n        return -reward.numpy()  # Return negative as CMA-ES minimizes\n\n    def update_transform(self, transform: Transform) -&gt; None:\n        \"\"\"\n        Updates the transform object used by the CMA-ES optimizer.\n\n        Args:\n            transform (Transform): The new transform object.\n        \"\"\"\n        self.transform = transform\n\n    def get_transform(self) -&gt; Transform:\n        \"\"\"\n        Retrieves a deep copy of the transform object.\n\n        Returns:\n            Transform: A deep copy of the transform object.\n        \"\"\"\n        return deepcopy(self.transform)\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, objective='SLogMI', X_init=None, **kwargs)</code>","text":"<p>Initializes the CMA-ES optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to optimize.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>objective</code> <code>Union[str, Objective]</code> <p>The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')                          or an instance of an objective class. Defaults to 'SLogMI'.</p> <code>'SLogMI'</code> <code>X_init</code> <code>Optional[ndarray]</code> <p>(num_sensing * num_robots, num_dim); Initial guess for sensing locations.                             If None, initial points are randomly selected from X_objective.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the objective function.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             objective: Union[str, Objective] = 'SLogMI',\n             X_init: Optional[np.ndarray] = None,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the CMA-ES optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations to optimize.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             Defaults to None.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                     or an instance of an objective class. Defaults to 'SLogMI'.\n        X_init (Optional[np.ndarray]): (num_sensing * num_robots, num_dim); Initial guess for sensing locations.\n                                        If None, initial points are randomly selected from X_objective.\n        **kwargs: Additional keyword arguments passed to the objective function.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    self.transform = transform\n    if X_init is None:\n        X_init = get_inducing_pts(X_objective,\n                                  num_sensing * self.num_robots)\n    else:\n        # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n        self.num_dim = X_init.shape[-1]\n\n    self.X_init: np.ndarray = X_init.reshape(-1)  # Flattened initial guess\n\n    if isinstance(objective, str):\n        self.objective = get_objective(objective)(X_objective, kernel,\n                                                  noise_variance, **kwargs)\n    else:\n        self.objective = objective\n\n    # Use the boundaries of the X_objective area as the search space limits\n    self.pbounds = geometry.MultiPoint([[p[0], p[1]]\n                                        for p in X_objective]).convex_hull\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the objective.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.objective.kernel), \\\n           self.objective.noise_variance\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.get_transform","title":"<code>get_transform()</code>","text":"<p>Retrieves a deep copy of the transform object.</p> <p>Returns:</p> Name Type Description <code>Transform</code> <code>Transform</code> <p>A deep copy of the transform object.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_transform(self) -&gt; Transform:\n    \"\"\"\n    Retrieves a deep copy of the transform object.\n\n    Returns:\n        Transform: A deep copy of the transform object.\n    \"\"\"\n    return deepcopy(self.transform)\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.optimize","title":"<code>optimize(max_steps=500, tol=1e-06, verbose=False, seed=None, restarts=5, **kwargs)</code>","text":"<p>Optimizes the sensor placement/path using CMA-ES.</p> <p>Parameters:</p> Name Type Description Default <code>max_steps</code> <code>int</code> <p>Maximum number of optimization steps (function evaluations). Defaults to 500.</p> <code>500</code> <code>tol</code> <code>float</code> <p>Tolerance for termination. Defaults to 1e-6.</p> <code>1e-06</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducibility. Defaults to None.</p> <code>None</code> <code>restarts</code> <code>int</code> <p>Number of restarts for CMA-ES. Defaults to 5.</p> <code>5</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for CMA-ES.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\ncma_method = CMA(\n    num_sensing=10,\n    X_objective=X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    transform=IPPTransform(num_robots=1), # Example transform\n    X_candidates=candidates\n)\noptimized_solution = cma_method.optimize(max_steps=1000)\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             max_steps: int = 500,\n             tol: float = 1e-6,\n             verbose: bool = False,\n             seed: Optional[int] = None,\n             restarts: int = 5,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes the sensor placement/path using CMA-ES.\n\n    Args:\n        max_steps (int): Maximum number of optimization steps (function evaluations). Defaults to 500.\n        tol (float): Tolerance for termination. Defaults to 1e-6.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        seed (Optional[int]): Random seed for reproducibility. Defaults to None.\n        restarts (int): Number of restarts for CMA-ES. Defaults to 5.\n        **kwargs: Additional keyword arguments for CMA-ES.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        cma_method = CMA(\n            num_sensing=10,\n            X_objective=X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            transform=IPPTransform(num_robots=1), # Example transform\n            X_candidates=candidates\n        )\n        optimized_solution = cma_method.optimize(max_steps=1000)\n        ```\n    \"\"\"\n    sigma0 = 1.0\n    verbose = 1 if verbose else 0\n    sol, _ = cma.fmin2(self._objective,\n                       self.X_init,\n                       sigma0,\n                       options={\n                           'maxfevals': max_steps,\n                           'verb_disp': verbose,\n                           'tolfun': tol,\n                           'seed': seed\n                       },\n                       restarts=restarts)\n\n    sol_np = np.array(sol).reshape(-1, self.num_dim)\n    if self.transform is not None:\n        try:\n            sol_np = self.transform.expand(sol_np,\n                                           expand_sensor_model=False)\n        except TypeError:\n            pass\n        if not isinstance(sol_np, np.ndarray):\n            sol_np = sol_np.numpy()\n\n    # Map solution locations to candidates set locations if X_candidates is provided\n    if self.X_candidates is not None:\n        sol_np = cont2disc(sol_np, self.X_candidates)\n\n    sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n    return sol_np\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the objective function.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.objective.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/cma.html#sgptools.methods.CMA.update_transform","title":"<code>update_transform(transform)</code>","text":"<p>Updates the transform object used by the CMA-ES optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>transform</code> <code>Transform</code> <p>The new transform object.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update_transform(self, transform: Transform) -&gt; None:\n    \"\"\"\n    Updates the transform object used by the CMA-ES optimizer.\n\n    Args:\n        transform (Transform): The new transform object.\n    \"\"\"\n    self.transform = transform\n</code></pre>"},{"location":"api/methods/continuous_sgp.html","title":"ContinuousSGP","text":""},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP","title":"<code>sgptools.methods.ContinuousSGP</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path optimization using a Sparse Gaussian Process (SGP).</p> <p>This method optimizes the inducing points of an SGP model to maximize the ELBO or other SGP-related objectives.</p> Refer to the following papers for more details <ul> <li>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]</li> <li>Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [Jakkala and Akella, 2024]</li> </ul> <p>Attributes:</p> Name Type Description <code>sgpr</code> <code>AugmentedSGPR</code> <p>The Augmented Sparse Gaussian Process Regression model.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class ContinuousSGP(Method):\n    \"\"\"\n    Implements informative sensor placement/path optimization using a Sparse Gaussian Process (SGP).\n\n    This method optimizes the inducing points of an SGP model to maximize the ELBO or other SGP-related objectives.\n\n    Refer to the following papers for more details:\n        - Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [[Jakkala and Akella, 2023](https://www.itskalvik.com/publication/sgp-sp/)]\n        - Multi-Robot Informative Path Planning from Regression with Sparse Gaussian Processes [[Jakkala and Akella, 2024](https://www.itskalvik.com/publication/sgp-ipp/)]\n\n    Attributes:\n        sgpr (AugmentedSGPR): The Augmented Sparse Gaussian Process Regression model.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 X_init: Optional[np.ndarray] = None,\n                 X_time: Optional[np.ndarray] = None,\n                 orientation: bool = False,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the ContinuousSGP optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations (inducing points) to optimize.\n            X_objective (np.ndarray): (n, d); Data points used to approximate the bounds of the environment.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 Defaults to None.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            X_init (Optional[np.ndarray]): (num_sensing * num_robots, d); Initial inducing points.\n                                            If None, initial points are randomly selected from X_objective.\n            X_time (Optional[np.ndarray]): (m, d); Temporal dimensions of the inducing points, used when\n                                            modeling spatio-temporal IPP. Defaults to None.\n            orientation (bool): If True, adds an additional dimension to model sensor FoV rotation angle\n                                when selecting initial inducing points. Defaults to False.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        if X_init is None:\n            X_init = get_inducing_pts(X_objective,\n                                      num_sensing * self.num_robots,\n                                      orientation=orientation)\n        else:\n            # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n            self.num_dim = X_init.shape[-1]\n\n        # Initialize the SGP\n        dtype = X_objective.dtype\n        train_set: Tuple[tf.Tensor, tf.Tensor] = (tf.constant(X_objective,\n                                                              dtype=dtype),\n                                                  tf.zeros(\n                                                      (len(X_objective), 1),\n                                                      dtype=dtype))\n        self.sgpr = AugmentedSGPR(train_set,\n                                  noise_variance=noise_variance,\n                                  kernel=kernel,\n                                  inducing_variable=X_init,\n                                  inducing_variable_time=X_time,\n                                  transform=transform)\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the SGP model.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.sgpr.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the SGP model.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.sgpr.kernel), \\\n               self.sgpr.likelihood.variance.numpy()\n\n    def optimize(self,\n                 max_steps: int = 500,\n                 optimizer: str = 'scipy.L-BFGS-B',\n                 verbose: bool = False,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes the inducing points of the SGP model.\n\n        Args:\n            max_steps (int): Maximum number of optimization steps. Defaults to 500.\n            optimizer (str): Optimizer \"&lt;backend&gt;.&lt;method&gt;\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').\n                             Defaults to 'scipy.L-BFGS-B'.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            **kwargs: Additional keyword arguments for the optimizer.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized inducing points (sensing locations).\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            csgp_method = ContinuousSGP(\n                num_sensing=10,\n                X_objective=dataset.X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                transform=IPPTransform(num_robots=1), # Example transform\n                X_candidates=candidates # Only if the solution needs to be mapped to candidates\n            )\n            optimized_solution = csgp_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n            ```\n        \"\"\"\n        _ = optimize_model(\n            self.sgpr,\n            max_steps=max_steps,\n            optimize_hparams=\n            False,  # Inducing points are optimized, not kernel hyperparameters\n            optimizer=optimizer,\n            verbose=verbose,\n            **kwargs)\n\n        sol: tf.Tensor = self.sgpr.inducing_variable.Z\n        try:\n            sol_expanded = self.transform.expand(sol,\n                                                 expand_sensor_model=False)\n        except TypeError:\n            sol_expanded = sol\n        if not isinstance(sol_expanded, np.ndarray):\n            sol_np = sol_expanded.numpy()\n        else:\n            sol_np = sol_expanded\n\n        # Map solution locations to candidates set locations if X_candidates is provided\n        if self.X_candidates is not None:\n            sol_np = cont2disc(sol_np, self.X_candidates)\n\n        sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n        return sol_np\n\n    @property\n    def transform(self) -&gt; Transform:\n        \"\"\"\n        Gets the transform object associated with the SGP model.\n\n        Returns:\n            Transform: The transform object.\n        \"\"\"\n        return self.sgpr.transform\n</code></pre>"},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP.transform","title":"<code>transform</code>  <code>property</code>","text":"<p>Gets the transform object associated with the SGP model.</p> <p>Returns:</p> Name Type Description <code>Transform</code> <code>Transform</code> <p>The transform object.</p>"},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, X_init=None, X_time=None, orientation=False, **kwargs)</code>","text":"<p>Initializes the ContinuousSGP optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations (inducing points) to optimize.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to approximate the bounds of the environment.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>X_init</code> <code>Optional[ndarray]</code> <p>(num_sensing * num_robots, d); Initial inducing points.                             If None, initial points are randomly selected from X_objective.</p> <code>None</code> <code>X_time</code> <code>Optional[ndarray]</code> <p>(m, d); Temporal dimensions of the inducing points, used when                             modeling spatio-temporal IPP. Defaults to None.</p> <code>None</code> <code>orientation</code> <code>bool</code> <p>If True, adds an additional dimension to model sensor FoV rotation angle                 when selecting initial inducing points. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             X_init: Optional[np.ndarray] = None,\n             X_time: Optional[np.ndarray] = None,\n             orientation: bool = False,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the ContinuousSGP optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations (inducing points) to optimize.\n        X_objective (np.ndarray): (n, d); Data points used to approximate the bounds of the environment.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             Defaults to None.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        X_init (Optional[np.ndarray]): (num_sensing * num_robots, d); Initial inducing points.\n                                        If None, initial points are randomly selected from X_objective.\n        X_time (Optional[np.ndarray]): (m, d); Temporal dimensions of the inducing points, used when\n                                        modeling spatio-temporal IPP. Defaults to None.\n        orientation (bool): If True, adds an additional dimension to model sensor FoV rotation angle\n                            when selecting initial inducing points. Defaults to False.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    if X_init is None:\n        X_init = get_inducing_pts(X_objective,\n                                  num_sensing * self.num_robots,\n                                  orientation=orientation)\n    else:\n        # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n        self.num_dim = X_init.shape[-1]\n\n    # Initialize the SGP\n    dtype = X_objective.dtype\n    train_set: Tuple[tf.Tensor, tf.Tensor] = (tf.constant(X_objective,\n                                                          dtype=dtype),\n                                              tf.zeros(\n                                                  (len(X_objective), 1),\n                                                  dtype=dtype))\n    self.sgpr = AugmentedSGPR(train_set,\n                              noise_variance=noise_variance,\n                              kernel=kernel,\n                              inducing_variable=X_init,\n                              inducing_variable_time=X_time,\n                              transform=transform)\n</code></pre>"},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the SGP model.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the SGP model.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.sgpr.kernel), \\\n           self.sgpr.likelihood.variance.numpy()\n</code></pre>"},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP.optimize","title":"<code>optimize(max_steps=500, optimizer='scipy.L-BFGS-B', verbose=False, **kwargs)</code>","text":"<p>Optimizes the inducing points of the SGP model.</p> <p>Parameters:</p> Name Type Description Default <code>max_steps</code> <code>int</code> <p>Maximum number of optimization steps. Defaults to 500.</p> <code>500</code> <code>optimizer</code> <code>str</code> <p>Optimizer \".\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').              Defaults to 'scipy.L-BFGS-B'. <code>'scipy.L-BFGS-B'</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the optimizer.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized inducing points (sensing locations).</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\ncsgp_method = ContinuousSGP(\n    num_sensing=10,\n    X_objective=dataset.X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    transform=IPPTransform(num_robots=1), # Example transform\n    X_candidates=candidates # Only if the solution needs to be mapped to candidates\n)\noptimized_solution = csgp_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             max_steps: int = 500,\n             optimizer: str = 'scipy.L-BFGS-B',\n             verbose: bool = False,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes the inducing points of the SGP model.\n\n    Args:\n        max_steps (int): Maximum number of optimization steps. Defaults to 500.\n        optimizer (str): Optimizer \"&lt;backend&gt;.&lt;method&gt;\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').\n                         Defaults to 'scipy.L-BFGS-B'.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        **kwargs: Additional keyword arguments for the optimizer.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized inducing points (sensing locations).\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        csgp_method = ContinuousSGP(\n            num_sensing=10,\n            X_objective=dataset.X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            transform=IPPTransform(num_robots=1), # Example transform\n            X_candidates=candidates # Only if the solution needs to be mapped to candidates\n        )\n        optimized_solution = csgp_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n        ```\n    \"\"\"\n    _ = optimize_model(\n        self.sgpr,\n        max_steps=max_steps,\n        optimize_hparams=\n        False,  # Inducing points are optimized, not kernel hyperparameters\n        optimizer=optimizer,\n        verbose=verbose,\n        **kwargs)\n\n    sol: tf.Tensor = self.sgpr.inducing_variable.Z\n    try:\n        sol_expanded = self.transform.expand(sol,\n                                             expand_sensor_model=False)\n    except TypeError:\n        sol_expanded = sol\n    if not isinstance(sol_expanded, np.ndarray):\n        sol_np = sol_expanded.numpy()\n    else:\n        sol_np = sol_expanded\n\n    # Map solution locations to candidates set locations if X_candidates is provided\n    if self.X_candidates is not None:\n        sol_np = cont2disc(sol_np, self.X_candidates)\n\n    sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n    return sol_np\n</code></pre>"},{"location":"api/methods/continuous_sgp.html#sgptools.methods.ContinuousSGP.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the SGP model.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the SGP model.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.sgpr.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/differentiable_objective.html","title":"DifferentiableObjective","text":""},{"location":"api/methods/differentiable_objective.html#sgptools.methods.DifferentiableObjective","title":"<code>sgptools.methods.DifferentiableObjective</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path planning optimization by directly differentiating through the objective function.</p> <p>This method leverages TensorFlow's automatic differentiation capabilities to optimize the sensing locations (or path waypoints) by treating them as trainable variables and minimizing a given objective function (e.g., Mutual Information). This approach can be more efficient than black-box methods like Bayesian Optimization or CMA-ES, especially when the objective function is smooth. However, the method is also more prone to getting stuck in local minima.</p> <p>Attributes:</p> Name Type Description <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to the solution.</p> <code>X_sol</code> <code>Variable</code> <p>The solution (e.g., sensor locations) being optimized.</p> <code>objective</code> <code>Objective</code> <p>The objective function to be optimized.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class DifferentiableObjective(Method):\n    \"\"\"\n    Implements informative sensor placement/path planning optimization by directly\n    differentiating through the objective function.\n\n    This method leverages TensorFlow's automatic differentiation capabilities to\n    optimize the sensing locations (or path waypoints) by treating them as\n    trainable variables and minimizing a given objective function (e.g., Mutual\n    Information). This approach can be more efficient than black-box methods like\n    Bayesian Optimization or CMA-ES, especially when the objective function is\n    smooth. However, the method is also more prone to getting stuck in local minima.\n\n    Attributes:\n        transform (Optional[Transform]): Transform object to apply to the solution.\n        X_sol (tf.Variable): The solution (e.g., sensor locations) being optimized.\n        objective (Objective): The objective function to be optimized.\n    \"\"\"\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 objective: Union[str, Objective] = 'SLogMI',\n                 X_init: Optional[np.ndarray] = None,\n                 X_time: Optional[np.ndarray] = None,\n                 orientation: bool = False,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the DifferentiableObjective optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations to optimize.\n            X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 Defaults to None.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                         or an instance of an objective class. Defaults to 'SLogMI'.\n            X_init (Optional[np.ndarray]): (num_sensing * num_robots, d); Initial solution.\n                                            If None, initial points are randomly selected from X_objective.\n            X_time (Optional[np.ndarray]): (m, d); Temporal dimensions of the inducing points, used when\n                                            modeling spatio-temporal IPP. Defaults to None.\n            orientation (bool): If True, adds an additional dimension to model sensor FoV rotation angle\n                                when selecting initial inducing points. Defaults to False.\n            **kwargs: Additional keyword arguments passed to the objective function.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        self.transform = transform\n        if X_candidates is None:\n            self.X_candidates = X_objective  # Default candidates to objective points\n\n        if X_init is None:\n            X_init = get_inducing_pts(X_objective,\n                                      num_sensing * self.num_robots,\n                                      orientation=orientation)\n        else:\n            # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n            self.num_dim = X_init.shape[-1]\n        self.X_sol = tf.Variable(X_init, dtype=X_init.dtype)\n\n        if isinstance(objective, str):\n            self.objective = get_objective(objective)(X_objective, kernel,\n                                                      noise_variance, **kwargs)\n        else:\n            self.objective = objective\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the objective function.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.objective.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.objective.kernel), \\\n               self.objective.noise_variance\n\n    def optimize(self,\n                 max_steps: int = 500,\n                 optimizer: str = 'scipy.L-BFGS-B',\n                 verbose: bool = False,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes the sensor placement/path by differentiating through the objective function.\n\n        Args:\n            max_steps (int): Maximum number of optimization steps. Defaults to 500.\n            optimizer (str): Optimizer \"&lt;backend&gt;.&lt;method&gt;\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').\n                             Defaults to 'scipy.L-BFGS-B'.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            **kwargs: Additional keyword arguments for the optimizer.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            diff_obj_method = DifferentiableObjective(\n                num_sensing=10,\n                X_objective=X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                transform=IPPTransform(num_robots=1), # Example transform\n                X_candidates=candidates\n            )\n            optimized_solution = diff_obj_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n            ```\n        \"\"\"\n        _ = optimize_model(\n            training_loss = self._objective,\n            max_steps=max_steps,\n            trainable_variables=[self.X_sol],\n            optimizer=optimizer,\n            verbose=verbose,\n            **kwargs)\n\n        sol: tf.Tensor = self.X_sol\n        try:\n            sol_expanded = self.transform.expand(sol,\n                                                 expand_sensor_model=False)\n        except TypeError:\n            sol_expanded = sol\n        if not isinstance(sol_expanded, np.ndarray):\n            sol_np = sol_expanded.numpy()\n        else:\n            sol_np = sol_expanded\n\n        # Map solution locations to candidates set locations if X_candidates is provided\n        if self.X_candidates is not None:\n            sol_np = cont2disc(sol_np, self.X_candidates)\n\n        sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n        return sol_np\n\n    def _objective(self) -&gt; float:\n        \"\"\"\n        Internal objective function to be minimized by the optimizer.\n\n        This function applies any specified transformations to the current solution,\n        calculates the objective value, and applies a penalty for constraint\n        violations.\n\n        Returns:\n            float: The objective value (reward + constraint penalty).\n        \"\"\"\n        constraint_penality: float = 0.0\n        if self.transform is not None:\n            X_expanded = self.transform.expand(self.X_sol)\n            constraint_penality = self.transform.constraints(self.X_sol)\n            reward = self.objective(X_expanded)  # maximize\n        else:\n            reward = self.objective(self.X_sol)  # maximize\n\n        reward += constraint_penality  # minimize (large negative value when constraint is unsatisfied)\n        return reward\n</code></pre>"},{"location":"api/methods/differentiable_objective.html#sgptools.methods.DifferentiableObjective.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, objective='SLogMI', X_init=None, X_time=None, orientation=False, **kwargs)</code>","text":"<p>Initializes the DifferentiableObjective optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to optimize.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>objective</code> <code>Union[str, Objective]</code> <p>The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')                          or an instance of an objective class. Defaults to 'SLogMI'.</p> <code>'SLogMI'</code> <code>X_init</code> <code>Optional[ndarray]</code> <p>(num_sensing * num_robots, d); Initial solution.                             If None, initial points are randomly selected from X_objective.</p> <code>None</code> <code>X_time</code> <code>Optional[ndarray]</code> <p>(m, d); Temporal dimensions of the inducing points, used when                             modeling spatio-temporal IPP. Defaults to None.</p> <code>None</code> <code>orientation</code> <code>bool</code> <p>If True, adds an additional dimension to model sensor FoV rotation angle                 when selecting initial inducing points. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the objective function.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             objective: Union[str, Objective] = 'SLogMI',\n             X_init: Optional[np.ndarray] = None,\n             X_time: Optional[np.ndarray] = None,\n             orientation: bool = False,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the DifferentiableObjective optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations to optimize.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             Defaults to None.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                     or an instance of an objective class. Defaults to 'SLogMI'.\n        X_init (Optional[np.ndarray]): (num_sensing * num_robots, d); Initial solution.\n                                        If None, initial points are randomly selected from X_objective.\n        X_time (Optional[np.ndarray]): (m, d); Temporal dimensions of the inducing points, used when\n                                        modeling spatio-temporal IPP. Defaults to None.\n        orientation (bool): If True, adds an additional dimension to model sensor FoV rotation angle\n                            when selecting initial inducing points. Defaults to False.\n        **kwargs: Additional keyword arguments passed to the objective function.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    self.transform = transform\n    if X_candidates is None:\n        self.X_candidates = X_objective  # Default candidates to objective points\n\n    if X_init is None:\n        X_init = get_inducing_pts(X_objective,\n                                  num_sensing * self.num_robots,\n                                  orientation=orientation)\n    else:\n        # override num_dim with initial inducing points dim, in case it differes from X_objective dim\n        self.num_dim = X_init.shape[-1]\n    self.X_sol = tf.Variable(X_init, dtype=X_init.dtype)\n\n    if isinstance(objective, str):\n        self.objective = get_objective(objective)(X_objective, kernel,\n                                                  noise_variance, **kwargs)\n    else:\n        self.objective = objective\n</code></pre>"},{"location":"api/methods/differentiable_objective.html#sgptools.methods.DifferentiableObjective.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the objective.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.objective.kernel), \\\n           self.objective.noise_variance\n</code></pre>"},{"location":"api/methods/differentiable_objective.html#sgptools.methods.DifferentiableObjective.optimize","title":"<code>optimize(max_steps=500, optimizer='scipy.L-BFGS-B', verbose=False, **kwargs)</code>","text":"<p>Optimizes the sensor placement/path by differentiating through the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>max_steps</code> <code>int</code> <p>Maximum number of optimization steps. Defaults to 500.</p> <code>500</code> <code>optimizer</code> <code>str</code> <p>Optimizer \".\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').              Defaults to 'scipy.L-BFGS-B'. <code>'scipy.L-BFGS-B'</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the optimizer.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\ndiff_obj_method = DifferentiableObjective(\n    num_sensing=10,\n    X_objective=X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    transform=IPPTransform(num_robots=1), # Example transform\n    X_candidates=candidates\n)\noptimized_solution = diff_obj_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             max_steps: int = 500,\n             optimizer: str = 'scipy.L-BFGS-B',\n             verbose: bool = False,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes the sensor placement/path by differentiating through the objective function.\n\n    Args:\n        max_steps (int): Maximum number of optimization steps. Defaults to 500.\n        optimizer (str): Optimizer \"&lt;backend&gt;.&lt;method&gt;\" to use for training (e.g., 'scipy.L-BFGS-B', 'tf.adam').\n                         Defaults to 'scipy.L-BFGS-B'.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        **kwargs: Additional keyword arguments for the optimizer.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        diff_obj_method = DifferentiableObjective(\n            num_sensing=10,\n            X_objective=X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            transform=IPPTransform(num_robots=1), # Example transform\n            X_candidates=candidates\n        )\n        optimized_solution = diff_obj_method.optimize(max_steps=500, optimizer='scipy.L-BFGS-B')\n        ```\n    \"\"\"\n    _ = optimize_model(\n        training_loss = self._objective,\n        max_steps=max_steps,\n        trainable_variables=[self.X_sol],\n        optimizer=optimizer,\n        verbose=verbose,\n        **kwargs)\n\n    sol: tf.Tensor = self.X_sol\n    try:\n        sol_expanded = self.transform.expand(sol,\n                                             expand_sensor_model=False)\n    except TypeError:\n        sol_expanded = sol\n    if not isinstance(sol_expanded, np.ndarray):\n        sol_np = sol_expanded.numpy()\n    else:\n        sol_np = sol_expanded\n\n    # Map solution locations to candidates set locations if X_candidates is provided\n    if self.X_candidates is not None:\n        sol_np = cont2disc(sol_np, self.X_candidates)\n\n    sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n    return sol_np\n</code></pre>"},{"location":"api/methods/differentiable_objective.html#sgptools.methods.DifferentiableObjective.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the objective function.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.objective.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/greedy_objective.html","title":"GreedyObjective","text":""},{"location":"api/methods/greedy_objective.html#sgptools.methods.GreedyObjective","title":"<code>sgptools.methods.GreedyObjective</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path optimization using a greedy approach based on a specified objective function.</p> <p>This method iteratively selects the best sensing location from a set of candidates that maximizes the objective function. It currently supports only single-robot scenarios.</p> Refer to the following papers for more details <ul> <li>Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies [Krause et al., 2008]</li> <li>Data-driven learning and planning for environmental sampling [Ma et al., 2018]</li> </ul> <p>Attributes:</p> Name Type Description <code>objective</code> <code>Objective</code> <p>The objective function to be maximized (e.g., Mutual Information).</p> <code>transform</code> <code>Optional[Transform]</code> <p>Transform object applied to selected locations.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class GreedyObjective(Method):\n    \"\"\"\n    Implements informative sensor placement/path optimization using a greedy approach based on a specified objective function.\n\n    This method iteratively selects the best sensing location from a set of candidates\n    that maximizes the objective function. It currently supports only single-robot scenarios.\n\n    Refer to the following papers for more details:\n        - Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies [Krause et al., 2008]\n        - Data-driven learning and planning for environmental sampling [Ma et al., 2018]\n\n    Attributes:\n        objective (Objective): The objective function to be maximized (e.g., Mutual Information).\n        transform (Optional[Transform]): Transform object applied to selected locations.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 objective: Union[str, Objective] = 'SLogMI',\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the GreedyObjective optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations to select.\n            X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 If None, X_objective is used as candidates.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                         or an instance of an objective class. Defaults to 'SLogMI'.\n            **kwargs: Additional keyword arguments passed to the objective function.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        self.X_objective = X_objective\n        if X_candidates is None:\n            self.X_candidates = X_objective  # Default candidates to objective points\n\n        if transform is not None:\n            try:\n                num_robots_transform = transform.num_robots\n            except AttributeError:\n                num_robots_transform = 1  # Assume single robot if num_robots not defined in transform\n            error = f\"num_robots is not equal in transform: {num_robots_transform} and GreedyObjective: {self.num_robots}\"\n            assert self.num_robots == num_robots_transform, error\n\n        error = f\"num_robots={self.num_robots}; GreedyObjective only supports num_robots=1\"\n        assert self.num_robots == 1, error\n\n        self.transform = transform\n\n        if isinstance(objective, str):\n            self.objective = get_objective(objective)(X_objective, kernel,\n                                                      noise_variance, **kwargs)\n        else:\n            self.objective = objective\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the objective function.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.objective.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.objective.kernel), \\\n               self.objective.noise_variance\n\n    def optimize(self,\n                 optimizer: str = 'naive',\n                 verbose: bool = False,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes sensor placement using a greedy approach.\n\n        Args:\n            optimizer (str): The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            greedy_obj_method = GreedyObjective(\n                num_sensing=5,\n                X_objective=X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                X_candidates=candidates\n            )\n            optimized_solution = greedy_obj_method.optimize(optimizer='naive')\n            ```\n        \"\"\"\n        model = CustomSelection(self.num_sensing,\n                                self._objective,\n                                optimizer=optimizer,\n                                verbose=verbose)\n\n        # apricot's CustomSelection expects indices, so pass a dummy array of indices\n        sol_indices = model.fit_transform(\n            np.arange(len(self.X_candidates)).reshape(-1, 1))\n        sol_indices = np.array(sol_indices).reshape(-1).astype(int)\n        sol_locations = self.X_candidates[sol_indices]\n\n        sol_locations = np.array(sol_locations).reshape(-1, self.num_dim)\n        if self.transform is not None:\n            try:\n                sol_locations = self.transform.expand(\n                    sol_locations, expand_sensor_model=False)\n            except TypeError:\n                pass\n            if not isinstance(sol_locations, np.ndarray):\n                sol_locations = sol_locations.numpy()\n        sol_locations = sol_locations.reshape(self.num_robots, -1,\n                                              self.num_dim)\n        return sol_locations\n\n    def _objective(self, X_indices: np.ndarray) -&gt; float:\n        \"\"\"\n        Internal objective function for the greedy selection.\n\n        This function maps the input indices to actual locations, applies any\n        transformations, calculates the objective value, and applies a penalty\n        for constraint violations.\n\n        Args:\n            X_indices (np.ndarray): (n, 1); Array of indices corresponding to candidate locations.\n\n        Returns:\n            float: The objective value (reward - constraint penalty) for the given selection.\n        \"\"\"\n        # Map solution location indices to locations\n        X_indices_flat = np.array(X_indices).reshape(-1).astype(int)\n        X_locations = self.X_objective[X_indices_flat].reshape(\n            -1, self.num_dim)\n\n        constraint_penality: float = 0.0\n        if self.transform is not None:\n            X_expanded = self.transform.expand(X_locations)\n            constraint_penality = self.transform.constraints(X_locations)\n            reward = self.objective(X_expanded)  # maximize\n        else:\n            reward = self.objective(X_locations)  # maximize\n\n        reward += constraint_penality  # minimize (large negative value when constraint is unsatisfied)\n        return reward.numpy()\n</code></pre>"},{"location":"api/methods/greedy_objective.html#sgptools.methods.GreedyObjective.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, objective='SLogMI', **kwargs)</code>","text":"<p>Initializes the GreedyObjective optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to select.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  If None, X_objective is used as candidates.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>objective</code> <code>Union[str, Objective]</code> <p>The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')                          or an instance of an objective class. Defaults to 'SLogMI'.</p> <code>'SLogMI'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the objective function.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             objective: Union[str, Objective] = 'SLogMI',\n             **kwargs: Any):\n    \"\"\"\n    Initializes the GreedyObjective optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations to select.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             If None, X_objective is used as candidates.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        objective (Union[str, Objective]): The objective function to use. Can be a string (e.g., 'SLogMI', 'MI')\n                                     or an instance of an objective class. Defaults to 'SLogMI'.\n        **kwargs: Additional keyword arguments passed to the objective function.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    self.X_objective = X_objective\n    if X_candidates is None:\n        self.X_candidates = X_objective  # Default candidates to objective points\n\n    if transform is not None:\n        try:\n            num_robots_transform = transform.num_robots\n        except AttributeError:\n            num_robots_transform = 1  # Assume single robot if num_robots not defined in transform\n        error = f\"num_robots is not equal in transform: {num_robots_transform} and GreedyObjective: {self.num_robots}\"\n        assert self.num_robots == num_robots_transform, error\n\n    error = f\"num_robots={self.num_robots}; GreedyObjective only supports num_robots=1\"\n    assert self.num_robots == 1, error\n\n    self.transform = transform\n\n    if isinstance(objective, str):\n        self.objective = get_objective(objective)(X_objective, kernel,\n                                                  noise_variance, **kwargs)\n    else:\n        self.objective = objective\n</code></pre>"},{"location":"api/methods/greedy_objective.html#sgptools.methods.GreedyObjective.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the objective.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the objective.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.objective.kernel), \\\n           self.objective.noise_variance\n</code></pre>"},{"location":"api/methods/greedy_objective.html#sgptools.methods.GreedyObjective.optimize","title":"<code>optimize(optimizer='naive', verbose=False, **kwargs)</code>","text":"<p>Optimizes sensor placement using a greedy approach.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>str</code> <p>The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.</p> <code>'naive'</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\ngreedy_obj_method = GreedyObjective(\n    num_sensing=5,\n    X_objective=X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    X_candidates=candidates\n)\noptimized_solution = greedy_obj_method.optimize(optimizer='naive')\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             optimizer: str = 'naive',\n             verbose: bool = False,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes sensor placement using a greedy approach.\n\n    Args:\n        optimizer (str): The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        greedy_obj_method = GreedyObjective(\n            num_sensing=5,\n            X_objective=X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            X_candidates=candidates\n        )\n        optimized_solution = greedy_obj_method.optimize(optimizer='naive')\n        ```\n    \"\"\"\n    model = CustomSelection(self.num_sensing,\n                            self._objective,\n                            optimizer=optimizer,\n                            verbose=verbose)\n\n    # apricot's CustomSelection expects indices, so pass a dummy array of indices\n    sol_indices = model.fit_transform(\n        np.arange(len(self.X_candidates)).reshape(-1, 1))\n    sol_indices = np.array(sol_indices).reshape(-1).astype(int)\n    sol_locations = self.X_candidates[sol_indices]\n\n    sol_locations = np.array(sol_locations).reshape(-1, self.num_dim)\n    if self.transform is not None:\n        try:\n            sol_locations = self.transform.expand(\n                sol_locations, expand_sensor_model=False)\n        except TypeError:\n            pass\n        if not isinstance(sol_locations, np.ndarray):\n            sol_locations = sol_locations.numpy()\n    sol_locations = sol_locations.reshape(self.num_robots, -1,\n                                          self.num_dim)\n    return sol_locations\n</code></pre>"},{"location":"api/methods/greedy_objective.html#sgptools.methods.GreedyObjective.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the objective function.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.objective.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/greedy_sgp.html","title":"GreedySGP","text":""},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP","title":"<code>sgptools.methods.GreedySGP</code>","text":"<p>               Bases: <code>Method</code></p> <p>Implements informative sensor placement/path optimization using a greedy approach combined with a Sparse Gaussian Process (SGP) ELBO objective.</p> <p>This method iteratively selects inducing points to maximize the SGP's ELBO. It currently supports only single-robot scenarios.</p> Refer to the following papers for more details <ul> <li>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [Jakkala and Akella, 2023]</li> </ul> <p>Attributes:</p> Name Type Description <code>sgpr</code> <code>AugmentedSGPR</code> <p>The Augmented Sparse Gaussian Process Regression model.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class GreedySGP(Method):\n    \"\"\"\n    Implements informative sensor placement/path optimization using a greedy approach combined with a Sparse Gaussian Process (SGP) ELBO objective.\n\n    This method iteratively selects inducing points to maximize the SGP's ELBO.\n    It currently supports only single-robot scenarios.\n\n    Refer to the following papers for more details:\n        - Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces [[Jakkala and Akella, 2023](https://www.itskalvik.com/publication/sgp-sp/)]\n\n    Attributes:\n        sgpr (AugmentedSGPR): The Augmented Sparse Gaussian Process Regression model.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the GreedySGP optimizer.\n\n        Args:\n            num_sensing (int): Number of sensing locations (inducing points) to select.\n            X_objective (np.ndarray): (n, d); Data points used to train the SGP model.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 If None, X_objective is used as candidates.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                         transform, num_robots, X_candidates, num_dim)\n        self.X_objective = X_objective\n        if X_candidates is None:\n            self.X_candidates = X_objective  # Default candidates to objective points\n\n        if transform is not None:\n            try:\n                num_robots_transform = transform.num_robots\n            except AttributeError:\n                num_robots_transform = 1  # Assume single robot if num_robots not defined in transform\n            error = f\"num_robots is not equal in transform: {num_robots_transform} and GreedySGP: {self.num_robots}\"\n            assert self.num_robots == num_robots_transform, error\n\n        error = f\"num_robots={self.num_robots}; GreedySGP only supports num_robots=1\"\n        assert self.num_robots == 1, error\n\n        # Initialize the SGP\n        dtype = X_objective.dtype\n        train_set: Tuple[tf.Tensor, tf.Tensor] = (tf.constant(X_objective,\n                                                              dtype=dtype),\n                                                  tf.zeros(\n                                                      (len(X_objective), 1),\n                                                      dtype=dtype))\n\n        X_init = get_inducing_pts(X_objective, num_sensing)\n        self.sgpr = AugmentedSGPR(train_set,\n                                  noise_variance=noise_variance,\n                                  kernel=kernel,\n                                  inducing_variable=X_init,\n                                  transform=transform)\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the SGP model.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n        \"\"\"\n        self.sgpr.update(kernel, noise_variance)\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters from the SGP model.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n        \"\"\"\n        return deepcopy(self.sgpr.kernel), \\\n               self.sgpr.likelihood.variance.numpy()\n\n    def optimize(self,\n                 optimizer: str = 'naive',\n                 verbose: bool = False,\n                 **kwargs: Any) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes sensor placement using a greedy SGP approach.\n\n        Args:\n            optimizer (str): The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.\n            verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n        Usage:\n            ```python\n            # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n            greedy_sgp_method = GreedySGP(\n                num_sensing=5,\n                X_objective=X_train,\n                kernel=kernel_opt,\n                noise_variance=noise_variance_opt,\n                X_candidates=candidates\n            )\n            optimized_solution = greedy_sgp_method.optimize(optimizer='naive')\n            ```\n        \"\"\"\n        model = CustomSelection(self.num_sensing,\n                                self._objective,\n                                optimizer=optimizer,\n                                verbose=verbose)\n\n        # apricot's CustomSelection expects indices, so pass a dummy array of indices\n        sol_indices = model.fit_transform(\n            np.arange(len(self.X_candidates)).reshape(-1, 1))\n        sol_indices = np.array(sol_indices).reshape(-1).astype(int)\n        sol_locations = self.X_candidates[sol_indices]\n\n        sol_locations = np.array(sol_locations).reshape(-1, self.num_dim)\n        try:\n            sol_expanded = self.transform.expand(sol_locations,\n                                                 expand_sensor_model=False)\n        except AttributeError:\n            sol_expanded = sol_locations\n        if not isinstance(sol_expanded, np.ndarray):\n            sol_np = sol_expanded.numpy()\n        else:\n            sol_np = sol_expanded\n\n        sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n        return sol_np\n\n    def _objective(self, X_indices: np.ndarray) -&gt; float:\n        \"\"\"\n        Internal objective function for the greedy SGP selection.\n\n        This function maps the input indices to actual locations and updates\n        the SGP model's inducing points to calculate the ELBO. The ELBO is\n        then used as the objective for greedy maximization.\n\n        Args:\n            X_indices (np.ndarray): (n, 1); Array of indices corresponding to candidate locations.\n\n        Returns:\n            float: The ELBO of the SGP model for the given inducing points.\n        \"\"\"\n        # Map solution location indices to locations\n        # Since SGP requires num_sensing points,\n        # pad the current greedy solution with the\n        # first location in the solution (or zeros if no points selected yet)\n        X_indices_flat = np.array(X_indices).reshape(-1).astype(int)\n        num_pad = self.num_sensing - len(X_indices_flat)\n\n        # Ensure that if X_indices_flat is empty, we still create a valid padding array\n        if len(X_indices_flat) == 0 and num_pad &gt; 0:\n            X_pad = np.zeros(num_pad, dtype=int)\n        elif len(X_indices_flat) &gt; 0 and num_pad &gt; 0:\n            X_pad = np.full(num_pad, X_indices_flat[0], dtype=int)\n        else:  # num_pad is 0 or negative\n            X_pad = np.array([], dtype=int)\n\n        X_combined_indices = np.concatenate([X_indices_flat, X_pad])\n        X_locations = self.X_objective[X_combined_indices].reshape(\n            -1, self.num_dim)\n\n        # Update the SGP inducing points\n        self.sgpr.inducing_variable.Z.assign(X_locations)\n        return self.sgpr.elbo().numpy()\n\n    @property\n    def transform(self) -&gt; Transform:\n        \"\"\"\n        Gets the transform object associated with the SGP model.\n\n        Returns:\n            Transform: The transform object.\n        \"\"\"\n        return self.sgpr.transform\n</code></pre>"},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP.transform","title":"<code>transform</code>  <code>property</code>","text":"<p>Gets the transform object associated with the SGP model.</p> <p>Returns:</p> Name Type Description <code>Transform</code> <code>Transform</code> <p>The transform object.</p>"},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, **kwargs)</code>","text":"<p>Initializes the GreedySGP optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations (inducing points) to select.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to train the SGP model.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  If None, X_objective is used as candidates.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the GreedySGP optimizer.\n\n    Args:\n        num_sensing (int): Number of sensing locations (inducing points) to select.\n        X_objective (np.ndarray): (n, d); Data points used to train the SGP model.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             If None, X_objective is used as candidates.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    super().__init__(num_sensing, X_objective, kernel, noise_variance,\n                     transform, num_robots, X_candidates, num_dim)\n    self.X_objective = X_objective\n    if X_candidates is None:\n        self.X_candidates = X_objective  # Default candidates to objective points\n\n    if transform is not None:\n        try:\n            num_robots_transform = transform.num_robots\n        except AttributeError:\n            num_robots_transform = 1  # Assume single robot if num_robots not defined in transform\n        error = f\"num_robots is not equal in transform: {num_robots_transform} and GreedySGP: {self.num_robots}\"\n        assert self.num_robots == num_robots_transform, error\n\n    error = f\"num_robots={self.num_robots}; GreedySGP only supports num_robots=1\"\n    assert self.num_robots == 1, error\n\n    # Initialize the SGP\n    dtype = X_objective.dtype\n    train_set: Tuple[tf.Tensor, tf.Tensor] = (tf.constant(X_objective,\n                                                          dtype=dtype),\n                                              tf.zeros(\n                                                  (len(X_objective), 1),\n                                                  dtype=dtype))\n\n    X_init = get_inducing_pts(X_objective, num_sensing)\n    self.sgpr = AugmentedSGPR(train_set,\n                              noise_variance=noise_variance,\n                              kernel=kernel,\n                              inducing_variable=X_init,\n                              transform=transform)\n</code></pre>"},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters from the SGP model.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters from the SGP model.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing a deep copy of the kernel and the noise variance.\n    \"\"\"\n    return deepcopy(self.sgpr.kernel), \\\n           self.sgpr.likelihood.variance.numpy()\n</code></pre>"},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP.optimize","title":"<code>optimize(optimizer='naive', verbose=False, **kwargs)</code>","text":"<p>Optimizes sensor placement using a greedy SGP approach.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>str</code> <p>The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.</p> <code>'naive'</code> <code>verbose</code> <code>bool</code> <p>Verbosity, if True additional details will by reported. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Usage <pre><code># Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\ngreedy_sgp_method = GreedySGP(\n    num_sensing=5,\n    X_objective=X_train,\n    kernel=kernel_opt,\n    noise_variance=noise_variance_opt,\n    X_candidates=candidates\n)\noptimized_solution = greedy_sgp_method.optimize(optimizer='naive')\n</code></pre> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self,\n             optimizer: str = 'naive',\n             verbose: bool = False,\n             **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes sensor placement using a greedy SGP approach.\n\n    Args:\n        optimizer (str): The greedy optimizer strategy (e.g., 'naive', 'lazy'). Defaults to 'naive'.\n        verbose (bool): Verbosity, if True additional details will by reported. Defaults to False.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n\n    Usage:\n        ```python\n        # Assuming X_train, candidates, kernel_opt, noise_variance_opt are defined\n        greedy_sgp_method = GreedySGP(\n            num_sensing=5,\n            X_objective=X_train,\n            kernel=kernel_opt,\n            noise_variance=noise_variance_opt,\n            X_candidates=candidates\n        )\n        optimized_solution = greedy_sgp_method.optimize(optimizer='naive')\n        ```\n    \"\"\"\n    model = CustomSelection(self.num_sensing,\n                            self._objective,\n                            optimizer=optimizer,\n                            verbose=verbose)\n\n    # apricot's CustomSelection expects indices, so pass a dummy array of indices\n    sol_indices = model.fit_transform(\n        np.arange(len(self.X_candidates)).reshape(-1, 1))\n    sol_indices = np.array(sol_indices).reshape(-1).astype(int)\n    sol_locations = self.X_candidates[sol_indices]\n\n    sol_locations = np.array(sol_locations).reshape(-1, self.num_dim)\n    try:\n        sol_expanded = self.transform.expand(sol_locations,\n                                             expand_sensor_model=False)\n    except AttributeError:\n        sol_expanded = sol_locations\n    if not isinstance(sol_expanded, np.ndarray):\n        sol_np = sol_expanded.numpy()\n    else:\n        sol_np = sol_expanded\n\n    sol_np = sol_np.reshape(self.num_robots, -1, self.num_dim)\n    return sol_np\n</code></pre>"},{"location":"api/methods/greedy_sgp.html#sgptools.methods.GreedySGP.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the SGP model.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the SGP model.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n    \"\"\"\n    self.sgpr.update(kernel, noise_variance)\n</code></pre>"},{"location":"api/methods/method.html","title":"Method","text":""},{"location":"api/methods/method.html#sgptools.methods.Method","title":"<code>sgptools.methods.Method</code>","text":"<p>Method class for optimization methods.</p> <p>Attributes:</p> Name Type Description <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to optimize.</p> <code>num_dim</code> <code>int</code> <p>Dimensionality of the data points.</p> <code>num_robots</code> <code>int</code> <p>Number of robots/agents.</p> <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points.</p> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.</p> <code>num_dim</code> <code>int</code> <p>Dimensionality of the sensing locations.</p> Source code in <code>sgptools/methods.py</code> <pre><code>class Method:\n    \"\"\"\n    Method class for optimization methods.\n\n    Attributes:\n        num_sensing (int): Number of sensing locations to optimize.\n        num_dim (int): Dimensionality of the data points.\n        num_robots (int): Number of robots/agents.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n        num_dim (int): Dimensionality of the sensing locations.\n    \"\"\"\n\n    def __init__(self,\n                 num_sensing: int,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 transform: Optional[Transform] = None,\n                 num_robots: int = 1,\n                 X_candidates: Optional[np.ndarray] = None,\n                 num_dim: Optional[int] = None,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the Method class.\n\n        Args:\n            num_sensing (int): Number of sensing locations to optimize.\n            X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n            kernel (gpflow.kernels.Kernel): GPflow kernel function.\n            noise_variance (float): Data noise variance.\n            transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n            num_robots (int): Number of robots/agents. Defaults to 1.\n            X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                                 Defaults to None.\n            num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        self.num_sensing = num_sensing\n        self.num_robots = num_robots\n        self.X_candidates = X_candidates\n        if num_dim is None:\n            self.num_dim = X_objective.shape[-1]\n        else:\n            self.num_dim = num_dim\n\n    def optimize(self) -&gt; np.ndarray:\n        \"\"\"\n        Optimizes the sensor placements/path(s).\n\n        Raises:\n            NotImplementedError: This method must be implemented by subclasses.\n\n        Returns:\n            np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n        \"\"\"\n        raise NotImplementedError\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance parameters of the underlying model/objective.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n            noise_variance (float): Updated data noise variance.\n\n        Raises:\n            NotImplementedError: This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n        \"\"\"\n        Retrieves the current kernel and noise variance hyperparameters.\n\n        Raises:\n            NotImplementedError: This method must be implemented by subclasses.\n\n        Returns:\n            Tuple[gpflow.kernels.Kernel, float]: A tuple containing the kernel and noise variance.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/methods/method.html#sgptools.methods.Method.__init__","title":"<code>__init__(num_sensing, X_objective, kernel, noise_variance, transform=None, num_robots=1, X_candidates=None, num_dim=None, **kwargs)</code>","text":"<p>Initializes the Method class.</p> <p>Parameters:</p> Name Type Description Default <code>num_sensing</code> <code>int</code> <p>Number of sensing locations to optimize.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); Data points used to define the objective function.</p> required <code>kernel</code> <code>Kernel</code> <p>GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Data noise variance.</p> required <code>transform</code> <code>Optional[Transform]</code> <p>Transform object to apply to inducing points. Defaults to None.</p> <code>None</code> <code>num_robots</code> <code>int</code> <p>Number of robots/agents. Defaults to 1.</p> <code>1</code> <code>X_candidates</code> <code>Optional[ndarray]</code> <p>(c, d); Discrete set of candidate locations for sensor placement.                                  Defaults to None.</p> <code>None</code> <code>num_dim</code> <code>Optional[int]</code> <p>Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/methods.py</code> <pre><code>def __init__(self,\n             num_sensing: int,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             transform: Optional[Transform] = None,\n             num_robots: int = 1,\n             X_candidates: Optional[np.ndarray] = None,\n             num_dim: Optional[int] = None,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the Method class.\n\n    Args:\n        num_sensing (int): Number of sensing locations to optimize.\n        X_objective (np.ndarray): (n, d); Data points used to define the objective function.\n        kernel (gpflow.kernels.Kernel): GPflow kernel function.\n        noise_variance (float): Data noise variance.\n        transform (Optional[Transform]): Transform object to apply to inducing points. Defaults to None.\n        num_robots (int): Number of robots/agents. Defaults to 1.\n        X_candidates (Optional[np.ndarray]): (c, d); Discrete set of candidate locations for sensor placement.\n                                             Defaults to None.\n        num_dim (Optional[int]): Dimensionality of the sensing locations. Defaults to dimensonality of X_objective.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    self.num_sensing = num_sensing\n    self.num_robots = num_robots\n    self.X_candidates = X_candidates\n    if num_dim is None:\n        self.num_dim = X_objective.shape[-1]\n    else:\n        self.num_dim = num_dim\n</code></pre>"},{"location":"api/methods/method.html#sgptools.methods.Method.get_hyperparameters","title":"<code>get_hyperparameters()</code>","text":"<p>Retrieves the current kernel and noise variance hyperparameters.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> <p>Returns:</p> Type Description <code>Tuple[Kernel, float]</code> <p>Tuple[gpflow.kernels.Kernel, float]: A tuple containing the kernel and noise variance.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def get_hyperparameters(self) -&gt; Tuple[gpflow.kernels.Kernel, float]:\n    \"\"\"\n    Retrieves the current kernel and noise variance hyperparameters.\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n\n    Returns:\n        Tuple[gpflow.kernels.Kernel, float]: A tuple containing the kernel and noise variance.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/methods/method.html#sgptools.methods.Method.optimize","title":"<code>optimize()</code>","text":"<p>Optimizes the sensor placements/path(s).</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def optimize(self) -&gt; np.ndarray:\n    \"\"\"\n    Optimizes the sensor placements/path(s).\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n\n    Returns:\n        np.ndarray: (num_robots, num_sensing, num_dim); Optimized sensing locations.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/methods/method.html#sgptools.methods.Method.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance parameters of the underlying model/objective.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>Updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>Updated data noise variance.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> Source code in <code>sgptools/methods.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance parameters of the underlying model/objective.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): Updated GPflow kernel function.\n        noise_variance (float): Updated data noise variance.\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/objectives/index.html","title":"<code>objectives</code>: Information-Theoretic Objectives","text":"<p>This module defines the objective functions that the optimization methods aim to maximize.  Use the <code>get_objective</code> method to retrieve an objective function class by its string name.</p> <ul> <li> <p><code>MI</code>, <code>SLogMI</code>, and <code>SchurMI</code>: These classes compute the Mutual Information (MI) between a set of sensing locations \\(X\\) and a set of objective locations \\(X_{objective}\\), using the kernel fuunction \\(K\\):</p> <ul> <li> <p><code>MI</code>: A naive implementation of MI.</p> </li> <li> <p><code>SLogMI</code>: Uses a numerically stable implementation of MI based on the log-determinant of the covariance matrix.</p> </li> <li> <p><code>SchurMI</code>: Computes MI using the Schur complement for improved numerical stability and computational efficiency.</p> </li> </ul> </li> <li> <p><code>AOptimal</code>: Computes the A-optimal design metric, which minimizes \\(Tr(K(X, X))\\).</p> </li> <li> <p><code>BOptimal</code>: Computes the B-optimal design metric, which minimizes \\(-Tr(K(X, X)^{-1})\\).</p> </li> <li> <p><code>DOptimal</code>: Computes the D-optimal design metric, which minimizes \\(|K(X, X)|\\).</p> </li> </ul>"},{"location":"api/objectives/index.html#sgptools.methods.get_objective","title":"<code>sgptools.methods.get_objective(objective_name)</code>","text":"<p>Retrieves an objective function class by its string name.</p> <p>Parameters:</p> Name Type Description Default <code>objective_name</code> <code>str</code> <p>The name of the objective function (e.g., 'MI', 'SLogMI').</p> required <p>Returns:</p> Type Description <code>Type[Objective]</code> <p>Type[Objective]: The class of the requested objective function.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the objective name is not found in the registered OBJECTIVES.</p> Usage <pre><code># Get the Mutual Information objective class\nMIObjectiveClass = get_objective('MI')\n# You can then instantiate it:\n# mi_instance = MIObjectiveClass(X_objective=..., kernel=..., noise_variance=...)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def get_objective(objective_name: str) -&gt; Type[Objective]:\n    \"\"\"\n    Retrieves an objective function class by its string name.\n\n    Args:\n        objective_name (str): The name of the objective function (e.g., 'MI', 'SLogMI').\n\n    Returns:\n        Type[Objective]: The class of the requested objective function.\n\n    Raises:\n        KeyError: If the objective name is not found in the registered OBJECTIVES.\n\n    Usage:\n        ```python\n        # Get the Mutual Information objective class\n        MIObjectiveClass = get_objective('MI')\n        # You can then instantiate it:\n        # mi_instance = MIObjectiveClass(X_objective=..., kernel=..., noise_variance=...)\n        ```\n    \"\"\"\n    if objective_name not in OBJECTIVES:\n        raise KeyError(f\"Objective '{objective_name}' not found. Available options: {list(OBJECTIVES.keys())}\")\n    return OBJECTIVES[objective_name]\n</code></pre>"},{"location":"api/objectives/a_optimal.html","title":"AOptimal","text":""},{"location":"api/objectives/a_optimal.html#sgptools.objectives.AOptimal","title":"<code>sgptools.objectives.AOptimal</code>","text":"<p>               Bases: <code>Objective</code></p> <p>Computes the A-optimal design metric.</p> <p>A-optimality aims to minimize the trace of the covariance matrix \\(Tr(K(X, X))\\). Since optimization algorithms typically minimize a function, this objective returns the negative trace, which is then maximized.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class  AOptimal(Objective):          \n    \"\"\"\n    Computes the A-optimal design metric.\n\n    A-optimality aims to minimize the trace of the\n    covariance matrix $Tr(K(X, X))$. Since optimization algorithms typically\n    minimize a function, this objective returns the negative trace, which\n    is then maximized.\n    \"\"\"  \n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the negative trace of the covariance matrix $-Tr(K(X, X))$.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           the objective is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed A-optimal metric value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume kernel is defined\n            # X_objective = np.random.rand(100, 2) # Not used by A-Optimal but required by base class\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            a_optimal_objective = AOptimal(\n                X_objective=X_objective,\n                kernel=kernel,\n                noise_variance=noise_variance\n            )\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            a_optimal_value = a_optimal_objective(X_sensing)\n            ```\n        \"\"\"\n        # K(X, X)\n        K_X_X = self.kernel(X)\n        trace_K_X_X = tf.linalg.trace(self.jitter_fn(K_X_X))\n        return -trace_K_X_X\n</code></pre>"},{"location":"api/objectives/a_optimal.html#sgptools.objectives.AOptimal.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the negative trace of the covariance matrix \\(-Tr(K(X, X))\\).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            the objective is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed A-optimal metric value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume kernel is defined\n# X_objective = np.random.rand(100, 2) # Not used by A-Optimal but required by base class\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\na_optimal_objective = AOptimal(\n    X_objective=X_objective,\n    kernel=kernel,\n    noise_variance=noise_variance\n)\nX_sensing = tf.constant(np.random.rand(10, 2))\na_optimal_value = a_optimal_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the negative trace of the covariance matrix $-Tr(K(X, X))$.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       the objective is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed A-optimal metric value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume kernel is defined\n        # X_objective = np.random.rand(100, 2) # Not used by A-Optimal but required by base class\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        a_optimal_objective = AOptimal(\n            X_objective=X_objective,\n            kernel=kernel,\n            noise_variance=noise_variance\n        )\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        a_optimal_value = a_optimal_objective(X_sensing)\n        ```\n    \"\"\"\n    # K(X, X)\n    K_X_X = self.kernel(X)\n    trace_K_X_X = tf.linalg.trace(self.jitter_fn(K_X_X))\n    return -trace_K_X_X\n</code></pre>"},{"location":"api/objectives/b_optimal.html","title":"BOptimal","text":""},{"location":"api/objectives/b_optimal.html#sgptools.objectives.BOptimal","title":"<code>sgptools.objectives.BOptimal</code>","text":"<p>               Bases: <code>Objective</code></p> <p>Computes the B-optimal design metric.</p> Refer to the following paper for more details <ul> <li>Approximate Sequential Optimization for Informative Path Planning [Ott et al., 2024]</li> </ul> <p>B-optimality minimizes the trace of the inverse of the covariance matrix  \\(-Tr(K(X, X)^{-1})\\). Since optimization  algorithms typically minimize a function, this objective returns  \\(Tr(K(X, X)^{-1})\\), which is then maximized.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class  BOptimal(Objective):     \n    \"\"\"\n    Computes the B-optimal design metric.\n\n    Refer to the following paper for more details:\n        - Approximate Sequential Optimization for Informative Path Planning [Ott et al., 2024]\n\n    B-optimality minimizes the trace of the inverse of the covariance matrix \n    $-Tr(K(X, X)^{-1})$. Since optimization \n    algorithms typically minimize a function, this objective returns \n    $Tr(K(X, X)^{-1})$, which is then maximized.\n    \"\"\"       \n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the trace of the inverse of the covariance matrix $Tr(K(X, X)^{-1})$.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           the objective is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed B-optimal metric value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume kernel is defined\n            # X_objective = np.random.rand(100, 2) # Not used by B-Optimal but required by base class\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            b_optimal_objective = BOptimal(\n                X_objective=X_objective,\n                kernel=kernel,\n                noise_variance=noise_variance\n            )\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            b_optimal_value = b_optimal_objective(X_sensing)\n            ```\n        \"\"\"\n        # K(X, X)\n        K_X_X = self.kernel(X)\n        inv_K_X_X = tf.linalg.inv(self.jitter_fn(K_X_X))\n        trace_inv_K_X_X = tf.linalg.trace(inv_K_X_X)\n        return trace_inv_K_X_X\n</code></pre>"},{"location":"api/objectives/b_optimal.html#sgptools.objectives.BOptimal.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the trace of the inverse of the covariance matrix \\(Tr(K(X, X)^{-1})\\).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            the objective is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed B-optimal metric value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume kernel is defined\n# X_objective = np.random.rand(100, 2) # Not used by B-Optimal but required by base class\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\nb_optimal_objective = BOptimal(\n    X_objective=X_objective,\n    kernel=kernel,\n    noise_variance=noise_variance\n)\nX_sensing = tf.constant(np.random.rand(10, 2))\nb_optimal_value = b_optimal_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the trace of the inverse of the covariance matrix $Tr(K(X, X)^{-1})$.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       the objective is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed B-optimal metric value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume kernel is defined\n        # X_objective = np.random.rand(100, 2) # Not used by B-Optimal but required by base class\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        b_optimal_objective = BOptimal(\n            X_objective=X_objective,\n            kernel=kernel,\n            noise_variance=noise_variance\n        )\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        b_optimal_value = b_optimal_objective(X_sensing)\n        ```\n    \"\"\"\n    # K(X, X)\n    K_X_X = self.kernel(X)\n    inv_K_X_X = tf.linalg.inv(self.jitter_fn(K_X_X))\n    trace_inv_K_X_X = tf.linalg.trace(inv_K_X_X)\n    return trace_inv_K_X_X\n</code></pre>"},{"location":"api/objectives/d_optimal.html","title":"DOptimal","text":""},{"location":"api/objectives/d_optimal.html#sgptools.objectives.DOptimal","title":"<code>sgptools.objectives.DOptimal</code>","text":"<p>               Bases: <code>Objective</code></p> <p>Computes the D-optimal design metric.</p> <p>D-optimality seeks to minimize the determinant of the posterior covariance matrix \\(|K(X, X)|\\). The objective returns the negative log-determinant of \\(K(X, X)\\), which is maximized during optimization. <code>tf.linalg.slogdet</code> is used for numerical stability.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class  DOptimal(Objective):            \n    \"\"\"\n    Computes the D-optimal design metric.\n\n    D-optimality seeks to minimize the determinant of the posterior\n    covariance matrix $|K(X, X)|$. The objective returns\n    the negative log-determinant of $K(X, X)$, which is maximized during\n    optimization. `tf.linalg.slogdet` is used for numerical stability.\n    \"\"\"\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the negative log-determinant of the covariance matrix $-log|K(X, X)|$.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           the objective is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed D-optimal metric value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume kernel is defined\n            # X_objective = np.random.rand(100, 2) # Not used by D-Optimal but required by base class\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            d_optimal_objective = DOptimal(\n                X_objective=X_objective,\n                kernel=kernel,\n                noise_variance=noise_variance\n            )\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            d_optimal_value = d_optimal_objective(X_sensing)\n            ```\n        \"\"\"\n        # K(X, X)\n        K_X_X = self.kernel(X)\n        _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n        return -logdet_K_X_X\n</code></pre>"},{"location":"api/objectives/d_optimal.html#sgptools.objectives.DOptimal.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the negative log-determinant of the covariance matrix \\(-log|K(X, X)|\\).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            the objective is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed D-optimal metric value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume kernel is defined\n# X_objective = np.random.rand(100, 2) # Not used by D-Optimal but required by base class\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\nd_optimal_objective = DOptimal(\n    X_objective=X_objective,\n    kernel=kernel,\n    noise_variance=noise_variance\n)\nX_sensing = tf.constant(np.random.rand(10, 2))\nd_optimal_value = d_optimal_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the negative log-determinant of the covariance matrix $-log|K(X, X)|$.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       the objective is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed D-optimal metric value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume kernel is defined\n        # X_objective = np.random.rand(100, 2) # Not used by D-Optimal but required by base class\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        d_optimal_objective = DOptimal(\n            X_objective=X_objective,\n            kernel=kernel,\n            noise_variance=noise_variance\n        )\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        d_optimal_value = d_optimal_objective(X_sensing)\n        ```\n    \"\"\"\n    # K(X, X)\n    K_X_X = self.kernel(X)\n    _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n    return -logdet_K_X_X\n</code></pre>"},{"location":"api/objectives/mi.html","title":"MI","text":""},{"location":"api/objectives/mi.html#sgptools.objectives.MI","title":"<code>sgptools.objectives.MI</code>","text":"<p>               Bases: <code>Objective</code></p> <p>Computes the Mutual Information (MI) between a fixed set of objective points (<code>X_objective</code>) and a variable set of input points (<code>X</code>).</p> <p>MI is calculated as: \\(MI(X; X_{objective}) = log|K(X,X)| + log|K(X_{objective},X_{objective})| - log|K(X \\cup X_{objective}, X \\cup X_{objective})|\\)</p> <p>Jitter is added to the diagonal of the covariance matrices to ensure numerical stability.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class MI(Objective):\n    \"\"\"\n    Computes the Mutual Information (MI) between a fixed set of objective points\n    (`X_objective`) and a variable set of input points (`X`).\n\n    MI is calculated as:\n    $MI(X; X_{objective}) = log|K(X,X)| + log|K(X_{objective},X_{objective})| - log|K(X \\cup X_{objective}, X \\cup X_{objective})|$\n\n    Jitter is added to the diagonal of the covariance matrices to ensure numerical stability.\n    \"\"\"\n\n    def __init__(self,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 jitter: float = 1e-6,\n                 cache: bool = True,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the Mutual Information (MI) objective.\n\n        Args:\n            X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                      or training data points) against which MI is computed.\n                                      Shape: (N, D).\n            kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n            noise_variance (float): The observed data noise variance, which is added to the jitter.\n            jitter (float): A small positive value to add for numerical stability to covariance\n                            matrix diagonals. Defaults to 1e-6.\n            cache (bool): If `True`, $K(X_{objective}, X_{objective})$ will be computed in the `_init__`\n                          and reused in the `__call__` for faster computation time. Defaults to True.\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        super().__init__(X_objective, kernel, noise_variance, jitter, **kwargs)\n        self.cache = cache\n        if self.cache:\n            # K(X_objective, X_objective)\n            self.K_obj_obj = self.kernel(self.X_objective)\n            # Compute log determinants\n            self.logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n                self.jitter_fn(self.K_obj_obj)))\n\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the Mutual Information for the given input points `X`.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           MI is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed Mutual Information value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume X_objective and kernel are defined\n            # X_objective = np.random.rand(100, 2)\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            mi_objective = MI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            mi_value = mi_objective(X_sensing)\n            ```\n        \"\"\"\n        # K(X_objective, X_objective)\n        if self.cache:\n            K_obj_obj = self.K_obj_obj\n        else:\n            K_obj_obj = self.kernel(self.X_objective)\n        # K(X, X)\n        K_X_X = self.kernel(X)\n        # K(X_objective U X, X_objective U X)\n        K_combined = self.kernel(tf.concat([self.X_objective, X], axis=0))\n\n        # Compute log determinants\n        if self.cache:\n            logdet_K_obj_obj = self.logdet_K_obj_obj\n        else:\n            logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n                self.jitter_fn(K_obj_obj)))\n        logdet_K_X_X = tf.math.log(tf.linalg.det(self.jitter_fn(K_X_X)))\n        logdet_K_combined = tf.math.log(\n            tf.linalg.det(self.jitter_fn(K_combined)))\n\n        # MI formula\n        mi = logdet_K_obj_obj + logdet_K_X_X - logdet_K_combined\n\n        return mi\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance for the MI objective.\n        This method is crucial for optimizing the GP hyperparameters externally\n        and having the objective function reflect those changes.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n            noise_variance (float): The updated data noise variance.\n        \"\"\"\n        super().update(kernel, noise_variance)\n        if self.cache:\n            # K(X_objective, X_objective)\n            self.K_obj_obj = self.kernel(self.X_objective)\n            # Compute log determinants\n            self.logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n                self.jitter_fn(self.K_obj_obj)))\n</code></pre>"},{"location":"api/objectives/mi.html#sgptools.objectives.MI.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the Mutual Information for the given input points <code>X</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            MI is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed Mutual Information value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume X_objective and kernel are defined\n# X_objective = np.random.rand(100, 2)\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\nmi_objective = MI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\nX_sensing = tf.constant(np.random.rand(10, 2))\nmi_value = mi_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the Mutual Information for the given input points `X`.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       MI is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed Mutual Information value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume X_objective and kernel are defined\n        # X_objective = np.random.rand(100, 2)\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        mi_objective = MI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        mi_value = mi_objective(X_sensing)\n        ```\n    \"\"\"\n    # K(X_objective, X_objective)\n    if self.cache:\n        K_obj_obj = self.K_obj_obj\n    else:\n        K_obj_obj = self.kernel(self.X_objective)\n    # K(X, X)\n    K_X_X = self.kernel(X)\n    # K(X_objective U X, X_objective U X)\n    K_combined = self.kernel(tf.concat([self.X_objective, X], axis=0))\n\n    # Compute log determinants\n    if self.cache:\n        logdet_K_obj_obj = self.logdet_K_obj_obj\n    else:\n        logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n            self.jitter_fn(K_obj_obj)))\n    logdet_K_X_X = tf.math.log(tf.linalg.det(self.jitter_fn(K_X_X)))\n    logdet_K_combined = tf.math.log(\n        tf.linalg.det(self.jitter_fn(K_combined)))\n\n    # MI formula\n    mi = logdet_K_obj_obj + logdet_K_X_X - logdet_K_combined\n\n    return mi\n</code></pre>"},{"location":"api/objectives/mi.html#sgptools.objectives.MI.__init__","title":"<code>__init__(X_objective, kernel, noise_variance, jitter=1e-06, cache=True, **kwargs)</code>","text":"<p>Initializes the Mutual Information (MI) objective.</p> <p>Parameters:</p> Name Type Description Default <code>X_objective</code> <code>ndarray</code> <p>The fixed set of data points (e.g., candidate locations                       or training data points) against which MI is computed.                       Shape: (N, D).</p> required <code>kernel</code> <code>Kernel</code> <p>The GPflow kernel function to compute covariances.</p> required <code>noise_variance</code> <code>float</code> <p>The observed data noise variance, which is added to the jitter.</p> required <code>jitter</code> <code>float</code> <p>A small positive value to add for numerical stability to covariance             matrix diagonals. Defaults to 1e-6.</p> <code>1e-06</code> <code>cache</code> <code>bool</code> <p>If <code>True</code>, \\(K(X_{objective}, X_{objective})\\) will be computed in the <code>_init__</code>           and reused in the <code>__call__</code> for faster computation time. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/objectives.py</code> <pre><code>def __init__(self,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             jitter: float = 1e-6,\n             cache: bool = True,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the Mutual Information (MI) objective.\n\n    Args:\n        X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                  or training data points) against which MI is computed.\n                                  Shape: (N, D).\n        kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n        noise_variance (float): The observed data noise variance, which is added to the jitter.\n        jitter (float): A small positive value to add for numerical stability to covariance\n                        matrix diagonals. Defaults to 1e-6.\n        cache (bool): If `True`, $K(X_{objective}, X_{objective})$ will be computed in the `_init__`\n                      and reused in the `__call__` for faster computation time. Defaults to True.\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    super().__init__(X_objective, kernel, noise_variance, jitter, **kwargs)\n    self.cache = cache\n    if self.cache:\n        # K(X_objective, X_objective)\n        self.K_obj_obj = self.kernel(self.X_objective)\n        # Compute log determinants\n        self.logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n            self.jitter_fn(self.K_obj_obj)))\n</code></pre>"},{"location":"api/objectives/mi.html#sgptools.objectives.MI.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance for the MI objective. This method is crucial for optimizing the GP hyperparameters externally and having the objective function reflect those changes.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>The updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>The updated data noise variance.</p> required Source code in <code>sgptools/objectives.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance for the MI objective.\n    This method is crucial for optimizing the GP hyperparameters externally\n    and having the objective function reflect those changes.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n        noise_variance (float): The updated data noise variance.\n    \"\"\"\n    super().update(kernel, noise_variance)\n    if self.cache:\n        # K(X_objective, X_objective)\n        self.K_obj_obj = self.kernel(self.X_objective)\n        # Compute log determinants\n        self.logdet_K_obj_obj = tf.math.log(tf.linalg.det(\n            self.jitter_fn(self.K_obj_obj)))\n</code></pre>"},{"location":"api/objectives/objective.html","title":"Objective","text":""},{"location":"api/objectives/objective.html#sgptools.objectives.Objective","title":"<code>sgptools.objectives.Objective</code>","text":"<p>Base class for objective functions used in optimization. Subclasses must implement the <code>__call__</code> method to define the objective.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class Objective:\n    \"\"\"\n    Base class for objective functions used in optimization.\n    Subclasses must implement the `__call__` method to define the objective.\n    \"\"\"\n\n    def __init__(self,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 jitter: float = 1e-6,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the base objective. This constructor primarily serves to define\n        the expected parameters for all objective subclasses.\n\n        Args:\n            X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                      or training data points) against which MI is computed.\n                                      Shape: (N, D).\n            kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n            noise_variance (float): The observed data noise variance, which is added to the jitter.\n            jitter (float): A small positive value to add for numerical stability to covariance\n                            matrix diagonals. Defaults to 1e-6.\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        self.X_objective = tf.constant(X_objective)\n        self.kernel = kernel\n        self.noise_variance = noise_variance\n        # Total jitter includes the noise variance\n        self._base_jitter = jitter\n        self.jitter_fn = lambda cov: jitter_fn(\n            cov, jitter=self._base_jitter + self.noise_variance)\n\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the objective value for a given set of input points `X`.\n        This method must be implemented by subclasses.\n\n        Args:\n            X (tf.Tensor): The input points for which the objective is to be computed.\n                           Shape: (M, D) where M is number of points, D is dimension.\n\n        Returns:\n            tf.Tensor: The computed objective value.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance for the MI objective.\n        This method is crucial for optimizing the GP hyperparameters externally\n        and having the objective function reflect those changes.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n            noise_variance (float): The updated data noise variance.\n        \"\"\"\n        # Update kernel's trainable variables (e.g., lengthscales, variance)\n        for self_var, var in zip(self.kernel.trainable_variables,\n                                 kernel.trainable_variables):\n            self_var.assign(var)\n\n        self.noise_variance = noise_variance\n        # Update the jitter function to reflect the new noise variance\n        self.jitter_fn = lambda cov: jitter_fn(\n            cov, jitter=self._base_jitter + self.noise_variance)\n</code></pre>"},{"location":"api/objectives/objective.html#sgptools.objectives.Objective.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the objective value for a given set of input points <code>X</code>. This method must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points for which the objective is to be computed.            Shape: (M, D) where M is number of points, D is dimension.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed objective value.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the objective value for a given set of input points `X`.\n    This method must be implemented by subclasses.\n\n    Args:\n        X (tf.Tensor): The input points for which the objective is to be computed.\n                       Shape: (M, D) where M is number of points, D is dimension.\n\n    Returns:\n        tf.Tensor: The computed objective value.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/objectives/objective.html#sgptools.objectives.Objective.__init__","title":"<code>__init__(X_objective, kernel, noise_variance, jitter=1e-06, **kwargs)</code>","text":"<p>Initializes the base objective. This constructor primarily serves to define the expected parameters for all objective subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X_objective</code> <code>ndarray</code> <p>The fixed set of data points (e.g., candidate locations                       or training data points) against which MI is computed.                       Shape: (N, D).</p> required <code>kernel</code> <code>Kernel</code> <p>The GPflow kernel function to compute covariances.</p> required <code>noise_variance</code> <code>float</code> <p>The observed data noise variance, which is added to the jitter.</p> required <code>jitter</code> <code>float</code> <p>A small positive value to add for numerical stability to covariance             matrix diagonals. Defaults to 1e-6.</p> <code>1e-06</code> <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/objectives.py</code> <pre><code>def __init__(self,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             jitter: float = 1e-6,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the base objective. This constructor primarily serves to define\n    the expected parameters for all objective subclasses.\n\n    Args:\n        X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                  or training data points) against which MI is computed.\n                                  Shape: (N, D).\n        kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n        noise_variance (float): The observed data noise variance, which is added to the jitter.\n        jitter (float): A small positive value to add for numerical stability to covariance\n                        matrix diagonals. Defaults to 1e-6.\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    self.X_objective = tf.constant(X_objective)\n    self.kernel = kernel\n    self.noise_variance = noise_variance\n    # Total jitter includes the noise variance\n    self._base_jitter = jitter\n    self.jitter_fn = lambda cov: jitter_fn(\n        cov, jitter=self._base_jitter + self.noise_variance)\n</code></pre>"},{"location":"api/objectives/objective.html#sgptools.objectives.Objective.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance for the MI objective. This method is crucial for optimizing the GP hyperparameters externally and having the objective function reflect those changes.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>The updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>The updated data noise variance.</p> required Source code in <code>sgptools/objectives.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance for the MI objective.\n    This method is crucial for optimizing the GP hyperparameters externally\n    and having the objective function reflect those changes.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n        noise_variance (float): The updated data noise variance.\n    \"\"\"\n    # Update kernel's trainable variables (e.g., lengthscales, variance)\n    for self_var, var in zip(self.kernel.trainable_variables,\n                             kernel.trainable_variables):\n        self_var.assign(var)\n\n    self.noise_variance = noise_variance\n    # Update the jitter function to reflect the new noise variance\n    self.jitter_fn = lambda cov: jitter_fn(\n        cov, jitter=self._base_jitter + self.noise_variance)\n</code></pre>"},{"location":"api/objectives/schur_mi.html","title":"SchurMI","text":""},{"location":"api/objectives/schur_mi.html#sgptools.objectives.SchurMI","title":"<code>sgptools.objectives.SchurMI</code>","text":"<p>               Bases: <code>SLogMI</code></p> <p>Computes Mutual Information (MI) using the Schur complement for improved numerical stability and computational efficiency.</p> <p>This method leverages the properties of block matrix determinants to reformulate the MI calculation. The standard MI formula is: \\(MI = \\log|K_{XX}| + \\log|K_{oo}| - \\log|K_{combined}|\\) where \\(K_{XX} = K(X, X)\\), \\(K_{oo} = K(X_{objective}, X_{objective})\\), and \\(K_{combined}\\) is the kernel of the union of the points.</p> <p>Using the Schur complement identity for determinants, \\(\\log|K_{combined}| = \\log|K_{oo}| + \\log|K_{XX} - K_{Xo} K_{oo}^{-1} K_{oX}|\\), the MI calculation simplifies to: \\(MI = \\log|K_{XX}| - \\log|SchurComplement|\\) where the Schur Complement is \\(K_{XX} - K_{Xo} K_{oo}^{-1} K_{oX}\\).</p> <p>This approach is particularly efficient when the objective is evaluated multiple times for different sensing locations \\(X\\) but with a fixed set of \\(X_{objective}\\) points. By caching the inverse of \\(K_{oo}\\), we avoid costly recomputations. Like <code>SLogMI</code>, this class uses <code>tf.linalg.slogdet</code> and adds jitter for robust computation.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class SchurMI(SLogMI):\n    \"\"\"\n    Computes Mutual Information (MI) using the Schur complement for improved\n    numerical stability and computational efficiency.\n\n    This method leverages the properties of block matrix determinants to reformulate\n    the MI calculation. The standard MI formula is:\n    $MI = \\\\log|K_{XX}| + \\\\log|K_{oo}| - \\\\log|K_{combined}|$\n    where $K_{XX} = K(X, X)$, $K_{oo} = K(X_{objective}, X_{objective})$, and\n    $K_{combined}$ is the kernel of the union of the points.\n\n    Using the Schur complement identity for determinants,\n    $\\\\log|K_{combined}| = \\\\log|K_{oo}| + \\\\log|K_{XX} - K_{Xo} K_{oo}^{-1} K_{oX}|$,\n    the MI calculation simplifies to:\n    $MI = \\\\log|K_{XX}| - \\\\log|SchurComplement|$\n    where the Schur Complement is $K_{XX} - K_{Xo} K_{oo}^{-1} K_{oX}$.\n\n    This approach is particularly efficient when the objective is evaluated\n    multiple times for different sensing locations $X$ but with a fixed set of\n    $X_{objective}$ points. By caching the inverse of $K_{oo}$, we avoid costly\n    recomputations. Like `SLogMI`, this class uses `tf.linalg.slogdet` and\n    adds jitter for robust computation.\n    \"\"\"\n    def __init__(self,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 jitter: float = 1e-6,\n                 cache: bool = True,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the SchurMI objective.\n\n        Args:\n            X_objective (np.ndarray): The fixed set of data points against which\n                                      MI is computed. Shape: (N, D).\n            kernel (gpflow.kernels.Kernel): The GPflow kernel to compute covariances.\n            noise_variance (float): The observed data noise variance.\n            jitter (float): A small value added to the diagonal of covariance\n                            matrices for numerical stability. Defaults to 1e-6.\n            cache (bool): If `True`, the inverse of $K(X_{objective}, X_{objective})$\n                          is pre-computed and cached to accelerate subsequent MI\n                          calculations. Defaults to True.\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        super().__init__(X_objective, kernel, noise_variance, jitter, cache=False, **kwargs)\n        self.cache = cache\n        if self.cache:\n            # K(X_objective, X_objective)\n            self.K_obj_obj = self.kernel(self.X_objective)\n            # Compute the inverse\n            self.inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(self.K_obj_obj))\n\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the Mutual Information for the input points `X` using the\n        Schur complement method.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           MI is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed Mutual Information value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume X_objective and kernel are defined\n            # X_objective = np.random.rand(100, 2)\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            schur_mi_objective = SchurMI(\n                X_objective=X_objective,\n                kernel=kernel,\n                noise_variance=noise_variance\n            )\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            mi_value = schur_mi_objective(X_sensing)\n            ```\n        \"\"\"\n        if self.cache:\n            inv_K_obj_obj = self.inv_K_obj_obj\n        else:\n            # K(X_objective, X_objective)\n            K_obj_obj = self.kernel(self.X_objective)\n            # Compute the inverse\n            inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(K_obj_obj))\n\n        K_X_X = self.kernel(X)\n        _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n        K_X_obj = self.kernel(X, self.X_objective)\n        transpose_K_X_obj = tf.transpose(K_X_obj)\n        schur = K_X_X - K_X_obj @ inv_K_obj_obj @ transpose_K_X_obj\n        _, schur_det = tf.linalg.slogdet(self.jitter_fn(schur))\n        mi = logdet_K_X_X - schur_det\n        return mi\n\n    def update(self, kernel: gpflow.kernels.Kernel,\n               noise_variance: float) -&gt; None:\n        \"\"\"\n        Updates the kernel and noise variance for the MI objective.\n        This method is crucial for optimizing the GP hyperparameters externally\n        and having the objective function reflect those changes.\n\n        Args:\n            kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n            noise_variance (float): The updated data noise variance.\n        \"\"\"\n        super().update(kernel, noise_variance)\n        if self.cache:\n            # K(X_objective, X_objective)\n            self.K_obj_obj = self.kernel(self.X_objective)\n            # Compute the inverse\n            self.inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(self.K_obj_obj))\n</code></pre>"},{"location":"api/objectives/schur_mi.html#sgptools.objectives.SchurMI.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the Mutual Information for the input points <code>X</code> using the Schur complement method.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            MI is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed Mutual Information value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume X_objective and kernel are defined\n# X_objective = np.random.rand(100, 2)\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\nschur_mi_objective = SchurMI(\n    X_objective=X_objective,\n    kernel=kernel,\n    noise_variance=noise_variance\n)\nX_sensing = tf.constant(np.random.rand(10, 2))\nmi_value = schur_mi_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the Mutual Information for the input points `X` using the\n    Schur complement method.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       MI is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed Mutual Information value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume X_objective and kernel are defined\n        # X_objective = np.random.rand(100, 2)\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        schur_mi_objective = SchurMI(\n            X_objective=X_objective,\n            kernel=kernel,\n            noise_variance=noise_variance\n        )\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        mi_value = schur_mi_objective(X_sensing)\n        ```\n    \"\"\"\n    if self.cache:\n        inv_K_obj_obj = self.inv_K_obj_obj\n    else:\n        # K(X_objective, X_objective)\n        K_obj_obj = self.kernel(self.X_objective)\n        # Compute the inverse\n        inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(K_obj_obj))\n\n    K_X_X = self.kernel(X)\n    _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n    K_X_obj = self.kernel(X, self.X_objective)\n    transpose_K_X_obj = tf.transpose(K_X_obj)\n    schur = K_X_X - K_X_obj @ inv_K_obj_obj @ transpose_K_X_obj\n    _, schur_det = tf.linalg.slogdet(self.jitter_fn(schur))\n    mi = logdet_K_X_X - schur_det\n    return mi\n</code></pre>"},{"location":"api/objectives/schur_mi.html#sgptools.objectives.SchurMI.__init__","title":"<code>__init__(X_objective, kernel, noise_variance, jitter=1e-06, cache=True, **kwargs)</code>","text":"<p>Initializes the SchurMI objective.</p> <p>Parameters:</p> Name Type Description Default <code>X_objective</code> <code>ndarray</code> <p>The fixed set of data points against which                       MI is computed. Shape: (N, D).</p> required <code>kernel</code> <code>Kernel</code> <p>The GPflow kernel to compute covariances.</p> required <code>noise_variance</code> <code>float</code> <p>The observed data noise variance.</p> required <code>jitter</code> <code>float</code> <p>A small value added to the diagonal of covariance             matrices for numerical stability. Defaults to 1e-6.</p> <code>1e-06</code> <code>cache</code> <code>bool</code> <p>If <code>True</code>, the inverse of \\(K(X_{objective}, X_{objective})\\)           is pre-computed and cached to accelerate subsequent MI           calculations. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/objectives.py</code> <pre><code>def __init__(self,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             jitter: float = 1e-6,\n             cache: bool = True,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the SchurMI objective.\n\n    Args:\n        X_objective (np.ndarray): The fixed set of data points against which\n                                  MI is computed. Shape: (N, D).\n        kernel (gpflow.kernels.Kernel): The GPflow kernel to compute covariances.\n        noise_variance (float): The observed data noise variance.\n        jitter (float): A small value added to the diagonal of covariance\n                        matrices for numerical stability. Defaults to 1e-6.\n        cache (bool): If `True`, the inverse of $K(X_{objective}, X_{objective})$\n                      is pre-computed and cached to accelerate subsequent MI\n                      calculations. Defaults to True.\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    super().__init__(X_objective, kernel, noise_variance, jitter, cache=False, **kwargs)\n    self.cache = cache\n    if self.cache:\n        # K(X_objective, X_objective)\n        self.K_obj_obj = self.kernel(self.X_objective)\n        # Compute the inverse\n        self.inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(self.K_obj_obj))\n</code></pre>"},{"location":"api/objectives/schur_mi.html#sgptools.objectives.SchurMI.update","title":"<code>update(kernel, noise_variance)</code>","text":"<p>Updates the kernel and noise variance for the MI objective. This method is crucial for optimizing the GP hyperparameters externally and having the objective function reflect those changes.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>The updated GPflow kernel function.</p> required <code>noise_variance</code> <code>float</code> <p>The updated data noise variance.</p> required Source code in <code>sgptools/objectives.py</code> <pre><code>def update(self, kernel: gpflow.kernels.Kernel,\n           noise_variance: float) -&gt; None:\n    \"\"\"\n    Updates the kernel and noise variance for the MI objective.\n    This method is crucial for optimizing the GP hyperparameters externally\n    and having the objective function reflect those changes.\n\n    Args:\n        kernel (gpflow.kernels.Kernel): The updated GPflow kernel function.\n        noise_variance (float): The updated data noise variance.\n    \"\"\"\n    super().update(kernel, noise_variance)\n    if self.cache:\n        # K(X_objective, X_objective)\n        self.K_obj_obj = self.kernel(self.X_objective)\n        # Compute the inverse\n        self.inv_K_obj_obj = tf.linalg.inv(self.jitter_fn(self.K_obj_obj))\n</code></pre>"},{"location":"api/objectives/slog_mi.html","title":"SLogMI","text":""},{"location":"api/objectives/slog_mi.html#sgptools.objectives.SLogMI","title":"<code>sgptools.objectives.SLogMI</code>","text":"<p>               Bases: <code>MI</code></p> <p>Computes the Mutual Information (MI) using <code>tf.linalg.slogdet</code> for numerical stability, especially for large or ill-conditioned covariance matrices.</p> <p>The slogdet (sign and log determinant) method computes the sign and the natural logarithm of the absolute value of the determinant of a square matrix. This is more numerically stable than computing the determinant directly and then taking the logarithm, as <code>tf.linalg.det</code> can return very small or very large numbers that lead to underflow/overflow when <code>tf.math.log</code> is applied.</p> <p>Jitter is also added to the diagonal for additional numerical stability.</p> Source code in <code>sgptools/objectives.py</code> <pre><code>class SLogMI(MI):\n    \"\"\"\n    Computes the Mutual Information (MI) using `tf.linalg.slogdet` for numerical stability,\n    especially for large or ill-conditioned covariance matrices.\n\n    The slogdet (sign and log determinant) method computes the sign and the natural\n    logarithm of the absolute value of the determinant of a square matrix.\n    This is more numerically stable than computing the determinant directly and then\n    taking the logarithm, as `tf.linalg.det` can return very small or very large\n    numbers that lead to underflow/overflow when `tf.math.log` is applied.\n\n    Jitter is also added to the diagonal for additional numerical stability.\n    \"\"\"\n\n    def __init__(self,\n                 X_objective: np.ndarray,\n                 kernel: gpflow.kernels.Kernel,\n                 noise_variance: float,\n                 jitter: float = 1e-6,\n                 cache: bool = True,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the Mutual Information (MI) objective based on `tf.linalg.slogdet`.\n\n        Args:\n            X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                      or training data points) against which MI is computed.\n                                      Shape: (N, D).\n            kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n            noise_variance (float): The observed data noise variance, which is added to the jitter.\n            jitter (float): A small positive value to add for numerical stability to covariance\n                            matrix diagonals. Defaults to 1e-6.\n            cache (bool): If `True`, $K(X_{objective}, X_{objective})$ will be computed in the `_init__`\n                          and reused in the `__call__` for faster computation time. Defaults to True.\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        super().__init__(X_objective, kernel, noise_variance, jitter, cache=False, **kwargs)\n        self.cache = cache\n        if self.cache:\n            # K(X_objective, X_objective)\n            self.K_obj_obj = self.kernel(self.X_objective)\n            # Compute log determinants\n            _, self.logdet_K_obj_obj = tf.linalg.slogdet(self.jitter_fn(self.K_obj_obj))\n\n    def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"\n        Computes the Mutual Information for the given input points `X` using `tf.linalg.slogdet`.\n\n        Args:\n            X (tf.Tensor): The input points (e.g., sensing locations) for which\n                           MI is to be computed. Shape: (M, D).\n\n        Returns:\n            tf.Tensor: The computed Mutual Information value.\n\n        Usage:\n            ```python\n            import gpflow\n            import numpy as np\n            # Assume X_objective and kernel are defined\n            # X_objective = np.random.rand(100, 2)\n            # kernel = gpflow.kernels.SquaredExponential()\n            # noise_variance = 0.1\n\n            slogmi_objective = SLogMI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\n            X_sensing = tf.constant(np.random.rand(10, 2))\n            mi_value = slogmi_objective(X_sensing)\n            ```\n        \"\"\"\n        # K(X_objective, X_objective)\n        if self.cache:\n            K_obj_obj = self.K_obj_obj\n        else:\n            K_obj_obj = self.kernel(self.X_objective)\n        # K(X, X)\n        K_X_X = self.kernel(X)\n        # K(X_objective U X, X_objective U X)\n        K_combined = self.kernel(tf.concat([self.X_objective, X], axis=0))\n\n        # Compute log determinants using slogdet for numerical stability\n        if self.cache:\n            logdet_K_obj_obj = self.logdet_K_obj_obj\n        else:\n            _, logdet_K_obj_obj = tf.linalg.slogdet(self.jitter_fn(K_obj_obj))\n\n        _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n        _, logdet_K_combined = tf.linalg.slogdet(self.jitter_fn(K_combined))\n\n        # MI formula\n        mi = logdet_K_obj_obj + logdet_K_X_X - logdet_K_combined\n\n        return mi\n</code></pre>"},{"location":"api/objectives/slog_mi.html#sgptools.objectives.SLogMI.__call__","title":"<code>__call__(X)</code>","text":"<p>Computes the Mutual Information for the given input points <code>X</code> using <code>tf.linalg.slogdet</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>The input points (e.g., sensing locations) for which            MI is to be computed. Shape: (M, D).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>tf.Tensor: The computed Mutual Information value.</p> Usage <pre><code>import gpflow\nimport numpy as np\n# Assume X_objective and kernel are defined\n# X_objective = np.random.rand(100, 2)\n# kernel = gpflow.kernels.SquaredExponential()\n# noise_variance = 0.1\n\nslogmi_objective = SLogMI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\nX_sensing = tf.constant(np.random.rand(10, 2))\nmi_value = slogmi_objective(X_sensing)\n</code></pre> Source code in <code>sgptools/objectives.py</code> <pre><code>def __call__(self, X: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"\n    Computes the Mutual Information for the given input points `X` using `tf.linalg.slogdet`.\n\n    Args:\n        X (tf.Tensor): The input points (e.g., sensing locations) for which\n                       MI is to be computed. Shape: (M, D).\n\n    Returns:\n        tf.Tensor: The computed Mutual Information value.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n        # Assume X_objective and kernel are defined\n        # X_objective = np.random.rand(100, 2)\n        # kernel = gpflow.kernels.SquaredExponential()\n        # noise_variance = 0.1\n\n        slogmi_objective = SLogMI(X_objective=X_objective, kernel=kernel, noise_variance=noise_variance)\n        X_sensing = tf.constant(np.random.rand(10, 2))\n        mi_value = slogmi_objective(X_sensing)\n        ```\n    \"\"\"\n    # K(X_objective, X_objective)\n    if self.cache:\n        K_obj_obj = self.K_obj_obj\n    else:\n        K_obj_obj = self.kernel(self.X_objective)\n    # K(X, X)\n    K_X_X = self.kernel(X)\n    # K(X_objective U X, X_objective U X)\n    K_combined = self.kernel(tf.concat([self.X_objective, X], axis=0))\n\n    # Compute log determinants using slogdet for numerical stability\n    if self.cache:\n        logdet_K_obj_obj = self.logdet_K_obj_obj\n    else:\n        _, logdet_K_obj_obj = tf.linalg.slogdet(self.jitter_fn(K_obj_obj))\n\n    _, logdet_K_X_X = tf.linalg.slogdet(self.jitter_fn(K_X_X))\n    _, logdet_K_combined = tf.linalg.slogdet(self.jitter_fn(K_combined))\n\n    # MI formula\n    mi = logdet_K_obj_obj + logdet_K_X_X - logdet_K_combined\n\n    return mi\n</code></pre>"},{"location":"api/objectives/slog_mi.html#sgptools.objectives.SLogMI.__init__","title":"<code>__init__(X_objective, kernel, noise_variance, jitter=1e-06, cache=True, **kwargs)</code>","text":"<p>Initializes the Mutual Information (MI) objective based on <code>tf.linalg.slogdet</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X_objective</code> <code>ndarray</code> <p>The fixed set of data points (e.g., candidate locations                       or training data points) against which MI is computed.                       Shape: (N, D).</p> required <code>kernel</code> <code>Kernel</code> <p>The GPflow kernel function to compute covariances.</p> required <code>noise_variance</code> <code>float</code> <p>The observed data noise variance, which is added to the jitter.</p> required <code>jitter</code> <code>float</code> <p>A small positive value to add for numerical stability to covariance             matrix diagonals. Defaults to 1e-6.</p> <code>1e-06</code> <code>cache</code> <code>bool</code> <p>If <code>True</code>, \\(K(X_{objective}, X_{objective})\\) will be computed in the <code>_init__</code>           and reused in the <code>__call__</code> for faster computation time. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>sgptools/objectives.py</code> <pre><code>def __init__(self,\n             X_objective: np.ndarray,\n             kernel: gpflow.kernels.Kernel,\n             noise_variance: float,\n             jitter: float = 1e-6,\n             cache: bool = True,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the Mutual Information (MI) objective based on `tf.linalg.slogdet`.\n\n    Args:\n        X_objective (np.ndarray): The fixed set of data points (e.g., candidate locations\n                                  or training data points) against which MI is computed.\n                                  Shape: (N, D).\n        kernel (gpflow.kernels.Kernel): The GPflow kernel function to compute covariances.\n        noise_variance (float): The observed data noise variance, which is added to the jitter.\n        jitter (float): A small positive value to add for numerical stability to covariance\n                        matrix diagonals. Defaults to 1e-6.\n        cache (bool): If `True`, $K(X_{objective}, X_{objective})$ will be computed in the `_init__`\n                      and reused in the `__call__` for faster computation time. Defaults to True.\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    super().__init__(X_objective, kernel, noise_variance, jitter, cache=False, **kwargs)\n    self.cache = cache\n    if self.cache:\n        # K(X_objective, X_objective)\n        self.K_obj_obj = self.kernel(self.X_objective)\n        # Compute log determinants\n        _, self.logdet_K_obj_obj = tf.linalg.slogdet(self.jitter_fn(self.K_obj_obj))\n</code></pre>"},{"location":"api/utils/index.html","title":"<code>utils</code>: Utility Functions","text":"<p>This module provides a collection of helper functions for data processing, model training, and other tasks.</p> <ul> <li> <p><code>data</code>: Contains the <code>Dataset</code> class, which handles loading, preprocessing, and sampling of data from various sources, including GeoTIFF files and synthetic data generation.</p> </li> <li> <p><code>gpflow</code>: Provides utility functions for training GPflow models, such as <code>get_model_params</code> for finding optimal kernel hyperparameters and <code>optimize_model</code> for running the optimization. It also includes a <code>TraceInducingPts</code> class to monitor the movement of inducing points during training.</p> </li> <li> <p><code>misc</code>: A collection of miscellaneous helper functions, including <code>get_inducing_pts</code> for selecting initial inducing points (via k-means or random sampling), <code>cont2disc</code> for mapping continuous solutions to a discrete set of candidates, and <code>polygon2candidates</code> for sampling points within a polygon.</p> </li> <li> <p><code>tsp</code>: Provides functionality for solving the Traveling Salesperson Problem (TSP) using Google's OR-Tools. The <code>run_tsp</code> function can find effient paths for single or multiple vehicles, with optional start and end nodes, and can resample the resulting paths to have a fixed number of points.</p> </li> </ul>"},{"location":"api/utils/data.html","title":"Data","text":""},{"location":"api/utils/data.html#sgptools.utils.data","title":"<code>sgptools.utils.data</code>","text":""},{"location":"api/utils/data.html#sgptools.utils.data.Dataset","title":"<code>Dataset</code>","text":"<p>A class to load, preprocess, and manage access to a dataset for sensor placement and informative path planning tasks.</p> <p>It handles the following operations:</p> <ul> <li>Loading from a GeoTIFF file, loading from a numpy array, and generating a synthetic dataset.</li> <li>Sampling training, testing, and candidate points from valid (non-NaN) locations.</li> <li>Standardizing both the input coordinates (X) and the labels (y) using <code>StandardScaler</code>.</li> <li>Providing methods to retrieve different subsets of the data (train, test, candidates) and to sample sensor data at specified locations or along a path.</li> </ul> <p>The dataset is expected to be a 2D array where each element represents a label (e.g., elevation, temperature, environmental reading).</p> Source code in <code>sgptools/utils/data.py</code> <pre><code>class Dataset:\n    \"\"\"\n    A class to load, preprocess, and manage access to a dataset for sensor placement\n    and informative path planning tasks.\n\n    It handles the following operations:\n\n    * Loading from a GeoTIFF file, loading from a numpy array, and generating a synthetic dataset.\n    * Sampling training, testing, and candidate points from valid (non-NaN) locations.\n    * Standardizing both the input coordinates (X) and the labels (y) using `StandardScaler`.\n    * Providing methods to retrieve different subsets of the data (train, test, candidates)\n    and to sample sensor data at specified locations or along a path.\n\n    The dataset is expected to be a 2D array where each element represents a label\n    (e.g., elevation, temperature, environmental reading).\n    \"\"\"\n\n    def __init__(self,\n                 dataset_path: Optional[str] = None,\n                 num_train: int = 1000,\n                 num_test: int = 2500,\n                 num_candidates: int = 150,\n                 verbose: bool = True,\n                 data=None,\n                 dtype=np.float64,\n                 **kwargs: Any):\n        \"\"\"\n        Initializes the Dataset class.\n\n        Args:\n            dataset_path (Optional[str]): Path to the dataset file (e.g., '.tif'). If None,\n                                          a synthetic dataset will be generated. Defaults to None.\n                                          Alternatively, pass an array of data to the constructor\n                                          with the `data` argument to use a custom dataset.\n            num_train (int): Number of training points to sample from the dataset. Defaults to 1000.\n            num_test (int): Number of testing points to sample from the dataset. Defaults to 2500.\n            num_candidates (int): Number of candidate points for potential sensor placements\n                                  to sample from the dataset. Defaults to 150.\n            verbose (bool): If `True`, print details about dataset loading, sampling, and preprocessing.\n                            Defaults to True.\n            data (Optional[np.ndarray]): (height, width, d); 2D n-dimensional array of data.\n            dtype (Optional[np.dtype]): The type of the output arrays. If dtype is not given, \n                                        it will be set to np.float64.\n            **kwargs: Additional keyword arguments passed to `prep_tif_dataset` or `prep_synthetic_dataset`.\n        \"\"\"\n        self.verbose = verbose\n        self.dtype = dtype\n\n        # Load/Create the data\n        if data is not None:\n            self.y = data\n        elif dataset_path is not None:\n            self.y = prep_tif_dataset(dataset_path=dataset_path,\n                                      verbose=verbose,\n                                      **kwargs)\n        else:\n            self.y = prep_synthetic_dataset(**kwargs)\n\n        # Store original dimensions for reshaping\n        w, h = self.y.shape[0], self.y.shape[1]\n        if self.verbose:\n            print(f\"Original dataset shape: {self.y.shape}\")\n\n        # Get valid points (non-NaN labels)\n        mask = np.where(np.isfinite(self.y))\n        X_valid_pixel_coords = np.column_stack((mask[0], mask[1]))\n\n        # Sample training, testing, and candidate points from valid pixel coordinates\n        # `get_inducing_pts` with random=True is used for random sampling\n        X_train_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                                num_train,\n                                                random=True)\n        y_train_raw = self.y[X_train_pixel_coords[:, 0],\n                             X_train_pixel_coords[:, 1]].reshape(-1, 1)\n\n        # If num_test is equal to dataset size, return test data in original order, enables plotting with imshow\n        if self.y.shape[0] * self.y.shape[1] == num_test:\n            X_test_pixel_coords = X_valid_pixel_coords\n            y_test_raw = self.y.reshape(-1, 1)\n        else:\n            X_test_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                                   num_test,\n                                                   random=True)\n            y_test_raw = self.y[X_test_pixel_coords[:, 0],\n                                X_test_pixel_coords[:, 1]].reshape(-1, 1)\n\n        X_candidates_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                                     num_candidates,\n                                                     random=True)\n\n        # Standardize dataset X coordinates (pixel coords to normalized space)\n        self.X_scaler = StandardScaler()\n        self.X_scaler.fit(X_train_pixel_coords)\n\n        # Adjust X_scaler's variance/scale to ensure uniform scaling across dimensions\n        # and to scale the data to have an extent of at least 10.0 in each dimension.\n        # This ensures consistency and prevents issues with very small scales.\n        ind = np.argmax(self.X_scaler.var_)\n        self.X_scaler.var_ = np.ones_like(\n            self.X_scaler.var_) * self.X_scaler.var_[ind]\n        self.X_scaler.scale_ = np.ones_like(\n            self.X_scaler.scale_) * self.X_scaler.scale_[ind]\n        self.X_scaler.scale_ /= 10.0  # Scale to ensure an extent of ~10 units\n\n        self.X_train = self.X_scaler.transform(X_train_pixel_coords)\n        self.X_train = self.X_train.astype(self.dtype)\n        self.X_test = self.X_scaler.transform(X_test_pixel_coords)\n        self.X_test = self.X_test.astype(self.dtype)\n        self.candidates = self.X_scaler.transform(X_candidates_pixel_coords)\n        self.candidates = self.candidates.astype(self.dtype)\n\n        # Standardize dataset labels (y values)\n        self.y_scaler = StandardScaler()\n        self.y_scaler.fit(y_train_raw)\n\n        self.y_train = self.y_scaler.transform(y_train_raw)\n        self.y_train = self.y_train.astype(self.dtype)\n        self.y_test = self.y_scaler.transform(y_test_raw)\n        self.y_test = self.y_test.astype(self.dtype)\n\n        # Transform the entire dataset's labels for consistency\n        self.y = self.y_scaler.transform(self.y.reshape(-1, 1)).reshape(w, h)\n        self.y = self.y.astype(self.dtype)\n\n        if self.verbose:\n            print(\n                f\"Training data shapes (X, y): {self.X_train.shape}, {self.y_train.shape}\"\n            )\n            print(\n                f\"Testing data shapes (X, y): {self.X_test.shape}, {self.y_test.shape}\"\n            )\n            print(f\"Candidate data shape (X): {self.candidates.shape}\")\n            print(\"Dataset loaded and preprocessed successfully.\")\n\n    def get_train(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Retrieves the preprocessed training data.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                           - X_train (np.ndarray): (num_train, 2); Normalized training input features.\n                                           - y_train (np.ndarray): (num_train, 1); Standardized training labels.\n\n        Usage:\n            ```python\n            # dataset_obj = Dataset(...)\n            # X_train, y_train = dataset_obj.get_train()\n            ```\n        \"\"\"\n        return self.X_train, self.y_train\n\n    def get_test(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Retrieves the preprocessed testing data.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                           - X_test (np.ndarray): (num_test, 2); Normalized testing input features.\n                                           - y_test (np.ndarray): (num_test, 1); Standardized testing labels.\n\n        Usage:\n            ```python\n            # dataset_obj = Dataset(...)\n            # X_test, y_test = dataset_obj.get_test()\n            ```\n        \"\"\"\n        return self.X_test, self.y_test\n\n    def get_candidates(self) -&gt; np.ndarray:\n        \"\"\"\n        Retrieves the preprocessed candidate locations for sensor placement.\n\n        Returns:\n            np.ndarray: (num_candidates, 2); Normalized candidate locations.\n\n        Usage:\n            ```python\n            # dataset_obj = Dataset(...)\n            # candidates = dataset_obj.get_candidates()\n            ```\n        \"\"\"\n        return self.candidates\n\n    def get_sensor_data(\n            self,\n            locations: np.ndarray,\n            continuous_sening: bool = False,\n            max_samples: int = 500) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Samples sensor data (labels) at specified normalized locations.\n        Can simulate discrete point sensing or continuous path sensing by interpolation.\n\n        Args:\n            locations (np.ndarray): (N, 2); Array of locations (normalized x, y coordinates)\n                                    where sensor data is to be sampled.\n            continuous_sening (bool): If `True`, interpolates additional points between\n                                      the given `locations` to simulate sensing along a path.\n                                      Defaults to `False`.\n            max_samples (int): Maximum number of samples to return if `continuous_sening`\n                               results in too many points. If the number of interpolated\n                               points exceeds `max_samples`, a random subset will be returned.\n                               Defaults to 500.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                           - sampled_locations (np.ndarray): (M, 2); Normalized locations\n                                                                             where sensor data was effectively sampled.\n                                           - sampled_data (np.ndarray): (M, 1); Standardized sensor data\n                                                                        sampled at these locations.\n                                           Returns empty arrays if no valid data points are found.\n\n        Usage:\n            ```python\n            # dataset_obj = Dataset(...)\n            # X_path_normalized = np.array([[0.1, 0.2], [0.5, 0.7], [0.9, 0.8]])\n            # # Discrete sensing\n            # sensed_X_discrete, sensed_y_discrete = dataset_obj.get_sensor_data(X_path_normalized)\n            # # Continuous sensing with interpolation\n            # sensed_X_continuous, sensed_y_continuous = dataset_obj.get_sensor_data(X_path_normalized, continuous_sening=True, max_samples=100)\n            ```\n        \"\"\"\n        # Convert normalized locations back to original pixel coordinates\n        locations_pixel_coords = self.X_scaler.inverse_transform(locations)\n\n        # Round locations to nearest integer and clip to valid dataset boundaries\n        locations_pixel_coords = np.round(locations_pixel_coords).astype(int)\n        locations_pixel_coords[:, 0] = np.clip(locations_pixel_coords[:, 0], 0,\n                                               self.y.shape[0] - 1)\n        locations_pixel_coords[:, 1] = np.clip(locations_pixel_coords[:, 1], 0,\n                                               self.y.shape[1] - 1)\n\n        # If continuous sensing is enabled, interpolate between points using skimage.draw.line\n        if continuous_sening:\n            interpolated_locs: List[np.ndarray] = []\n            if locations_pixel_coords.shape[0] &gt; 1:\n                # Iterate through pairs of consecutive points to draw lines\n                for i in range(locations_pixel_coords.shape[0] - 1):\n                    loc1 = locations_pixel_coords[i]\n                    loc2 = locations_pixel_coords[i + 1]\n                    # line returns (row_coords, col_coords)\n                    rr, cc = line(loc1[0], loc1[1], loc2[0], loc2[1])\n                    interpolated_locs.append(np.column_stack((rr, cc)))\n\n            # If there's only one point, or if no lines were drawn (e.g., due to identical consecutive points),\n            # still include the initial locations.\n            if not interpolated_locs:\n                # If continuous sensing is true but no path, just return the initial locations if any\n                if locations_pixel_coords.shape[0] &gt; 0:\n                    locations_pixel_coords = locations_pixel_coords\n                else:\n                    return np.empty((0, 2)), np.empty((0, 1))\n            else:\n                locations_pixel_coords = np.concatenate(interpolated_locs,\n                                                        axis=0)\n\n        # Ensure that locations_pixel_coords is not empty before indexing\n        if locations_pixel_coords.shape[0] == 0:\n            return np.empty((0, 2)), np.empty((0, 1))\n\n        # Ensure indices are within bounds (should be handled by clip, but double check)\n        valid_rows = np.clip(locations_pixel_coords[:, 0], 0,\n                             self.y.shape[0] - 1)\n        valid_cols = np.clip(locations_pixel_coords[:, 1], 0,\n                             self.y.shape[1] - 1)\n\n        # Extract data at the specified pixel locations\n        data = self.y[valid_rows, valid_cols].reshape(-1, 1)\n\n        # Drop NaN values from data and corresponding locations\n        valid_mask = np.isfinite(data.ravel())\n        locations_pixel_coords = locations_pixel_coords[valid_mask]\n        data = data[valid_mask]\n\n        # Re-normalize valid locations\n        if locations_pixel_coords.shape[0] == 0:\n            return np.empty((0, 2)), np.empty((0, 1))\n        locations_normalized = self.X_scaler.transform(locations_pixel_coords)\n\n        # Limit the number of samples to max_samples if needed\n        if len(locations_normalized) &gt; max_samples:\n            indices = np.random.choice(len(locations_normalized),\n                                       max_samples,\n                                       replace=False)\n            locations_normalized = locations_normalized[indices]\n            data = data[indices]\n\n        return locations_normalized.astype(self.dtype), data.astype(self.dtype)\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.Dataset.__init__","title":"<code>__init__(dataset_path=None, num_train=1000, num_test=2500, num_candidates=150, verbose=True, data=None, dtype=np.float64, **kwargs)</code>","text":"<p>Initializes the Dataset class.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>Optional[str]</code> <p>Path to the dataset file (e.g., '.tif'). If None,                           a synthetic dataset will be generated. Defaults to None.                           Alternatively, pass an array of data to the constructor                           with the <code>data</code> argument to use a custom dataset.</p> <code>None</code> <code>num_train</code> <code>int</code> <p>Number of training points to sample from the dataset. Defaults to 1000.</p> <code>1000</code> <code>num_test</code> <code>int</code> <p>Number of testing points to sample from the dataset. Defaults to 2500.</p> <code>2500</code> <code>num_candidates</code> <code>int</code> <p>Number of candidate points for potential sensor placements                   to sample from the dataset. Defaults to 150.</p> <code>150</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, print details about dataset loading, sampling, and preprocessing.             Defaults to True.</p> <code>True</code> <code>data</code> <code>Optional[ndarray]</code> <p>(height, width, d); 2D n-dimensional array of data.</p> <code>None</code> <code>dtype</code> <code>Optional[dtype]</code> <p>The type of the output arrays. If dtype is not given,                          it will be set to np.float64.</p> <code>float64</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>prep_tif_dataset</code> or <code>prep_synthetic_dataset</code>.</p> <code>{}</code> Source code in <code>sgptools/utils/data.py</code> <pre><code>def __init__(self,\n             dataset_path: Optional[str] = None,\n             num_train: int = 1000,\n             num_test: int = 2500,\n             num_candidates: int = 150,\n             verbose: bool = True,\n             data=None,\n             dtype=np.float64,\n             **kwargs: Any):\n    \"\"\"\n    Initializes the Dataset class.\n\n    Args:\n        dataset_path (Optional[str]): Path to the dataset file (e.g., '.tif'). If None,\n                                      a synthetic dataset will be generated. Defaults to None.\n                                      Alternatively, pass an array of data to the constructor\n                                      with the `data` argument to use a custom dataset.\n        num_train (int): Number of training points to sample from the dataset. Defaults to 1000.\n        num_test (int): Number of testing points to sample from the dataset. Defaults to 2500.\n        num_candidates (int): Number of candidate points for potential sensor placements\n                              to sample from the dataset. Defaults to 150.\n        verbose (bool): If `True`, print details about dataset loading, sampling, and preprocessing.\n                        Defaults to True.\n        data (Optional[np.ndarray]): (height, width, d); 2D n-dimensional array of data.\n        dtype (Optional[np.dtype]): The type of the output arrays. If dtype is not given, \n                                    it will be set to np.float64.\n        **kwargs: Additional keyword arguments passed to `prep_tif_dataset` or `prep_synthetic_dataset`.\n    \"\"\"\n    self.verbose = verbose\n    self.dtype = dtype\n\n    # Load/Create the data\n    if data is not None:\n        self.y = data\n    elif dataset_path is not None:\n        self.y = prep_tif_dataset(dataset_path=dataset_path,\n                                  verbose=verbose,\n                                  **kwargs)\n    else:\n        self.y = prep_synthetic_dataset(**kwargs)\n\n    # Store original dimensions for reshaping\n    w, h = self.y.shape[0], self.y.shape[1]\n    if self.verbose:\n        print(f\"Original dataset shape: {self.y.shape}\")\n\n    # Get valid points (non-NaN labels)\n    mask = np.where(np.isfinite(self.y))\n    X_valid_pixel_coords = np.column_stack((mask[0], mask[1]))\n\n    # Sample training, testing, and candidate points from valid pixel coordinates\n    # `get_inducing_pts` with random=True is used for random sampling\n    X_train_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                            num_train,\n                                            random=True)\n    y_train_raw = self.y[X_train_pixel_coords[:, 0],\n                         X_train_pixel_coords[:, 1]].reshape(-1, 1)\n\n    # If num_test is equal to dataset size, return test data in original order, enables plotting with imshow\n    if self.y.shape[0] * self.y.shape[1] == num_test:\n        X_test_pixel_coords = X_valid_pixel_coords\n        y_test_raw = self.y.reshape(-1, 1)\n    else:\n        X_test_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                               num_test,\n                                               random=True)\n        y_test_raw = self.y[X_test_pixel_coords[:, 0],\n                            X_test_pixel_coords[:, 1]].reshape(-1, 1)\n\n    X_candidates_pixel_coords = get_inducing_pts(X_valid_pixel_coords,\n                                                 num_candidates,\n                                                 random=True)\n\n    # Standardize dataset X coordinates (pixel coords to normalized space)\n    self.X_scaler = StandardScaler()\n    self.X_scaler.fit(X_train_pixel_coords)\n\n    # Adjust X_scaler's variance/scale to ensure uniform scaling across dimensions\n    # and to scale the data to have an extent of at least 10.0 in each dimension.\n    # This ensures consistency and prevents issues with very small scales.\n    ind = np.argmax(self.X_scaler.var_)\n    self.X_scaler.var_ = np.ones_like(\n        self.X_scaler.var_) * self.X_scaler.var_[ind]\n    self.X_scaler.scale_ = np.ones_like(\n        self.X_scaler.scale_) * self.X_scaler.scale_[ind]\n    self.X_scaler.scale_ /= 10.0  # Scale to ensure an extent of ~10 units\n\n    self.X_train = self.X_scaler.transform(X_train_pixel_coords)\n    self.X_train = self.X_train.astype(self.dtype)\n    self.X_test = self.X_scaler.transform(X_test_pixel_coords)\n    self.X_test = self.X_test.astype(self.dtype)\n    self.candidates = self.X_scaler.transform(X_candidates_pixel_coords)\n    self.candidates = self.candidates.astype(self.dtype)\n\n    # Standardize dataset labels (y values)\n    self.y_scaler = StandardScaler()\n    self.y_scaler.fit(y_train_raw)\n\n    self.y_train = self.y_scaler.transform(y_train_raw)\n    self.y_train = self.y_train.astype(self.dtype)\n    self.y_test = self.y_scaler.transform(y_test_raw)\n    self.y_test = self.y_test.astype(self.dtype)\n\n    # Transform the entire dataset's labels for consistency\n    self.y = self.y_scaler.transform(self.y.reshape(-1, 1)).reshape(w, h)\n    self.y = self.y.astype(self.dtype)\n\n    if self.verbose:\n        print(\n            f\"Training data shapes (X, y): {self.X_train.shape}, {self.y_train.shape}\"\n        )\n        print(\n            f\"Testing data shapes (X, y): {self.X_test.shape}, {self.y_test.shape}\"\n        )\n        print(f\"Candidate data shape (X): {self.candidates.shape}\")\n        print(\"Dataset loaded and preprocessed successfully.\")\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.Dataset.get_candidates","title":"<code>get_candidates()</code>","text":"<p>Retrieves the preprocessed candidate locations for sensor placement.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_candidates, 2); Normalized candidate locations.</p> Usage <pre><code># dataset_obj = Dataset(...)\n# candidates = dataset_obj.get_candidates()\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def get_candidates(self) -&gt; np.ndarray:\n    \"\"\"\n    Retrieves the preprocessed candidate locations for sensor placement.\n\n    Returns:\n        np.ndarray: (num_candidates, 2); Normalized candidate locations.\n\n    Usage:\n        ```python\n        # dataset_obj = Dataset(...)\n        # candidates = dataset_obj.get_candidates()\n        ```\n    \"\"\"\n    return self.candidates\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.Dataset.get_sensor_data","title":"<code>get_sensor_data(locations, continuous_sening=False, max_samples=500)</code>","text":"<p>Samples sensor data (labels) at specified normalized locations. Can simulate discrete point sensing or continuous path sensing by interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>locations</code> <code>ndarray</code> <p>(N, 2); Array of locations (normalized x, y coordinates)                     where sensor data is to be sampled.</p> required <code>continuous_sening</code> <code>bool</code> <p>If <code>True</code>, interpolates additional points between                       the given <code>locations</code> to simulate sensing along a path.                       Defaults to <code>False</code>.</p> <code>False</code> <code>max_samples</code> <code>int</code> <p>Maximum number of samples to return if <code>continuous_sening</code>                results in too many points. If the number of interpolated                points exceeds <code>max_samples</code>, a random subset will be returned.                Defaults to 500.</p> <code>500</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing:                            - sampled_locations (np.ndarray): (M, 2); Normalized locations                                                              where sensor data was effectively sampled.                            - sampled_data (np.ndarray): (M, 1); Standardized sensor data                                                         sampled at these locations.                            Returns empty arrays if no valid data points are found.</p> Usage <pre><code># dataset_obj = Dataset(...)\n# X_path_normalized = np.array([[0.1, 0.2], [0.5, 0.7], [0.9, 0.8]])\n# # Discrete sensing\n# sensed_X_discrete, sensed_y_discrete = dataset_obj.get_sensor_data(X_path_normalized)\n# # Continuous sensing with interpolation\n# sensed_X_continuous, sensed_y_continuous = dataset_obj.get_sensor_data(X_path_normalized, continuous_sening=True, max_samples=100)\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def get_sensor_data(\n        self,\n        locations: np.ndarray,\n        continuous_sening: bool = False,\n        max_samples: int = 500) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Samples sensor data (labels) at specified normalized locations.\n    Can simulate discrete point sensing or continuous path sensing by interpolation.\n\n    Args:\n        locations (np.ndarray): (N, 2); Array of locations (normalized x, y coordinates)\n                                where sensor data is to be sampled.\n        continuous_sening (bool): If `True`, interpolates additional points between\n                                  the given `locations` to simulate sensing along a path.\n                                  Defaults to `False`.\n        max_samples (int): Maximum number of samples to return if `continuous_sening`\n                           results in too many points. If the number of interpolated\n                           points exceeds `max_samples`, a random subset will be returned.\n                           Defaults to 500.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                       - sampled_locations (np.ndarray): (M, 2); Normalized locations\n                                                                         where sensor data was effectively sampled.\n                                       - sampled_data (np.ndarray): (M, 1); Standardized sensor data\n                                                                    sampled at these locations.\n                                       Returns empty arrays if no valid data points are found.\n\n    Usage:\n        ```python\n        # dataset_obj = Dataset(...)\n        # X_path_normalized = np.array([[0.1, 0.2], [0.5, 0.7], [0.9, 0.8]])\n        # # Discrete sensing\n        # sensed_X_discrete, sensed_y_discrete = dataset_obj.get_sensor_data(X_path_normalized)\n        # # Continuous sensing with interpolation\n        # sensed_X_continuous, sensed_y_continuous = dataset_obj.get_sensor_data(X_path_normalized, continuous_sening=True, max_samples=100)\n        ```\n    \"\"\"\n    # Convert normalized locations back to original pixel coordinates\n    locations_pixel_coords = self.X_scaler.inverse_transform(locations)\n\n    # Round locations to nearest integer and clip to valid dataset boundaries\n    locations_pixel_coords = np.round(locations_pixel_coords).astype(int)\n    locations_pixel_coords[:, 0] = np.clip(locations_pixel_coords[:, 0], 0,\n                                           self.y.shape[0] - 1)\n    locations_pixel_coords[:, 1] = np.clip(locations_pixel_coords[:, 1], 0,\n                                           self.y.shape[1] - 1)\n\n    # If continuous sensing is enabled, interpolate between points using skimage.draw.line\n    if continuous_sening:\n        interpolated_locs: List[np.ndarray] = []\n        if locations_pixel_coords.shape[0] &gt; 1:\n            # Iterate through pairs of consecutive points to draw lines\n            for i in range(locations_pixel_coords.shape[0] - 1):\n                loc1 = locations_pixel_coords[i]\n                loc2 = locations_pixel_coords[i + 1]\n                # line returns (row_coords, col_coords)\n                rr, cc = line(loc1[0], loc1[1], loc2[0], loc2[1])\n                interpolated_locs.append(np.column_stack((rr, cc)))\n\n        # If there's only one point, or if no lines were drawn (e.g., due to identical consecutive points),\n        # still include the initial locations.\n        if not interpolated_locs:\n            # If continuous sensing is true but no path, just return the initial locations if any\n            if locations_pixel_coords.shape[0] &gt; 0:\n                locations_pixel_coords = locations_pixel_coords\n            else:\n                return np.empty((0, 2)), np.empty((0, 1))\n        else:\n            locations_pixel_coords = np.concatenate(interpolated_locs,\n                                                    axis=0)\n\n    # Ensure that locations_pixel_coords is not empty before indexing\n    if locations_pixel_coords.shape[0] == 0:\n        return np.empty((0, 2)), np.empty((0, 1))\n\n    # Ensure indices are within bounds (should be handled by clip, but double check)\n    valid_rows = np.clip(locations_pixel_coords[:, 0], 0,\n                         self.y.shape[0] - 1)\n    valid_cols = np.clip(locations_pixel_coords[:, 1], 0,\n                         self.y.shape[1] - 1)\n\n    # Extract data at the specified pixel locations\n    data = self.y[valid_rows, valid_cols].reshape(-1, 1)\n\n    # Drop NaN values from data and corresponding locations\n    valid_mask = np.isfinite(data.ravel())\n    locations_pixel_coords = locations_pixel_coords[valid_mask]\n    data = data[valid_mask]\n\n    # Re-normalize valid locations\n    if locations_pixel_coords.shape[0] == 0:\n        return np.empty((0, 2)), np.empty((0, 1))\n    locations_normalized = self.X_scaler.transform(locations_pixel_coords)\n\n    # Limit the number of samples to max_samples if needed\n    if len(locations_normalized) &gt; max_samples:\n        indices = np.random.choice(len(locations_normalized),\n                                   max_samples,\n                                   replace=False)\n        locations_normalized = locations_normalized[indices]\n        data = data[indices]\n\n    return locations_normalized.astype(self.dtype), data.astype(self.dtype)\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.Dataset.get_test","title":"<code>get_test()</code>","text":"<p>Retrieves the preprocessed testing data.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing:                            - X_test (np.ndarray): (num_test, 2); Normalized testing input features.                            - y_test (np.ndarray): (num_test, 1); Standardized testing labels.</p> Usage <pre><code># dataset_obj = Dataset(...)\n# X_test, y_test = dataset_obj.get_test()\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def get_test(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Retrieves the preprocessed testing data.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                       - X_test (np.ndarray): (num_test, 2); Normalized testing input features.\n                                       - y_test (np.ndarray): (num_test, 1); Standardized testing labels.\n\n    Usage:\n        ```python\n        # dataset_obj = Dataset(...)\n        # X_test, y_test = dataset_obj.get_test()\n        ```\n    \"\"\"\n    return self.X_test, self.y_test\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.Dataset.get_train","title":"<code>get_train()</code>","text":"<p>Retrieves the preprocessed training data.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing:                            - X_train (np.ndarray): (num_train, 2); Normalized training input features.                            - y_train (np.ndarray): (num_train, 1); Standardized training labels.</p> Usage <pre><code># dataset_obj = Dataset(...)\n# X_train, y_train = dataset_obj.get_train()\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def get_train(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Retrieves the preprocessed training data.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                       - X_train (np.ndarray): (num_train, 2); Normalized training input features.\n                                       - y_train (np.ndarray): (num_train, 1); Standardized training labels.\n\n    Usage:\n        ```python\n        # dataset_obj = Dataset(...)\n        # X_train, y_train = dataset_obj.get_train()\n        ```\n    \"\"\"\n    return self.X_train, self.y_train\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.point_pos","title":"<code>point_pos(point, d, theta)</code>","text":"<p>Generates a new point at a specified distance <code>d</code> and angle <code>theta</code> (in radians) from an existing point. This function applies the transformation to multiple points simultaneously.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>ndarray</code> <p>(N, 2); Array of original 2D points (x, y).</p> required <code>d</code> <code>float</code> <p>The distance from the original point to the new point.</p> required <code>theta</code> <code>float</code> <p>The angle in radians for the direction of displacement.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (N, 2); An array of new points after displacement.</p> Usage <pre><code>import numpy as np\n\n# Example points (N=2)\ninitial_points = np.array([[0.0, 0.0], [1.0, 1.0]])\n# Displace by distance 5.0 at angle pi/4 (45 degrees)\nnew_points = point_pos(initial_points, 5.0, np.pi/4)\n# Expected:\n# New points:\n# [[3.53553391 3.53553391]\n#  [4.53553391 4.53553391]]\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def point_pos(point: np.ndarray, d: float, theta: float) -&gt; np.ndarray:\n    \"\"\"\n    Generates a new point at a specified distance `d` and angle `theta`\n    (in radians) from an existing point. This function applies the\n    transformation to multiple points simultaneously.\n\n    Args:\n        point (np.ndarray): (N, 2); Array of original 2D points (x, y).\n        d (float): The distance from the original point to the new point.\n        theta (float): The angle in radians for the direction of displacement.\n\n    Returns:\n        np.ndarray: (N, 2); An array of new points after displacement.\n\n    Usage:\n        ```python\n        import numpy as np\n\n        # Example points (N=2)\n        initial_points = np.array([[0.0, 0.0], [1.0, 1.0]])\n        # Displace by distance 5.0 at angle pi/4 (45 degrees)\n        new_points = point_pos(initial_points, 5.0, np.pi/4)\n        # Expected:\n        # New points:\n        # [[3.53553391 3.53553391]\n        #  [4.53553391 4.53553391]]\n        ```\n    \"\"\"\n    return np.c_[point[:, 0] + d * np.cos(theta),\n                 point[:, 1] + d * np.sin(theta)]\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.prep_synthetic_dataset","title":"<code>prep_synthetic_dataset(shape=(1000, 1000), min_height=0.0, max_height=30.0, roughness=0.5, random_seed=None, **kwargs)</code>","text":"<p>Generates a 2D synthetic elevation (or similar) dataset using the diamond-square algorithm.</p> <p>Reference: https://github.com/buckinha/DiamondSquare</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int, int]</code> <p>(width, height); The dimensions of the generated grid. Defaults to (1000, 1000).</p> <code>(1000, 1000)</code> <code>min_height</code> <code>float</code> <p>Minimum allowed value in the generated data. Defaults to 0.0.</p> <code>0.0</code> <code>max_height</code> <code>float</code> <p>Maximum allowed value in the generated data. Defaults to 30.0.</p> <code>30.0</code> <code>roughness</code> <code>float</code> <p>Controls the fractal dimension of the generated terrain. Higher                values produce rougher terrain. Defaults to 0.5.</p> <code>0.5</code> <code>random_seed</code> <code>Optional[int]</code> <p>Seed for reproducibility of the generated data. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed directly to the <code>diamond_square</code> function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (height, width); The generated 2D synthetic dataset.</p> Usage <pre><code># from sgptools.utils.data import prep_synthetic_dataset\n# synthetic_data = prep_synthetic_dataset(shape=(256, 256), roughness=0.7, random_seed=42)\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def prep_synthetic_dataset(shape: Tuple[int, int] = (1000, 1000),\n                           min_height: float = 0.0,\n                           max_height: float = 30.0,\n                           roughness: float = 0.5,\n                           random_seed: Optional[int] = None,\n                           **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Generates a 2D synthetic elevation (or similar) dataset using the diamond-square algorithm.\n\n    Reference: [https://github.com/buckinha/DiamondSquare](https://github.com/buckinha/DiamondSquare)\n\n    Args:\n        shape (Tuple[int, int]): (width, height); The dimensions of the generated grid. Defaults to (1000, 1000).\n        min_height (float): Minimum allowed value in the generated data. Defaults to 0.0.\n        max_height (float): Maximum allowed value in the generated data. Defaults to 30.0.\n        roughness (float): Controls the fractal dimension of the generated terrain. Higher\n                           values produce rougher terrain. Defaults to 0.5.\n        random_seed (Optional[int]): Seed for reproducibility of the generated data. Defaults to None.\n        **kwargs: Additional keyword arguments passed directly to the `diamond_square` function.\n\n    Returns:\n       np.ndarray: (height, width); The generated 2D synthetic dataset.\n\n    Usage:\n        ```python\n        # from sgptools.utils.data import prep_synthetic_dataset\n        # synthetic_data = prep_synthetic_dataset(shape=(256, 256), roughness=0.7, random_seed=42)\n        ```\n    \"\"\"\n    data = diamond_square(shape=shape,\n                          min_height=min_height,\n                          max_height=max_height,\n                          roughness=roughness,\n                          random_seed=random_seed,\n                          **kwargs)\n    return data.astype(float)\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.prep_tif_dataset","title":"<code>prep_tif_dataset(dataset_path, dim_max=2500, verbose=True)</code>","text":"<p>Loads and preprocesses a dataset from a GeoTIFF (.tif) file. The function handles downsampling for large files and replaces NoData values (-999999.0) with NaN.</p> <p>For very large .tif files, it's recommended to downsample them externally using GDAL: <code>gdalwarp -tr 50 50 &lt;input&gt;.tif &lt;output&gt;.tif</code></p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the GeoTIFF dataset file.</p> required <code>dim_max</code> <code>int</code> <p>Maximum allowed dimension (width or height) for the loaded dataset.            If either dimension exceeds <code>dim_max</code>, the image will be downsampled            to fit, maintaining aspect ratio. Defaults to 2500.</p> <code>2500</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, print details about loading and downsampling. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (H, W); The preprocessed 2D NumPy array representing the dataset,          with NoData values converted to NaN.</p> Usage <pre><code># Assuming 'path/to/your/dataset.tif' exists\n# from sgptools.utils.data import prep_tif_dataset\n# dataset_array = prep_tif_dataset('path/to/your/dataset.tif', dim_max=1000)\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def prep_tif_dataset(dataset_path: str,\n                     dim_max: int = 2500,\n                     verbose: bool = True) -&gt; np.ndarray:\n    \"\"\"\n    Loads and preprocesses a dataset from a GeoTIFF (.tif) file.\n    The function handles downsampling for large files and replaces NoData values (-999999.0) with NaN.\n\n    For very large .tif files, it's recommended to downsample them externally using GDAL:\n    `gdalwarp -tr 50 50 &lt;input&gt;.tif &lt;output&gt;.tif`\n\n    Args:\n        dataset_path (str): Path to the GeoTIFF dataset file.\n        dim_max (int): Maximum allowed dimension (width or height) for the loaded dataset.\n                       If either dimension exceeds `dim_max`, the image will be downsampled\n                       to fit, maintaining aspect ratio. Defaults to 2500.\n        verbose (bool): If `True`, print details about loading and downsampling. Defaults to True.\n\n    Returns:\n       np.ndarray: (H, W); The preprocessed 2D NumPy array representing the dataset,\n                   with NoData values converted to NaN.\n\n    Usage:\n        ```python\n        # Assuming 'path/to/your/dataset.tif' exists\n        # from sgptools.utils.data import prep_tif_dataset\n        # dataset_array = prep_tif_dataset('path/to/your/dataset.tif', dim_max=1000)\n        ```\n    \"\"\"\n    data = PIL.Image.open(dataset_path)\n    data_array = np.array(data)\n    if verbose:\n        print(\n            f\"Loaded dataset from {dataset_path} with shape {data_array.shape}\"\n        )\n\n    downsample_factor = np.ceil(np.max(data_array.shape) / dim_max).astype(int)\n    if downsample_factor &lt;= 1:\n        downsample_factor = 1\n    elif verbose:\n        print(\n            f'Downsampling by a factor of {downsample_factor} to fit the maximum dimension of {dim_max}'\n        )\n\n    # Downsample and convert to float, replace specific NoData value with NaN\n    data_array = data_array[::downsample_factor, ::downsample_factor].astype(\n        float)\n    data_array[np.where(data_array == -999999.0)] = np.nan\n    return data_array\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.remove_circle_patches","title":"<code>remove_circle_patches(X, Y, circle_patches)</code>","text":"<p>Removes points that fall inside a list of matplotlib Circle patches.</p> <p>Note: This function assumes that the <code>circle_patch</code> objects have a <code>contains_points</code> method, similar to <code>matplotlib.patches.Circle</code> or <code>matplotlib.path.Path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>(N,); Array of x-coordinates.</p> required <code>Y</code> <code>ndarray</code> <p>(N,); Array of y-coordinates.</p> required <code>circle_patches</code> <code>List[Any]</code> <p>A list of objects representing circle patches.                          Each object must have a <code>contains_points(points)</code> method.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing two 1D NumPy arrays:                            (filtered_X_coordinates, filtered_Y_coordinates).</p> Usage <pre><code>import numpy as np\nfrom matplotlib.patches import Circle\nfrom matplotlib.collections import PatchCollection\n\n# Example points\nX_coords = np.array([0, 1, 2, 3, 4, 5])\nY_coords = np.array([0, 1, 2, 3, 4, 5])\n\n# Define a circle patch centered at (2,2) with radius 1.5\ncircle = Circle((2, 2), 1.5)\n\nfiltered_X, filtered_Y = remove_circle_patches(X_coords, Y_coords, [circle])\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def remove_circle_patches(\n        X: np.ndarray, Y: np.ndarray,\n        circle_patches: List[Any]) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Removes points that fall inside a list of matplotlib Circle patches.\n\n    Note: This function assumes that the `circle_patch` objects have a `contains_points` method,\n    similar to `matplotlib.patches.Circle` or `matplotlib.path.Path`.\n\n    Args:\n        X (np.ndarray): (N,); Array of x-coordinates.\n        Y (np.ndarray): (N,); Array of y-coordinates.\n        circle_patches (List[Any]): A list of objects representing circle patches.\n                                     Each object must have a `contains_points(points)` method.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing two 1D NumPy arrays:\n                                       (filtered_X_coordinates, filtered_Y_coordinates).\n\n    Usage:\n        ```python\n        import numpy as np\n        from matplotlib.patches import Circle\n        from matplotlib.collections import PatchCollection\n\n        # Example points\n        X_coords = np.array([0, 1, 2, 3, 4, 5])\n        Y_coords = np.array([0, 1, 2, 3, 4, 5])\n\n        # Define a circle patch centered at (2,2) with radius 1.5\n        circle = Circle((2, 2), 1.5)\n\n        filtered_X, filtered_Y = remove_circle_patches(X_coords, Y_coords, [circle])\n        ```\n    \"\"\"\n    points = np.array([X.flatten(), Y.flatten()]).T\n    for circle_patch in circle_patches:\n        points = points[~circle_patch.contains_points(points)]\n    return points[:, 0], points[:, 1]\n</code></pre>"},{"location":"api/utils/data.html#sgptools.utils.data.remove_polygons","title":"<code>remove_polygons(X, Y, polygons)</code>","text":"<p>Removes points that fall inside a list of matplotlib Path polygons.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>(N,); Array of x-coordinates.</p> required <code>Y</code> <code>ndarray</code> <p>(N,); Array of y-coordinates.</p> required <code>polygons</code> <code>List[Path]</code> <p>A list of <code>matplotlib.path.Path</code> objects.                          Points within these polygons will be removed.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing two 1D NumPy arrays:                            (filtered_X_coordinates, filtered_Y_coordinates).</p> Usage <pre><code>import matplotlib.path as mpath\nimport numpy as np\n\n# Example points\nX_coords = np.array([0, 1, 2, 3, 4, 5])\nY_coords = np.array([0, 1, 2, 3, 4, 5])\n\n# Define a square polygon (points inside will be removed)\npolygon_vertices = np.array([[1, 1], [1, 3], [3, 3], [3, 1]])\nsquare_polygon = mpath.Path(polygon_vertices)\n\nfiltered_X, filtered_Y = remove_polygons(X_coords, Y_coords, [square_polygon])\n</code></pre> Source code in <code>sgptools/utils/data.py</code> <pre><code>def remove_polygons(\n        X: np.ndarray, Y: np.ndarray,\n        polygons: List[path.Path]) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Removes points that fall inside a list of matplotlib Path polygons.\n\n    Args:\n        X (np.ndarray): (N,); Array of x-coordinates.\n        Y (np.ndarray): (N,); Array of y-coordinates.\n        polygons (List[path.Path]): A list of `matplotlib.path.Path` objects.\n                                     Points within these polygons will be removed.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing two 1D NumPy arrays:\n                                       (filtered_X_coordinates, filtered_Y_coordinates).\n\n    Usage:\n        ```python\n        import matplotlib.path as mpath\n        import numpy as np\n\n        # Example points\n        X_coords = np.array([0, 1, 2, 3, 4, 5])\n        Y_coords = np.array([0, 1, 2, 3, 4, 5])\n\n        # Define a square polygon (points inside will be removed)\n        polygon_vertices = np.array([[1, 1], [1, 3], [3, 3], [3, 1]])\n        square_polygon = mpath.Path(polygon_vertices)\n\n        filtered_X, filtered_Y = remove_polygons(X_coords, Y_coords, [square_polygon])\n        ```\n    \"\"\"\n    points = np.array([X.flatten(), Y.flatten()]).T\n    for polygon in polygons:\n        p = path.Path(polygon)\n        points = points[~p.contains_points(points)]\n    return points[:, 0], points[:, 1]\n</code></pre>"},{"location":"api/utils/gpflow.html","title":"GPflow","text":""},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow","title":"<code>sgptools.utils.gpflow</code>","text":""},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.TraceInducingPts","title":"<code>TraceInducingPts</code>","text":"<p>               Bases: <code>MonitorTask</code></p> <p>A GPflow monitoring task designed to trace the state of inducing points at every step during optimization of a Sparse Gaussian Process (SGP) model. This is particularly useful for visualizing the movement of inducing points during training.</p> <p>Attributes:</p> Name Type Description <code>trace</code> <code>List[ndarray]</code> <p>A list to store the numpy arrays of inducing points                       at each optimization step.</p> <code>model</code> <code>Union[GPR, SGPR]</code> <p>The GPflow model being monitored.</p> Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>class TraceInducingPts(gpflow.monitor.MonitorTask):\n    \"\"\"\n    A GPflow monitoring task designed to trace the state of inducing points\n    at every step during optimization of a Sparse Gaussian Process (SGP) model.\n    This is particularly useful for visualizing the movement of inducing points\n    during training.\n\n    Attributes:\n        trace (List[np.ndarray]): A list to store the numpy arrays of inducing points\n                                  at each optimization step.\n        model (Union[gpflow.models.GPR, gpflow.models.SGPR]): The GPflow model being monitored.\n    \"\"\"\n\n    def __init__(self, model: Union[gpflow.models.GPR, gpflow.models.SGPR]):\n        \"\"\"\n        Initializes the TraceInducingPts monitor task.\n\n        Args:\n            model (Union[gpflow.models.GPR, gpflow.models.SGPR]): The GPflow GP or SGP model instance\n                                                   to monitor. It is expected to have an\n                                                   `inducing_variable.Z` attribute and potentially\n                                                   a `transform` attribute.\n        \"\"\"\n        super().__init__()\n        self.trace: List[np.ndarray] = []\n        self.model = model\n\n    def run(self, **kwargs: Any) -&gt; None:\n        \"\"\"\n        Executes the monitoring task. This method is called by the GPflow `Monitor`\n        at specified intervals. It extracts the current inducing points, applies\n        any associated transformations (e.g., `IPPTransform`'s fixed points expansion),\n        and appends them to the internal trace list.\n\n        Args:\n            **kwargs: Additional keyword arguments (e.g., `step`, `loss_value`)\n                      passed by the `gpflow.monitor.Monitor` framework.\n\n        Usage:\n            This method is called internally by `gpflow.monitor.Monitor` and typically\n            not invoked directly by the user.\n        \"\"\"\n        Xu = self.model.inducing_variable.Z\n        Xu_exp: np.ndarray\n        # Apply IPP fixed points transform if available, without expanding sensor model\n        try:\n            Xu_exp = self.model.transform.expand(\n                Xu, expand_sensor_model=False).numpy()\n        except AttributeError:\n            Xu_exp = Xu\n        self.trace.append(Xu_exp)\n\n    def run(self, **kwargs):\n        '''\n        Method used to extract the inducing points and \n        apply IPP fixed points transform if available\n        '''\n        Xu = self.model.inducing_variable.Z\n        Xu_exp = self.model.transform.expand(\n            Xu, expand_sensor_model=False).numpy()\n        self.trace.append(Xu_exp)\n\n    def get_trace(self) -&gt; np.ndarray:\n        \"\"\"\n        Returns the collected inducing points at each optimization step.\n\n        Returns:\n            np.ndarray: (num_steps, num_inducing_points, num_dimensions);\n                        An array where:\n                        - `num_steps` is the number of optimization steps monitored.\n                        - `num_inducing_points` is the number of inducing points.\n                        - `num_dimensions` is the dimensionality of the inducing points.\n\n        Usage:\n            ```python\n            # Assuming `model` is an SGPR and `opt_losses` was called with `trace_fn='traceXu'`\n            # trace_task = TraceInducingPts(model)\n            # Then retrieve trace after optimization\n            # inducing_points_history = trace_task.get_trace()\n            ```\n        \"\"\"\n        return np.array(self.trace)\n</code></pre>"},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.TraceInducingPts.__init__","title":"<code>__init__(model)</code>","text":"<p>Initializes the TraceInducingPts monitor task.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[GPR, SGPR]</code> <p>The GPflow GP or SGP model instance                                    to monitor. It is expected to have an                                    <code>inducing_variable.Z</code> attribute and potentially                                    a <code>transform</code> attribute.</p> required Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>def __init__(self, model: Union[gpflow.models.GPR, gpflow.models.SGPR]):\n    \"\"\"\n    Initializes the TraceInducingPts monitor task.\n\n    Args:\n        model (Union[gpflow.models.GPR, gpflow.models.SGPR]): The GPflow GP or SGP model instance\n                                               to monitor. It is expected to have an\n                                               `inducing_variable.Z` attribute and potentially\n                                               a `transform` attribute.\n    \"\"\"\n    super().__init__()\n    self.trace: List[np.ndarray] = []\n    self.model = model\n</code></pre>"},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.TraceInducingPts.get_trace","title":"<code>get_trace()</code>","text":"<p>Returns the collected inducing points at each optimization step.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_steps, num_inducing_points, num_dimensions);         An array where:         - <code>num_steps</code> is the number of optimization steps monitored.         - <code>num_inducing_points</code> is the number of inducing points.         - <code>num_dimensions</code> is the dimensionality of the inducing points.</p> Usage <pre><code># Assuming `model` is an SGPR and `opt_losses` was called with `trace_fn='traceXu'`\n# trace_task = TraceInducingPts(model)\n# Then retrieve trace after optimization\n# inducing_points_history = trace_task.get_trace()\n</code></pre> Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>def get_trace(self) -&gt; np.ndarray:\n    \"\"\"\n    Returns the collected inducing points at each optimization step.\n\n    Returns:\n        np.ndarray: (num_steps, num_inducing_points, num_dimensions);\n                    An array where:\n                    - `num_steps` is the number of optimization steps monitored.\n                    - `num_inducing_points` is the number of inducing points.\n                    - `num_dimensions` is the dimensionality of the inducing points.\n\n    Usage:\n        ```python\n        # Assuming `model` is an SGPR and `opt_losses` was called with `trace_fn='traceXu'`\n        # trace_task = TraceInducingPts(model)\n        # Then retrieve trace after optimization\n        # inducing_points_history = trace_task.get_trace()\n        ```\n    \"\"\"\n    return np.array(self.trace)\n</code></pre>"},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.TraceInducingPts.run","title":"<code>run(**kwargs)</code>","text":"<p>Method used to extract the inducing points and  apply IPP fixed points transform if available</p> Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>def run(self, **kwargs):\n    '''\n    Method used to extract the inducing points and \n    apply IPP fixed points transform if available\n    '''\n    Xu = self.model.inducing_variable.Z\n    Xu_exp = self.model.transform.expand(\n        Xu, expand_sensor_model=False).numpy()\n    self.trace.append(Xu_exp)\n</code></pre>"},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.get_model_params","title":"<code>get_model_params(X_train, y_train, max_steps=1500, verbose=True, lengthscales=1.0, variance=1.0, noise_variance=0.1, kernel=None, return_model=False, train_inducing_pts=False, num_inducing_pts=500, **kwargs)</code>","text":"<p>Trains a Gaussian Process (GP) or Sparse Gaussian Process (SGP) model on the given training set. A Sparse GP is used if the training set size exceeds 1500 samples.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>ndarray</code> <p>(n, d); Training set input features. <code>n</code> is the number of samples,                   <code>d</code> is the number of input dimensions.</p> required <code>y_train</code> <code>ndarray</code> <p>(n, 1); Training set labels. <code>n</code> is the number of samples.</p> required <code>max_steps</code> <code>int</code> <p>Maximum number of optimization steps. Defaults to 1500.</p> <code>1500</code> <code>verbose</code> <code>bool</code> <p>If True, prints a summary of the optimized GP parameters. Defaults to True.</p> <code>True</code> <code>lengthscales</code> <code>Union[float, List[float]]</code> <p>Initial kernel lengthscale(s). If a float, it's                       applied uniformly to all dimensions. If a list, each element                       corresponds to a data dimension. Defaults to 1.0.</p> <code>1.0</code> <code>variance</code> <code>float</code> <p>Initial kernel variance. Defaults to 1.0.</p> <code>1.0</code> <code>noise_variance</code> <code>float</code> <p>Initial data noise variance. Defaults to 0.1.</p> <code>0.1</code> <code>kernel</code> <code>Optional[Kernel]</code> <p>A pre-defined GPflow kernel function. If None,                          a <code>gpflow.kernels.SquaredExponential</code> kernel is created                          with the provided <code>lengthscales</code> and <code>variance</code>. Defaults to None.</p> <code>None</code> <code>return_model</code> <code>bool</code> <p>If True, the trained GP/SGP model object is returned along with                  loss, variance, and kernel. Defaults to False.</p> <code>False</code> <code>train_inducing_pts</code> <code>bool</code> <p>If True and using a Sparse GP model, the inducing points                        are optimized along with other model parameters. If False,                        inducing points remain fixed (default for SGP). Defaults to False.</p> <code>False</code> <code>num_inducing_pts</code> <code>int</code> <p>Number of inducing points to use when training a Sparse GP model.                     Ignored if <code>len(X_train)</code> is less than or equal to 1500. Defaults to 500.</p> <code>500</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the <code>optimize_model</code> function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Tuple[ndarray, float, Kernel], Tuple[ndarray, float, Kernel, Union[GPR, SGPR]]]</code> <p>Union[Tuple[np.ndarray, float, gpflow.kernels.Kernel], Tuple[np.ndarray, float, gpflow.kernels.Kernel, Union[gpflow.models.GPR, gpflow.models.SGPR]]]:</p> <code>Union[Tuple[ndarray, float, Kernel], Tuple[ndarray, float, Kernel, Union[GPR, SGPR]]]</code> <ul> <li>If <code>return_model</code> is False: Tuple: (loss (np.ndarray), variance (float), kernel (gpflow.kernels.Kernel)). <code>loss</code> is an array of loss values obtained during training. <code>variance</code> is the optimized data noise variance. <code>kernel</code> is the optimized GPflow kernel function.</li> </ul> <code>Union[Tuple[ndarray, float, Kernel], Tuple[ndarray, float, Kernel, Union[GPR, SGPR]]]</code> <ul> <li>If <code>return_model</code> is True: Tuple: (loss (np.ndarray), variance (float), kernel (gpflow.kernels.Kernel), gp (Union[gpflow.models.GPR, gpflow.models.SGPR])). <code>gp</code> is the optimized GPflow GPR or SGPR model object.</li> </ul> Usage <pre><code>import numpy as np\n# Generate some dummy data\nX = np.random.rand(1000, 2) * 10\ny = np.sin(X[:, 0:1]) + np.cos(X[:, 1:2]) + np.random.randn(1000, 1) * 0.1\n\n# Train a GPR model (since 1000 samples &lt;= 1500)\nlosses, noise_var, trained_kernel = get_model_params(X, y, max_steps=500, verbose=True)\n\n# Train an SGPR model (more than 1500 samples)\nX_large = np.random.rand(2000, 2) * 10\ny_large = np.sin(X_large[:, 0:1]) + np.cos(X_large[:, 1:2]) + np.random.randn(2000, 1) * 0.1\nlosses_sgpr, noise_var_sgpr, trained_kernel_sgpr, sgpr_model =             get_model_params(X_large, y_large, max_steps=500, num_inducing_pts=100, return_model=True)\n</code></pre> Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>def get_model_params(\n    X_train: np.ndarray,\n    y_train: np.ndarray,\n    max_steps: int = 1500,\n    verbose: bool = True,\n    lengthscales: Union[float, List[float]] = 1.0,\n    variance: float = 1.0,\n    noise_variance: float = 0.1,\n    kernel: Optional[gpflow.kernels.Kernel] = None,\n    return_model: bool = False,\n    train_inducing_pts: bool = False,\n    num_inducing_pts: int = 500,\n    **kwargs: Any\n) -&gt; Union[Tuple[np.ndarray, float, gpflow.kernels.Kernel], Tuple[\n        np.ndarray, float, gpflow.kernels.Kernel, Union[gpflow.models.GPR,\n                                                        gpflow.models.SGPR]]]:\n    \"\"\"\n    Trains a Gaussian Process (GP) or Sparse Gaussian Process (SGP) model on the given training set.\n    A Sparse GP is used if the training set size exceeds 1500 samples.\n\n    Args:\n        X_train (np.ndarray): (n, d); Training set input features. `n` is the number of samples,\n                              `d` is the number of input dimensions.\n        y_train (np.ndarray): (n, 1); Training set labels. `n` is the number of samples.\n        max_steps (int): Maximum number of optimization steps. Defaults to 1500.\n        verbose (bool): If True, prints a summary of the optimized GP parameters. Defaults to True.\n        lengthscales (Union[float, List[float]]): Initial kernel lengthscale(s). If a float, it's\n                                  applied uniformly to all dimensions. If a list, each element\n                                  corresponds to a data dimension. Defaults to 1.0.\n        variance (float): Initial kernel variance. Defaults to 1.0.\n        noise_variance (float): Initial data noise variance. Defaults to 0.1.\n        kernel (Optional[gpflow.kernels.Kernel]): A pre-defined GPflow kernel function. If None,\n                                     a `gpflow.kernels.SquaredExponential` kernel is created\n                                     with the provided `lengthscales` and `variance`. Defaults to None.\n        return_model (bool): If True, the trained GP/SGP model object is returned along with\n                             loss, variance, and kernel. Defaults to False.\n        train_inducing_pts (bool): If True and using a Sparse GP model, the inducing points\n                                   are optimized along with other model parameters. If False,\n                                   inducing points remain fixed (default for SGP). Defaults to False.\n        num_inducing_pts (int): Number of inducing points to use when training a Sparse GP model.\n                                Ignored if `len(X_train)` is less than or equal to 1500. Defaults to 500.\n        **kwargs: Additional keyword arguments passed to the `optimize_model` function.\n\n    Returns:\n        Union[Tuple[np.ndarray, float, gpflow.kernels.Kernel], Tuple[np.ndarray, float, gpflow.kernels.Kernel, Union[gpflow.models.GPR, gpflow.models.SGPR]]]:\n        - If `return_model` is False:\n            Tuple: (loss (np.ndarray), variance (float), kernel (gpflow.kernels.Kernel)).\n            `loss` is an array of loss values obtained during training.\n            `variance` is the optimized data noise variance.\n            `kernel` is the optimized GPflow kernel function.\n        - If `return_model` is True:\n            Tuple: (loss (np.ndarray), variance (float), kernel (gpflow.kernels.Kernel), gp (Union[gpflow.models.GPR, gpflow.models.SGPR])).\n            `gp` is the optimized GPflow GPR or SGPR model object.\n\n    Usage:\n        ```python\n        import numpy as np\n        # Generate some dummy data\n        X = np.random.rand(1000, 2) * 10\n        y = np.sin(X[:, 0:1]) + np.cos(X[:, 1:2]) + np.random.randn(1000, 1) * 0.1\n\n        # Train a GPR model (since 1000 samples &lt;= 1500)\n        losses, noise_var, trained_kernel = get_model_params(X, y, max_steps=500, verbose=True)\n\n        # Train an SGPR model (more than 1500 samples)\n        X_large = np.random.rand(2000, 2) * 10\n        y_large = np.sin(X_large[:, 0:1]) + np.cos(X_large[:, 1:2]) + np.random.randn(2000, 1) * 0.1\n        losses_sgpr, noise_var_sgpr, trained_kernel_sgpr, sgpr_model = \\\n            get_model_params(X_large, y_large, max_steps=500, num_inducing_pts=100, return_model=True)\n        ```\n    \"\"\"\n    if kernel is None:\n        kernel = gpflow.kernels.SquaredExponential(lengthscales=lengthscales,\n                                                   variance=variance)\n\n    model: Union[gpflow.models.GPR, gpflow.models.SGPR]\n    trainable_variables_list: List[tf.Variable]\n\n    if len(X_train) &lt;= 1500:\n        model = gpflow.models.GPR(data=(X_train, y_train),\n                                  kernel=kernel,\n                                  noise_variance=noise_variance)\n        trainable_variables_list = model.trainable_variables\n    else:\n        inducing_pts = get_inducing_pts(X_train, num_inducing_pts)\n        model = gpflow.models.SGPR(data=(X_train, y_train),\n                                   kernel=kernel,\n                                   inducing_variable=inducing_pts,\n                                   noise_variance=noise_variance)\n        if train_inducing_pts:\n            trainable_variables_list = model.trainable_variables\n        else:\n            # Exclude inducing points from trainable variables if not specified to be trained\n            # Assuming inducing_variable is the first parameter in SGPR's trainable_variables\n            trainable_variables_list = model.trainable_variables[1:]\n\n    loss_values: np.ndarray\n    if max_steps &gt; 0:\n        loss_values = optimize_model(\n            model,\n            max_steps=max_steps,\n            trainable_variables=trainable_variables_list,\n            verbose=verbose,\n            **kwargs)\n    else:\n        # If no optimization steps, return an array with a single '0' loss\n        loss_values = np.array([0.0])\n\n    if verbose:\n        print_summary(model)\n\n    if return_model:\n        return loss_values, model.likelihood.variance.numpy(), kernel, model\n    else:\n        return loss_values, model.likelihood.variance.numpy(), kernel\n</code></pre>"},{"location":"api/utils/gpflow.html#sgptools.utils.gpflow.optimize_model","title":"<code>optimize_model(model=None, max_steps=2000, optimize_hparams=True, optimizer='scipy.L-BFGS-B', verbose=False, trace_fn=None, convergence_criterion=True, trainable_variables=None, training_loss=None, **kwargs)</code>","text":"<p>Trains a GPflow GP or SGP model using either SciPy's optimizers or TensorFlow's optimizers.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[GPR, SGPR]</code> <p>The GPflow model (GPR or SGPR) to be trained.                  Optionally, you can instead pass a loss function with the <code>training_loss</code> argument. </p> <code>None</code> <code>max_steps</code> <code>int</code> <p>Maximum number of training steps (iterations). Defaults to 2000.</p> <code>2000</code> <code>optimize_hparams</code> <code>bool</code> <p>If <code>False</code>, the model hyperparameters (kernel parameters and data likelihood)                  will not be optimized. This is ignored if <code>trainable_variables</code> is explicitly passed.                 Defaults to True.</p> <code>True</code> <code>optimizer</code> <code>str</code> <p>Specifies the optimizer to use in \".\" format.              Supported backends: <code>scipy</code> and <code>tf</code> (TensorFlow).              - For <code>scipy</code> backend: Refer to <code>scipy.optimize.minimize</code> documentation for available                methods (e.g., 'L-BFGS-B', 'CG'). Only first-order and quasi-Newton methods                that do not require the Hessian are supported.              - For <code>tf</code> backend: Refer to <code>tf.keras.optimizers</code> for available methods                (e.g., 'Adam', 'SGD').              Defaults to 'scipy.L-BFGS-B'. <code>'scipy.L-BFGS-B'</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, the training progress will be printed. For SciPy optimizers,             this controls <code>disp</code> option. Defaults to False.</p> <code>False</code> <code>trace_fn</code> <code>Optional[Union[str, Callable[[Any], Any]]]</code> <p>Specifies what to trace during training:                 - <code>None</code>: Returns the loss values.                 - <code>'traceXu'</code>: Traces the inducing points' states at each optimization step.                                This increases computation time.                 - <code>Callable</code>: A custom function that takes the traceable quantities from the optimizer                               and returns the desired output.                               - For <code>scipy</code> backend: Refer to <code>gpflow.monitor.MonitorTask</code>                               - For <code>tf</code> backend: Refer to <code>trace_fn</code> argument of <code>tfp.math.minimize</code>                 Defaults to None.</p> <code>None</code> <code>convergence_criterion</code> <code>bool</code> <p>If <code>True</code> and using a TensorFlow optimizer, it enables early                           stopping when the loss plateaus (using <code>tfp.optimizer.convergence_criteria.LossNotDecreasing</code>).                           Defaults to True.</p> <code>True</code> <code>trainable_variables</code> <code>Optional[List[Variable]]</code> <p>A list of specific model variables to train.                         If None, variables are determined based on <code>kernel_grad</code>. Defaults to None.</p> <code>None</code> <code>training_loss</code> <code>Optional[Callable[[Any], Any]]</code> <p>A custom training loss function.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the backend optimizers.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of loss values (or traced quantities if <code>trace_fn</code> is specified)         recorded during the optimization process. The shape depends on <code>trace_fn</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid optimizer format or an unsupported backend is specified.</p> Usage <pre><code>import gpflow\nimport numpy as np\n\n# Create a dummy model (e.g., GPR for simplicity)\nX = np.random.rand(100, 1)\ny = X + np.random.randn(100, 1) * 0.1\nkernel = gpflow.kernels.SquaredExponential()\nmodel = gpflow.models.GPR((X, y), kernel=kernel, noise_variance=0.1)\n\n# 1. Optimize using SciPy's L-BFGS-B (default)\nlosses_scipy = optimize_model(model, max_steps=500, verbose=True)\n\n# 2. Optimize using TensorFlow's Adam optimizer\n# Re-initialize model to reset parameters for new optimization\nmodel_tf = gpflow.models.GPR((X, y), kernel=gpflow.kernels.SquaredExponential(), noise_variance=0.1)\nlosses_tf = optimize_model(model_tf, max_steps=1000, learning_rate=0.01, optimizer='tf.Adam', verbose=False)\n\n# 3. Optimize SGPR and trace inducing points\nX_sgpr = np.random.rand(2000, 2)\ny_sgpr = np.sin(X_sgpr[:, 0:1]) + np.random.randn(2000, 1) * 0.1\ninducing_points_init = get_inducing_pts(X_sgpr, 100)\nsgpr_model = gpflow.models.SGPR((X_sgpr, y_sgpr), kernel=gpflow.kernels.SquaredExponential(),\n                                inducing_variable=inducing_points_init, noise_variance=0.1)\ntraced_ips = optimize_model(sgpr_model, max_steps=100, optimizer='tf.Adam', trace_fn='traceXu', verbose=False)\n</code></pre> Source code in <code>sgptools/utils/gpflow.py</code> <pre><code>def optimize_model(model: Optional[Union[gpflow.models.GPR, gpflow.models.SGPR]]=None,\n                   max_steps: int = 2000,\n                   optimize_hparams: bool = True,\n                   optimizer: str = 'scipy.L-BFGS-B',\n                   verbose: bool = False,\n                   trace_fn: Optional[Union[str, Callable[[Any], Any]]] = None,\n                   convergence_criterion: bool = True,\n                   trainable_variables: Optional[List[tf.Variable]] = None,\n                   training_loss: Optional[Callable[[Any], Any]] = None,\n                   **kwargs: Any) -&gt; np.ndarray:\n    \"\"\"\n    Trains a GPflow GP or SGP model using either SciPy's optimizers or TensorFlow's optimizers.\n\n    Args:\n        model (Union[gpflow.models.GPR, gpflow.models.SGPR]): The GPflow model (GPR or SGPR) to be trained. \n                            Optionally, you can instead pass a loss function with the `training_loss` argument. \n        max_steps (int): Maximum number of training steps (iterations). Defaults to 2000.\n        optimize_hparams (bool): If `False`, the model hyperparameters (kernel parameters and data likelihood) \n                            will not be optimized. This is ignored if `trainable_variables` is explicitly passed.\n                            Defaults to True.\n        optimizer (str): Specifies the optimizer to use in \"&lt;backend&gt;.&lt;method&gt;\" format.\n                         Supported backends: `scipy` and `tf` (TensorFlow).\n                         - For `scipy` backend: Refer to `scipy.optimize.minimize` documentation for available\n                           methods (e.g., 'L-BFGS-B', 'CG'). Only first-order and quasi-Newton methods\n                           that do not require the Hessian are supported.\n                         - For `tf` backend: Refer to `tf.keras.optimizers` for available methods\n                           (e.g., 'Adam', 'SGD').\n                         Defaults to 'scipy.L-BFGS-B'.\n        verbose (bool): If `True`, the training progress will be printed. For SciPy optimizers,\n                        this controls `disp` option. Defaults to False.\n        trace_fn (Optional[Union[str, Callable[[Any], Any]]]): Specifies what to trace during training:\n                            - `None`: Returns the loss values.\n                            - `'traceXu'`: Traces the inducing points' states at each optimization step.\n                                           This increases computation time.\n                            - `Callable`: A custom function that takes the traceable quantities from the optimizer\n                                          and returns the desired output.\n                                          - For `scipy` backend: Refer to `gpflow.monitor.MonitorTask`\n                                          - For `tf` backend: Refer to `trace_fn` argument of `tfp.math.minimize`\n                            Defaults to None.\n        convergence_criterion (bool): If `True` and using a TensorFlow optimizer, it enables early\n                                      stopping when the loss plateaus (using `tfp.optimizer.convergence_criteria.LossNotDecreasing`).\n                                      Defaults to True.\n        trainable_variables (Optional[List[tf.Variable]]): A list of specific model variables to train.\n                                    If None, variables are determined based on `kernel_grad`. Defaults to None.\n        training_loss (Optional[Callable[[Any], Any]]): A custom training loss function.\n        **kwargs: Additional keyword arguments passed to the backend optimizers.\n\n    Returns:\n        np.ndarray: An array of loss values (or traced quantities if `trace_fn` is specified)\n                    recorded during the optimization process. The shape depends on `trace_fn`.\n\n    Raises:\n        ValueError: If an invalid optimizer format or an unsupported backend is specified.\n\n    Usage:\n        ```python\n        import gpflow\n        import numpy as np\n\n        # Create a dummy model (e.g., GPR for simplicity)\n        X = np.random.rand(100, 1)\n        y = X + np.random.randn(100, 1) * 0.1\n        kernel = gpflow.kernels.SquaredExponential()\n        model = gpflow.models.GPR((X, y), kernel=kernel, noise_variance=0.1)\n\n        # 1. Optimize using SciPy's L-BFGS-B (default)\n        losses_scipy = optimize_model(model, max_steps=500, verbose=True)\n\n        # 2. Optimize using TensorFlow's Adam optimizer\n        # Re-initialize model to reset parameters for new optimization\n        model_tf = gpflow.models.GPR((X, y), kernel=gpflow.kernels.SquaredExponential(), noise_variance=0.1)\n        losses_tf = optimize_model(model_tf, max_steps=1000, learning_rate=0.01, optimizer='tf.Adam', verbose=False)\n\n        # 3. Optimize SGPR and trace inducing points\n        X_sgpr = np.random.rand(2000, 2)\n        y_sgpr = np.sin(X_sgpr[:, 0:1]) + np.random.randn(2000, 1) * 0.1\n        inducing_points_init = get_inducing_pts(X_sgpr, 100)\n        sgpr_model = gpflow.models.SGPR((X_sgpr, y_sgpr), kernel=gpflow.kernels.SquaredExponential(),\n                                        inducing_variable=inducing_points_init, noise_variance=0.1)\n        traced_ips = optimize_model(sgpr_model, max_steps=100, optimizer='tf.Adam', trace_fn='traceXu', verbose=False)\n        ```\n    \"\"\"\n    reset_trainable = False\n    # Determine which variables to train\n    if trainable_variables is None:\n        # Disable hyperparameter gradients (kernel and likelihood parameters)\n        if not optimize_hparams:\n            set_trainable(model.kernel, False)\n            set_trainable(model.likelihood, False)\n            reset_trainable = True\n        trainable_variables = model.trainable_variables\n\n    # Determine the training loss function\n    if training_loss is None:\n        training_loss = model.training_loss\n\n    # Parse optimizer string\n    optimizer_parts = optimizer.split('.')\n    if len(optimizer_parts) != 2:\n        raise ValueError(\n            f\"Invalid optimizer format! Expected &lt;backend&gt;.&lt;method&gt;; got {optimizer}\"\n        )\n    backend, method = optimizer_parts\n\n    losses_output: Any  # Will hold the final loss values or traced data\n\n    if backend == 'scipy':\n        # Configure SciPy monitor if tracing is requested\n        scipy_monitor: Optional[gpflow.monitor.Monitor] = None\n        trace_task_instance: Optional[TraceInducingPts] = None\n        if trace_fn == 'traceXu':\n            trace_task_instance = TraceInducingPts(model)\n            # Period=1 means run task at every step\n            task_group = gpflow.monitor.MonitorTaskGroup(trace_task_instance,\n                                                         period=1)\n            scipy_monitor = gpflow.monitor.Monitor(task_group)\n\n        opt = gpflow.optimizers.Scipy()\n        # SciPy optimize method returns a `ScipyOptimizerResults` object\n        # which has `fun` attribute for the final loss. `step_callback` is used for tracing.\n        results = opt.minimize(\n            training_loss,\n            trainable_variables,\n            method=method,\n            options=dict(disp=verbose, maxiter=max_steps),\n            step_callback=scipy_monitor,  # Pass the monitor as step_callback\n            **kwargs)\n\n        if trace_fn == 'traceXu' and trace_task_instance is not None:\n            losses_output = trace_task_instance.task_groups[0].tasks[\n                0].get_trace()\n        else:\n            # If no tracing or non-Xu tracing, the `results.fun` contains the final loss\n            losses_output = np.array([results.fun\n                                      ])  # Return as an array for consistency\n            # Note: For SciPy, `losses.fun` is typically just the final loss, not a history.\n            # To get history, a custom callback capturing loss at each step would be needed.\n\n    elif backend == 'tf':\n        tf_trace_fn: Optional[Callable[[Any], Any]] = None\n        if trace_fn is None:\n            # Default TF trace function to capture loss history\n            tf_trace_fn = lambda traceable_quantities: traceable_quantities.loss\n        elif trace_fn == 'traceXu':\n\n            def tf_trace_fn(traceable_quantities):\n                return model.inducing_variable.Z.numpy()\n        elif callable(trace_fn):\n            tf_trace_fn = trace_fn\n        else:\n            raise ValueError(\n                f\"Invalid trace_fn for TensorFlow backend: {trace_fn}\")\n\n        # Get Keras optimizer instance\n        opt = getattr(optimizers, method)(**kwargs)\n\n        # Configure convergence criterion\n        tf_convergence_criterion: Optional[\n            tfp.optimizer.convergence_criteria.ConvergenceCriterion] = None\n        if convergence_criterion:\n            tf_convergence_criterion = tfp.optimizer.convergence_criteria.LossNotDecreasing(\n                atol=1e-5,  # Absolute tolerance for checking decrease\n                window_size=\n                50,  # Number of steps to consider for plateau detection\n                min_num_steps=int(\n                    max_steps *\n                    0.1)  # Minimum steps before early stopping is considered\n            )\n\n        # Run TensorFlow optimization\n        results_tf = tfp.math.minimize(\n            training_loss,\n            trainable_variables=trainable_variables,\n            num_steps=max_steps,\n            optimizer=opt,\n            convergence_criterion=tf_convergence_criterion,\n            trace_fn=tf_trace_fn)\n\n        # Fallback to just final loss if no proper trace captured\n        losses_output = np.array(results_tf.numpy())\n\n    else:\n        raise ValueError(\n            f\"Invalid backend! Expected `scipy` or `tf`; got {backend}\")\n\n    # Reset trainable variables\n    if not optimize_hparams and reset_trainable:\n        set_trainable(model.kernel, True)\n        set_trainable(model.likelihood, True)\n\n    return losses_output\n</code></pre>"},{"location":"api/utils/metrics.html","title":"Metrics","text":""},{"location":"api/utils/metrics.html#sgptools.utils.metrics","title":"<code>sgptools.utils.metrics</code>","text":""},{"location":"api/utils/metrics.html#sgptools.utils.metrics.gaussian_entropy","title":"<code>gaussian_entropy(K)</code>","text":"<p>Computes the entropy of a multivariate Gaussian distribution defined by its covariance matrix <code>K</code>. This is often used to quantify the uncertainty or information content of a Gaussian Process.</p> <p>Parameters:</p> Name Type Description Default <code>K</code> <code>ndarray</code> <p>(n, n); A square NumPy array representing the covariance matrix.             Must be positive semi-definite.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The entropy of the multivariate Gaussian distribution.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.metrics import gaussian_entropy\n\n# Example covariance matrix for 2 variables\ncovariance_matrix = np.array([[1.0, 0.5], [0.5, 1.0]])\nentropy_value = gaussian_entropy(covariance_matrix)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def gaussian_entropy(K: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the entropy of a multivariate Gaussian distribution defined by its\n    covariance matrix `K`. This is often used to quantify the uncertainty or\n    information content of a Gaussian Process.\n\n    Args:\n        K (np.ndarray): (n, n); A square NumPy array representing the covariance matrix.\n                        Must be positive semi-definite.\n\n    Returns:\n        float: The entropy of the multivariate Gaussian distribution.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.metrics import gaussian_entropy\n\n        # Example covariance matrix for 2 variables\n        covariance_matrix = np.array([[1.0, 0.5], [0.5, 1.0]])\n        entropy_value = gaussian_entropy(covariance_matrix)\n        ```\n    \"\"\"\n    # Using scipy's multivariate_normal for entropy calculation\n    # allow_singular=True to handle cases where the covariance matrix might be singular\n    # or near-singular due to numerical issues, preventing errors.\n    return float(\n        multivariate_normal(mean=None, cov=K, allow_singular=True).entropy())\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_distance","title":"<code>get_distance(X)</code>","text":"<p>Computes the total length of a path defined by a sequence of waypoints. The length is calculated as the sum of Euclidean distances between consecutive waypoints.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>(m, d); NumPy array where each row represents a waypoint             and columns represent its coordinates (e.g., (x, y) or (x, y, z)).             <code>m</code> is the number of waypoints, <code>d</code> is the dimensionality.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The total length of the path.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.metrics import get_distance\n\n# Example 2D path with 3 waypoints\npath_waypoints_2d = np.array([[0.0, 0.0], [3.0, 4.0], [3.0, 7.0]])\ndistance_2d = get_distance(path_waypoints_2d)\n\n# Example 3D path\npath_waypoints_3d = np.array([[0.0, 0.0, 0.0], [1.0, 1.0, 1.0]])\ndistance_3d = get_distance(path_waypoints_3d)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_distance(X: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the total length of a path defined by a sequence of waypoints.\n    The length is calculated as the sum of Euclidean distances between consecutive waypoints.\n\n    Args:\n        X (np.ndarray): (m, d); NumPy array where each row represents a waypoint\n                        and columns represent its coordinates (e.g., (x, y) or (x, y, z)).\n                        `m` is the number of waypoints, `d` is the dimensionality.\n\n    Returns:\n        float: The total length of the path.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.metrics import get_distance\n\n        # Example 2D path with 3 waypoints\n        path_waypoints_2d = np.array([[0.0, 0.0], [3.0, 4.0], [3.0, 7.0]])\n        distance_2d = get_distance(path_waypoints_2d)\n\n        # Example 3D path\n        path_waypoints_3d = np.array([[0.0, 0.0, 0.0], [1.0, 1.0, 1.0]])\n        distance_3d = get_distance(path_waypoints_3d)\n        ```\n    \"\"\"\n    if X.shape[0] &lt; 2:\n        return 0.0  # A path needs at least two points to have a length\n\n    # Compute Euclidean distance (L2-norm) between consecutive points\n    # `X[1:] - X[:-1]` calculates the vector differences between adjacent waypoints\n    dist_segments = np.linalg.norm(X[1:] - X[:-1], axis=-1)\n\n    # Sum the lengths of all segments to get the total path length\n    total_distance = np.sum(dist_segments)\n    return float(total_distance)\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_elbo","title":"<code>get_elbo(Xu, X_env, noise_variance, kernel, baseline=False)</code>","text":"<p>Computes the Evidence Lower Bound (ELBO) of a Sparse Gaussian Process (SGP) model. The ELBO is a lower bound on the marginal likelihood and is commonly used as an optimization objective for sparse GPs. Optionally, a baseline can be subtracted to ensure the ELBO is positive or to compare against a trivial model.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>ndarray</code> <p>(m, d); NumPy array of inducing points. <code>m</code> is the number of              inducing points, <code>d</code> is the dimensionality.</p> required <code>X_env</code> <code>ndarray</code> <p>(n, d); NumPy array of data points representing the environment                 or training data. <code>n</code> is the number of data points, <code>d</code> is the dimensionality.</p> required <code>noise_variance</code> <code>float</code> <p>The noise variance of the Gaussian Process likelihood.</p> required <code>kernel</code> <code>Kernel</code> <p>A GPflow kernel object.</p> required <code>baseline</code> <code>bool</code> <p>If True, a baseline ELBO (computed with a single inducing point at [0,0])              is subtracted from the main ELBO. This can normalize the ELBO value.              Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed ELBO value.</p> Usage <pre><code>import numpy as np\nimport gpflow\nfrom sgptools.utils.metrics import get_elbo\n\n# Dummy data\nX_environment = np.random.rand(100, 2) * 10 # Environment data\ninducing_points = np.array([[2.0, 2.0], [8.0, 8.0]], dtype=np.float64) # Inducing points\nnoise_var = 0.1\nrbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=2.0, variance=1.0)\n\n# Compute ELBO without baseline\nelbo_no_baseline = get_elbo(inducing_points, X_environment, noise_var, rbf_kernel)\n\n# Compute ELBO with baseline\nelbo_with_baseline = get_elbo(inducing_points, X_environment, noise_var, rbf_kernel, baseline=True)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_elbo(Xu: np.ndarray,\n             X_env: np.ndarray,\n             noise_variance: float,\n             kernel: gpflow.kernels.Kernel,\n             baseline: bool = False) -&gt; float:\n    \"\"\"\n    Computes the Evidence Lower Bound (ELBO) of a Sparse Gaussian Process (SGP) model.\n    The ELBO is a lower bound on the marginal likelihood and is commonly used as\n    an optimization objective for sparse GPs. Optionally, a baseline can be\n    subtracted to ensure the ELBO is positive or to compare against a trivial model.\n\n    Args:\n        Xu (np.ndarray): (m, d); NumPy array of inducing points. `m` is the number of\n                         inducing points, `d` is the dimensionality.\n        X_env (np.ndarray): (n, d); NumPy array of data points representing the environment\n                            or training data. `n` is the number of data points, `d` is the dimensionality.\n        noise_variance (float): The noise variance of the Gaussian Process likelihood.\n        kernel (gpflow.kernels.Kernel): A GPflow kernel object.\n        baseline (bool): If True, a baseline ELBO (computed with a single inducing point at [0,0])\n                         is subtracted from the main ELBO. This can normalize the ELBO value.\n                         Defaults to False.\n\n    Returns:\n        float: The computed ELBO value.\n\n    Usage:\n        ```python\n        import numpy as np\n        import gpflow\n        from sgptools.utils.metrics import get_elbo\n\n        # Dummy data\n        X_environment = np.random.rand(100, 2) * 10 # Environment data\n        inducing_points = np.array([[2.0, 2.0], [8.0, 8.0]], dtype=np.float64) # Inducing points\n        noise_var = 0.1\n        rbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=2.0, variance=1.0)\n\n        # Compute ELBO without baseline\n        elbo_no_baseline = get_elbo(inducing_points, X_environment, noise_var, rbf_kernel)\n\n        # Compute ELBO with baseline\n        elbo_with_baseline = get_elbo(inducing_points, X_environment, noise_var, rbf_kernel, baseline=True)\n        ```\n    \"\"\"\n    # Convert Xu to TensorFlow tensor for SGPR\n    tf_Xu = tf.constant(Xu, dtype=tf.float64)\n    # X_env is expected as (X, Y) tuple, but for ELBO calculation without Y, pass (X_env, zeros)\n    tf_X_env = tf.constant(X_env, dtype=tf.float64)\n    y_dummy = tf.zeros((tf_X_env.shape[0], 1), dtype=tf.float64)\n\n    baseline_value = 0.0\n    if baseline:\n        # Create a temporary SGPR model with a single dummy inducing point for baseline\n        sgpr_baseline = gpflow.models.SGPR(data=(tf_X_env, y_dummy),\n                                           noise_variance=noise_variance,\n                                           kernel=kernel,\n                                           inducing_variable=tf.constant(\n                                               [[0.0, 0.0]], dtype=tf.float64))\n        baseline_value = float(sgpr_baseline.elbo().numpy())\n\n    # Create the main SGPR model with the provided inducing points\n    sgpr_model = gpflow.models.SGPR(data=(tf_X_env, y_dummy),\n                                    noise_variance=noise_variance,\n                                    kernel=kernel,\n                                    inducing_variable=tf_Xu)\n\n    return float((sgpr_model.elbo() - baseline_value).numpy())\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_kl","title":"<code>get_kl(Xu, X_env, noise_variance, kernel)</code>","text":"<p>Computes the Kullback-Leibler (KL) divergence between a full Gaussian Process (GP) and a Sparse Gaussian Process (SGP) approximation. This KL divergence term is part of the ELBO objective in sparse GPs.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>ndarray</code> <p>(m, d); NumPy array of inducing points for the SGP.</p> required <code>X_env</code> <code>ndarray</code> <p>(n, d); NumPy array of data points representing the environment                 or training data.</p> required <code>noise_variance</code> <code>float</code> <p>The noise variance of the Gaussian Process likelihood.</p> required <code>kernel</code> <code>Kernel</code> <p>A GPflow kernel object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed KL divergence value (specifically, the trace term    from the KL divergence in the ELBO formulation, \\(0.5     ext{Tr}(K_{ff} - Q_{ff}) / \\sigma^2\\)).</p> Usage <pre><code>import numpy as np\nimport gpflow\nfrom sgptools.utils.metrics import get_kl\n\n# Dummy data\nX_environment = np.random.rand(100, 2) * 10\ninducing_points = np.array([[2.0, 2.0], [8.0, 8.0]], dtype=np.float64)\nnoise_var = 0.1\nrbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=2.0, variance=1.0)\n\nkl_value = get_kl(inducing_points, X_environment, noise_var, rbf_kernel)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_kl(Xu: np.ndarray, X_env: np.ndarray, noise_variance: float,\n           kernel: gpflow.kernels.Kernel) -&gt; float:\n    \"\"\"\n    Computes the Kullback-Leibler (KL) divergence between a full Gaussian Process (GP)\n    and a Sparse Gaussian Process (SGP) approximation. This KL divergence term is\n    part of the ELBO objective in sparse GPs.\n\n    Args:\n        Xu (np.ndarray): (m, d); NumPy array of inducing points for the SGP.\n        X_env (np.ndarray): (n, d); NumPy array of data points representing the environment\n                            or training data.\n        noise_variance (float): The noise variance of the Gaussian Process likelihood.\n        kernel (gpflow.kernels.Kernel): A GPflow kernel object.\n\n    Returns:\n        float: The computed KL divergence value (specifically, the trace term\n               from the KL divergence in the ELBO formulation, $0.5 \\text{Tr}(K_{ff} - Q_{ff}) / \\sigma^2$).\n\n    Usage:\n        ```python\n        import numpy as np\n        import gpflow\n        from sgptools.utils.metrics import get_kl\n\n        # Dummy data\n        X_environment = np.random.rand(100, 2) * 10\n        inducing_points = np.array([[2.0, 2.0], [8.0, 8.0]], dtype=np.float64)\n        noise_var = 0.1\n        rbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=2.0, variance=1.0)\n\n        kl_value = get_kl(inducing_points, X_environment, noise_var, rbf_kernel)\n        ```\n    \"\"\"\n    tf_Xu = tf.constant(Xu, dtype=tf.float64)\n    tf_X_env = tf.constant(X_env, dtype=tf.float64)\n    y_dummy = tf.zeros((tf_X_env.shape[0], 1), dtype=tf.float64)\n\n    sgpr_model = gpflow.models.SGPR(data=(tf_X_env, y_dummy),\n                                    noise_variance=noise_variance,\n                                    kernel=kernel,\n                                    inducing_variable=tf_Xu)\n\n    # Accessing common terms used in ELBO calculation from GPflow's internal methods\n    # This involves private methods (_common_calculation), so be aware of potential\n    # breaking changes in future GPflow versions.\n    common = sgpr_model._common_calculation()\n    sigma_sq = common.sigma_sq\n    AAT = common.AAT  # AAT = A @ A.T, where A = L\u207b\u00b9Kuf/\u03c3\n\n    # kdiag: diagonal of Kff (prior covariance for all data points)\n    kdiag = sgpr_model.kernel(tf_X_env, full_cov=False)\n\n    # trace_k: Tr(Kff) / \u03c3\u00b2\n    trace_k = tf.reduce_sum(kdiag / sigma_sq)\n    # trace_q: Tr(Qff) / \u03c3\u00b2 = Tr(Kuf.T @ Kuu^-1 @ Kuf) / \u03c3\u00b2\n    # From the ELBO derivation, Tr(Q_N N) / sigma^2 is Tr(AAT)\n    trace_q = tf.reduce_sum(tf.linalg.diag_part(AAT))\n\n    # KL divergence trace term: 0.5 * Tr(Kff - Qff) / \u03c3\u00b2\n    trace_term = 0.5 * (trace_k - trace_q)\n\n    return float(trace_term.numpy())\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_mi","title":"<code>get_mi(Xu, X_objective, noise_variance, kernel)</code>","text":"<p>Computes the Mutual Information (MI) between a set of sensing locations (<code>Xu</code>) and a set of objective/candidate locations (<code>X_objective</code>) using a Gaussian Process model. MI quantifies the reduction in uncertainty about <code>X_objective</code> given <code>Xu</code>. Internally, it uses the <code>SLogMI</code> objective from <code>sgptools.objectives</code> for numerical stability.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>ndarray</code> <p>(m, d); NumPy array of sensing locations. <code>m</code> is the number of              sensing points, <code>d</code> is the dimensionality.</p> required <code>X_objective</code> <code>ndarray</code> <p>(n, d); NumPy array of candidate or objective locations. <code>n</code> is the number of                       objective points, <code>d</code> is the dimensionality.</p> required <code>noise_variance</code> <code>float</code> <p>The noise variance of the Gaussian Process likelihood.</p> required <code>kernel</code> <code>Kernel</code> <p>A GPflow kernel object used to compute covariances.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed Mutual Information value.</p> Usage <pre><code>import numpy as np\nimport gpflow\nfrom sgptools.utils.metrics import get_mi\n\n# Dummy data\nX_sensing_locs = np.array([[0.1, 0.1], [0.5, 0.5]], dtype=np.float64)\nX_candidate_locs = np.array([[0.2, 0.2], [0.6, 0.6], [0.9, 0.9]], dtype=np.float64)\nnoise_var = 0.1\nrbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=1.0, variance=1.0)\n\nmi_value = get_mi(X_sensing_locs, X_candidate_locs, noise_var, rbf_kernel)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_mi(Xu: np.ndarray, X_objective: np.ndarray, noise_variance: float,\n           kernel: gpflow.kernels.Kernel) -&gt; float:\n    \"\"\"\n    Computes the Mutual Information (MI) between a set of sensing locations (`Xu`)\n    and a set of objective/candidate locations (`X_objective`) using a Gaussian Process model.\n    MI quantifies the reduction in uncertainty about `X_objective` given `Xu`.\n    Internally, it uses the `SLogMI` objective from `sgptools.objectives` for numerical stability.\n\n    Args:\n        Xu (np.ndarray): (m, d); NumPy array of sensing locations. `m` is the number of\n                         sensing points, `d` is the dimensionality.\n        X_objective (np.ndarray): (n, d); NumPy array of candidate or objective locations. `n` is the number of\n                                  objective points, `d` is the dimensionality.\n        noise_variance (float): The noise variance of the Gaussian Process likelihood.\n        kernel (gpflow.kernels.Kernel): A GPflow kernel object used to compute covariances.\n\n    Returns:\n        float: The computed Mutual Information value.\n\n    Usage:\n        ```python\n        import numpy as np\n        import gpflow\n        from sgptools.utils.metrics import get_mi\n\n        # Dummy data\n        X_sensing_locs = np.array([[0.1, 0.1], [0.5, 0.5]], dtype=np.float64)\n        X_candidate_locs = np.array([[0.2, 0.2], [0.6, 0.6], [0.9, 0.9]], dtype=np.float64)\n        noise_var = 0.1\n        rbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=1.0, variance=1.0)\n\n        mi_value = get_mi(X_sensing_locs, X_candidate_locs, noise_var, rbf_kernel)\n        ```\n    \"\"\"\n    # Ensure inputs are TensorFlow tensors for compatibility with SLogMI\n    # SLogMI expects tf.Tensor, not np.ndarray for X_objective\n    # Assuming SLogMI's init takes np.ndarray for X_objective and converts it\n    # If not, convert X_objective here: tf.constant(X_objective, dtype=tf.float64)\n    mi_model = SLogMI(\n        X_objective=X_objective,\n        kernel=kernel,\n        noise_variance=noise_variance,\n        jitter=1e-6)  # jitter is added to noise_variance in SLogMI\n    # SLogMI's __call__ method expects a tf.Tensor for X (Xu in this context)\n    return float(mi_model(tf.constant(Xu, dtype=tf.float64)).numpy())\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_nlpd","title":"<code>get_nlpd(y_pred, y_test, var)</code>","text":"<p>Computes the Negative Log Predictive Density (NLPD). NLPD is a measure of how well a probabilistic model predicts new data. A lower NLPD indicates a better fit. For a Gaussian predictive distribution, it is derived from the log-likelihood of the true observations under the predicted Gaussian.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>(n, 1); NumPy array of predicted mean values.</p> required <code>y_test</code> <code>ndarray</code> <p>(n, 1); NumPy array of ground truth values.</p> required <code>var</code> <code>ndarray</code> <p>(n, 1); NumPy array of predicted variances for each prediction.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed NLPD value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>var</code> contains zero or negative values, which would lead to invalid log or division.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.metrics import get_nlpd\n\n# Dummy data\npredictions = np.array([[1.1], [2.2], [3.3]])\nground_truth = np.array([[1.0], [2.0], [3.0]])\n# Predicted variances (must be positive)\nvariances = np.array([[0.01], [0.04], [0.09]]) \n\nnlpd_value = get_nlpd(predictions, ground_truth, variances)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_nlpd(y_pred: np.ndarray, y_test: np.ndarray, var: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the Negative Log Predictive Density (NLPD).\n    NLPD is a measure of how well a probabilistic model predicts new data.\n    A lower NLPD indicates a better fit. For a Gaussian predictive distribution,\n    it is derived from the log-likelihood of the true observations under the\n    predicted Gaussian.\n\n    Args:\n        y_pred (np.ndarray): (n, 1); NumPy array of predicted mean values.\n        y_test (np.ndarray): (n, 1); NumPy array of ground truth values.\n        var (np.ndarray): (n, 1); NumPy array of predicted variances for each prediction.\n\n    Returns:\n        float: The computed NLPD value.\n\n    Raises:\n        ValueError: If `var` contains zero or negative values, which would lead to invalid log or division.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.metrics import get_nlpd\n\n        # Dummy data\n        predictions = np.array([[1.1], [2.2], [3.3]])\n        ground_truth = np.array([[1.0], [2.0], [3.0]])\n        # Predicted variances (must be positive)\n        variances = np.array([[0.01], [0.04], [0.09]]) \n\n        nlpd_value = get_nlpd(predictions, ground_truth, variances)\n        ```\n    \"\"\"\n    if np.any(var &lt;= 0):\n        raise ValueError(\n            \"Predicted variance (var) must be strictly positive for NLPD calculation.\"\n        )\n\n    error = y_pred - y_test\n    # Calculate NLPD terms for each point\n    nlpd_terms = 0.5 * np.log(\n        2 * np.pi) + 0.5 * np.log(var) + 0.5 * np.square(error) / var\n\n    # Return the mean NLPD across all points\n    return float(np.mean(nlpd_terms))\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_reconstruction","title":"<code>get_reconstruction(sensor_data, X_test, noise_variance, kernel)</code>","text":"<p>Computes the Gaussian Process (GP)-based reconstruction (mean prediction and variance) of a data field. The provided <code>sensor_data</code> serves as the training set for the GP model, and predictions are made over <code>X_test</code>.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_data</code> <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing:                                         - Xu_X (np.ndarray): (m, d); Input locations from sensor measurements.                                         - Xu_y (np.ndarray): (m, 1); Corresponding labels (measurements) from sensors.</p> required <code>X_test</code> <code>ndarray</code> <p>(n, d); NumPy array of testing input locations                  (points where the data field needs to be estimated).</p> required <code>noise_variance</code> <code>float</code> <p>The noise variance of the Gaussian Process likelihood.</p> required <code>kernel</code> <code>Kernel</code> <p>A GPflow kernel object.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple containing:                            - y_pred (np.ndarray): (n, 1); Predicted mean estimates of the data field at <code>X_test</code>.                            - y_var (np.ndarray): (n, 1); Predicted variance of the data field at <code>X_test</code>.</p> Usage <pre><code>import numpy as np\nimport gpflow\nfrom sgptools.utils.metrics import get_reconstruction\n\n# Dummy sensor data (training data for GP)\nsensor_locs = np.array([[0.1, 0.1], [0.3, 0.3], [0.7, 0.7]], dtype=np.float64)\nsensor_vals = np.array([[0.5], [1.5], [2.5]], dtype=np.float64)\n\n# Dummy test locations (where we want predictions)\ntest_locs = np.array([[0.2, 0.2], [0.4, 0.4], [0.6, 0.6], [0.8, 0.8]], dtype=np.float64)\n\nnoise_var = 0.05\nrbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=1.0, variance=1.0)\n\npredicted_means, predicted_vars = get_reconstruction(\n    (sensor_locs, sensor_vals), test_locs, noise_var, rbf_kernel\n)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_reconstruction(\n        sensor_data: Tuple[np.ndarray, np.ndarray], X_test: np.ndarray,\n        noise_variance: float,\n        kernel: gpflow.kernels.Kernel) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes the Gaussian Process (GP)-based reconstruction (mean prediction and variance)\n    of a data field. The provided `sensor_data` serves as the training set for the GP model,\n    and predictions are made over `X_test`.\n\n    Args:\n        sensor_data (Tuple[np.ndarray, np.ndarray]): A tuple containing:\n                                                    - Xu_X (np.ndarray): (m, d); Input locations from sensor measurements.\n                                                    - Xu_y (np.ndarray): (m, 1); Corresponding labels (measurements) from sensors.\n        X_test (np.ndarray): (n, d); NumPy array of testing input locations\n                             (points where the data field needs to be estimated).\n        noise_variance (float): The noise variance of the Gaussian Process likelihood.\n        kernel (gpflow.kernels.Kernel): A GPflow kernel object.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n                                       - y_pred (np.ndarray): (n, 1); Predicted mean estimates of the data field at `X_test`.\n                                       - y_var (np.ndarray): (n, 1); Predicted variance of the data field at `X_test`.\n\n    Usage:\n        ```python\n        import numpy as np\n        import gpflow\n        from sgptools.utils.metrics import get_reconstruction\n\n        # Dummy sensor data (training data for GP)\n        sensor_locs = np.array([[0.1, 0.1], [0.3, 0.3], [0.7, 0.7]], dtype=np.float64)\n        sensor_vals = np.array([[0.5], [1.5], [2.5]], dtype=np.float64)\n\n        # Dummy test locations (where we want predictions)\n        test_locs = np.array([[0.2, 0.2], [0.4, 0.4], [0.6, 0.6], [0.8, 0.8]], dtype=np.float64)\n\n        noise_var = 0.05\n        rbf_kernel = gpflow.kernels.SquaredExponential(lengthscales=1.0, variance=1.0)\n\n        predicted_means, predicted_vars = get_reconstruction(\n            (sensor_locs, sensor_vals), test_locs, noise_var, rbf_kernel\n        )\n        ```\n    \"\"\"\n    Xu_X, Xu_y = sensor_data\n\n    # Initialize and train a GP Regression (GPR) model\n    gpr = gpflow.models.GPR(data=(Xu_X, Xu_y),\n                            noise_variance=noise_variance,\n                            kernel=kernel)\n\n    # Predict the mean and variance at the test locations\n    y_pred_tf, y_var_tf = gpr.predict_f(X_test)\n\n    # Convert TensorFlow tensors to NumPy arrays and reshape\n    y_pred = y_pred_tf.numpy().reshape(-1, 1)\n    y_var = y_var_tf.numpy().reshape(-1, 1)\n\n    return y_pred, y_var\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_rmse","title":"<code>get_rmse(y_pred, y_test)</code>","text":"<p>Computes the Root Mean Square Error (RMSE) between predicted and ground truth values.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>(n, 1); NumPy array of predicted values.</p> required <code>y_test</code> <code>ndarray</code> <p>(n, 1); NumPy array of ground truth values.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed RMSE.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.metrics import get_rmse\n\n# Dummy data\npredictions = np.array([[1.1], [2.2], [3.3]])\nground_truth = np.array([[1.0], [2.0], [3.0]])\n\nrmse_value = get_rmse(predictions, ground_truth)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_rmse(y_pred: np.ndarray, y_test: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the Root Mean Square Error (RMSE) between predicted and ground truth values.\n\n    Args:\n        y_pred (np.ndarray): (n, 1); NumPy array of predicted values.\n        y_test (np.ndarray): (n, 1); NumPy array of ground truth values.\n\n    Returns:\n        float: The computed RMSE.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.metrics import get_rmse\n\n        # Dummy data\n        predictions = np.array([[1.1], [2.2], [3.3]])\n        ground_truth = np.array([[1.0], [2.0], [3.0]])\n\n        rmse_value = get_rmse(predictions, ground_truth)\n        ```\n    \"\"\"\n    error = y_pred - y_test\n    return float(np.sqrt(np.mean(np.square(error))))\n</code></pre>"},{"location":"api/utils/metrics.html#sgptools.utils.metrics.get_smse","title":"<code>get_smse(y_pred, y_test, var)</code>","text":"<p>Computes the Standardized Mean Square Error (SMSE). SMSE is a variant of MSE where each squared error term is divided by the predicted variance. It's particularly useful in Bayesian contexts as it accounts for the model's uncertainty in its predictions.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>(n, 1); NumPy array of predicted values.</p> required <code>y_test</code> <code>ndarray</code> <p>(n, 1); NumPy array of ground truth values.</p> required <code>var</code> <code>ndarray</code> <p>(n, 1); NumPy array of predicted variances for each prediction.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed SMSE value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>var</code> contains zero or negative values, which would lead to division by zero or invalid results.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.metrics import get_smse\n\n# Dummy data\npredictions = np.array([[1.1], [2.2], [3.3]])\nground_truth = np.array([[1.0], [2.0], [3.0]])\n# Predicted variances (must be positive)\nvariances = np.array([[0.01], [0.04], [0.09]]) \n\nsmse_value = get_smse(predictions, ground_truth, variances)\n</code></pre> Source code in <code>sgptools/utils/metrics.py</code> <pre><code>def get_smse(y_pred: np.ndarray, y_test: np.ndarray, var: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the Standardized Mean Square Error (SMSE).\n    SMSE is a variant of MSE where each squared error term is divided by\n    the predicted variance. It's particularly useful in Bayesian contexts\n    as it accounts for the model's uncertainty in its predictions.\n\n    Args:\n        y_pred (np.ndarray): (n, 1); NumPy array of predicted values.\n        y_test (np.ndarray): (n, 1); NumPy array of ground truth values.\n        var (np.ndarray): (n, 1); NumPy array of predicted variances for each prediction.\n\n    Returns:\n        float: The computed SMSE value.\n\n    Raises:\n        ValueError: If `var` contains zero or negative values, which would lead to division by zero or invalid results.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.metrics import get_smse\n\n        # Dummy data\n        predictions = np.array([[1.1], [2.2], [3.3]])\n        ground_truth = np.array([[1.0], [2.0], [3.0]])\n        # Predicted variances (must be positive)\n        variances = np.array([[0.01], [0.04], [0.09]]) \n\n        smse_value = get_smse(predictions, ground_truth, variances)\n        ```\n    \"\"\"\n    if np.any(var &lt;= 0):\n        raise ValueError(\n            \"Predicted variance (var) must be strictly positive for SMSE calculation.\"\n        )\n\n    error = y_pred - y_test\n    # Element-wise division by variance\n    smse_val = np.mean(np.square(error) / var)\n    return float(smse_val)\n</code></pre>"},{"location":"api/utils/misc.html","title":"Misc","text":""},{"location":"api/utils/misc.html#sgptools.utils.misc","title":"<code>sgptools.utils.misc</code>","text":""},{"location":"api/utils/misc.html#sgptools.utils.misc.cont2disc","title":"<code>cont2disc(Xu, candidates, candidate_labels=None)</code>","text":"<p>Maps continuous space locations (<code>Xu</code>) to the closest points in a discrete set of candidate locations (<code>candidates</code>) using a Hungarian algorithm (linear sum assignment) for optimal matching. This ensures each <code>Xu</code> point is matched to a unique candidate.</p> <p>Parameters:</p> Name Type Description Default <code>Xu</code> <code>ndarray</code> <p>(m, d); Continuous space points (e.g., optimized sensor locations).              <code>m</code> is the number of points, <code>d</code> is the dimensionality.</p> required <code>candidates</code> <code>ndarray</code> <p>(n, d); Discrete set of candidate locations.                      <code>n</code> is the number of candidates, <code>d</code> is the dimensionality.</p> required <code>candidate_labels</code> <code>Optional[ndarray]</code> <p>(n, 1); Optional labels corresponding to                                     the discrete set of candidate locations.                                     If provided, the matched labels are also returned.                                     Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tuple[ndarray, ndarray]]</code> <p>Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:</p> <code>Union[ndarray, Tuple[ndarray, ndarray]]</code> <ul> <li>If <code>candidate_labels</code> is None: np.ndarray: (m, d); Discrete space points' locations (<code>Xu_X</code>),             where each point in <code>Xu</code> is mapped to its closest             unique point in <code>candidates</code>.</li> </ul> <code>Union[ndarray, Tuple[ndarray, ndarray]]</code> <ul> <li>If <code>candidate_labels</code> is provided: Tuple[np.ndarray, np.ndarray]: (<code>Xu_X</code>, <code>Xu_y</code>). <code>Xu_X</code> (np.ndarray): (m, d); The matched discrete locations. <code>Xu_y</code> (np.ndarray): (m, 1); The labels corresponding to <code>Xu_X</code>.</li> </ul> Usage <pre><code>import numpy as np\nfrom sgptools.utils.misc import cont2disc\n\n# Example continuous points\ncontinuous_points = np.array([[0.1, 0.1], [0.9, 0.9], [0.5, 0.5]])\n# Example discrete candidates\ndiscrete_candidates = np.array([[0.0, 0.0], [1.0, 1.0], [0.4, 0.6]])\n# Example candidate labels (optional)\ndiscrete_labels = np.array([[10.0], [20.0], [15.0]])\n\n# 1. Map without labels\nmapped_points = cont2disc(continuous_points, discrete_candidates)\n\n# 2. Map with labels\nmapped_points_X, mapped_points_y = cont2disc(continuous_points, discrete_candidates, discrete_labels)\n</code></pre> Source code in <code>sgptools/utils/misc.py</code> <pre><code>def cont2disc(\n    Xu: np.ndarray,\n    candidates: np.ndarray,\n    candidate_labels: Optional[np.ndarray] = None\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Maps continuous space locations (`Xu`) to the closest points in a discrete\n    set of candidate locations (`candidates`) using a Hungarian algorithm\n    (linear sum assignment) for optimal matching. This ensures each `Xu` point\n    is matched to a unique candidate.\n\n    Args:\n        Xu (np.ndarray): (m, d); Continuous space points (e.g., optimized sensor locations).\n                         `m` is the number of points, `d` is the dimensionality.\n        candidates (np.ndarray): (n, d); Discrete set of candidate locations.\n                                 `n` is the number of candidates, `d` is the dimensionality.\n        candidate_labels (Optional[np.ndarray]): (n, 1); Optional labels corresponding to\n                                                the discrete set of candidate locations.\n                                                If provided, the matched labels are also returned.\n                                                Defaults to None.\n\n    Returns:\n        Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n        - If `candidate_labels` is None:\n            np.ndarray: (m, d); Discrete space points' locations (`Xu_X`),\n                        where each point in `Xu` is mapped to its closest\n                        unique point in `candidates`.\n        - If `candidate_labels` is provided:\n            Tuple[np.ndarray, np.ndarray]: (`Xu_X`, `Xu_y`).\n            `Xu_X` (np.ndarray): (m, d); The matched discrete locations.\n            `Xu_y` (np.ndarray): (m, 1); The labels corresponding to `Xu_X`.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.misc import cont2disc\n\n        # Example continuous points\n        continuous_points = np.array([[0.1, 0.1], [0.9, 0.9], [0.5, 0.5]])\n        # Example discrete candidates\n        discrete_candidates = np.array([[0.0, 0.0], [1.0, 1.0], [0.4, 0.6]])\n        # Example candidate labels (optional)\n        discrete_labels = np.array([[10.0], [20.0], [15.0]])\n\n        # 1. Map without labels\n        mapped_points = cont2disc(continuous_points, discrete_candidates)\n\n        # 2. Map with labels\n        mapped_points_X, mapped_points_y = cont2disc(continuous_points, discrete_candidates, discrete_labels)\n        ```\n    \"\"\"\n    # Sanity check to handle empty inputs gracefully\n    if len(candidates) == 0 or len(Xu) == 0:\n        if candidate_labels is not None:\n            return np.empty((0, Xu.shape[1])), np.empty((0, 1))\n        else:\n            return np.empty((0, Xu.shape[1]))\n\n    # Compute pairwise Euclidean distances between candidates and Xu\n    dists = pairwise_distances(candidates, Y=Xu, metric='euclidean')\n\n    # Use the Hungarian algorithm (linear_sum_assignment) to find the optimal\n    # assignment of rows (candidates) to columns (Xu points) that minimizes\n    # the total cost (distances). `row_ind` gives the indices of the rows\n    # (candidates) chosen, `col_ind` gives the corresponding indices of `Xu`.\n    row_ind, col_ind = linear_sum_assignment(dists)\n\n    # Select the candidate locations that were matched to Xu points\n    Xu_X = candidates[row_ind].copy()\n\n    if candidate_labels is not None:\n        # If labels are provided, select the corresponding labels as well\n        Xu_y = candidate_labels[row_ind].copy()\n        return Xu_X, Xu_y\n    else:\n        return Xu_X\n</code></pre>"},{"location":"api/utils/misc.html#sgptools.utils.misc.get_inducing_pts","title":"<code>get_inducing_pts(data, num_inducing, orientation=False, random=False, seed=None)</code>","text":"<p>Selects a subset of data points to be used as inducing points. By default, it uses k-means clustering to select representative points. Alternatively, it can select points randomly. If <code>orientation</code> is True, an additional dimension representing a rotation angle is appended to each inducing point.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>(n, d_in); Input data points from which to select inducing points.                <code>n</code> is the number of data points, <code>d_in</code> is the input dimensionality.</p> required <code>num_inducing</code> <code>int</code> <p>The desired number of inducing points to select.</p> required <code>orientation</code> <code>bool</code> <p>If True, a random orientation angle (in radians, from 0 to 2*pi)                 is added as an additional dimension to each inducing point.                 Defaults to False.</p> <code>False</code> <code>random</code> <code>bool</code> <p>If True, inducing points are selected randomly from <code>data</code>.            If False, k-means clustering (<code>kmeans2</code>) is used for selection.            Defaults to False.</p> <code>False</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for reproducibility of the random point sampling.                   Defaults to None.</p> <code>None</code> <p>Returns:     np.ndarray: (m, d_out); Inducing points. <code>m</code> is <code>num_inducing</code>.                 <code>d_out</code> is <code>d_in</code> if <code>orientation</code> is False, or <code>d_in + 1</code> if <code>orientation</code> is True.                 If <code>orientation</code> is True, the last dimension contains angles in radians.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.misc import get_inducing_pts\n\n# Example data (1000 2D points)\ndata_points = np.random.rand(1000, 2) * 100\n\n# 1. Select 50 inducing points using k-means (default)\ninducing_points_kmeans = get_inducing_pts(data_points, 50)\n\n# 2. Select 20 inducing points randomly with orientation\ninducing_points_random_oriented = get_inducing_pts(data_points, 20, orientation=True, random=True)\n</code></pre> Source code in <code>sgptools/utils/misc.py</code> <pre><code>def get_inducing_pts(data: np.ndarray,\n                     num_inducing: int,\n                     orientation: bool = False,\n                     random: bool = False,\n                     seed: Optional[int] = None) -&gt; np.ndarray:\n    \"\"\"\n    Selects a subset of data points to be used as inducing points.\n    By default, it uses k-means clustering to select representative points.\n    Alternatively, it can select points randomly.\n    If `orientation` is True, an additional dimension representing a rotation angle\n    is appended to each inducing point.\n\n    Args:\n        data (np.ndarray): (n, d_in); Input data points from which to select inducing points.\n                           `n` is the number of data points, `d_in` is the input dimensionality.\n        num_inducing (int): The desired number of inducing points to select.\n        orientation (bool): If True, a random orientation angle (in radians, from 0 to 2*pi)\n                            is added as an additional dimension to each inducing point.\n                            Defaults to False.\n        random (bool): If True, inducing points are selected randomly from `data`.\n                       If False, k-means clustering (`kmeans2`) is used for selection.\n                       Defaults to False.\n        seed (Optional[int]): Seed for reproducibility of the random point sampling.\n                              Defaults to None.\n    Returns:\n        np.ndarray: (m, d_out); Inducing points. `m` is `num_inducing`.\n                    `d_out` is `d_in` if `orientation` is False, or `d_in + 1` if `orientation` is True.\n                    If `orientation` is True, the last dimension contains angles in radians.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.misc import get_inducing_pts\n\n        # Example data (1000 2D points)\n        data_points = np.random.rand(1000, 2) * 100\n\n        # 1. Select 50 inducing points using k-means (default)\n        inducing_points_kmeans = get_inducing_pts(data_points, 50)\n\n        # 2. Select 20 inducing points randomly with orientation\n        inducing_points_random_oriented = get_inducing_pts(data_points, 20, orientation=True, random=True)\n        ```\n    \"\"\"\n    if random:\n        # Randomly select `num_inducing` indices from the data\n        idx = np.random.choice(len(data), size=num_inducing, replace=False)\n        Xu = data[idx]\n    else:\n        # Use k-means clustering to find `num_inducing` cluster centers\n        # `minit=\"points\"` initializes centroids by picking random data points\n        Xu = kmeans2(data, num_inducing, minit=\"points\", seed=seed)[0]\n\n    if orientation:\n        # Generate random angles between 0 and 2*pi (radians)\n        thetas = np.random.uniform(0, 2 * np.pi, size=(Xu.shape[0], 1))\n        # Concatenate the points with their corresponding angles\n        Xu = np.concatenate([Xu, thetas], axis=1)\n\n    return Xu\n</code></pre>"},{"location":"api/utils/misc.html#sgptools.utils.misc.polygon2candidates","title":"<code>polygon2candidates(vertices, num_samples=5000, seed=None)</code>","text":"<p>Samples a specified number of candidate points randomly within a polygon defined by its vertices. This function leverages <code>geopandas</code> for geometric operations.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <code>ndarray</code> <p>(v, 2); A NumPy array where each row represents the (x, y)                    coordinates of a vertex defining the polygon. <code>v</code> is the                    number of vertices. The polygon is closed automatically if                    the first and last vertices are not identical.</p> required <code>num_samples</code> <code>int</code> <p>The desired number of candidate points to sample within the polygon.                Defaults to 5000.</p> <code>5000</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for reproducibility of the random point sampling.                   Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (n, 2); A NumPy array where each row represents the (x, y) coordinates          of a sampled candidate sensor placement location. <code>n</code> is <code>num_samples</code>.</p> Usage <pre><code>import numpy as np\n# from sgptools.utils.misc import polygon2candidates\n\n# Define vertices for a square polygon\nsquare_vertices = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n\n# Sample 100 candidate points within the square\nsampled_candidates = polygon2candidates(square_vertices, num_samples=100, random_seed=42)\n</code></pre> Source code in <code>sgptools/utils/misc.py</code> <pre><code>def polygon2candidates(vertices: np.ndarray,\n                       num_samples: int = 5000,\n                       seed: Optional[int] = None) -&gt; np.ndarray:\n    \"\"\"\n    Samples a specified number of candidate points randomly within a polygon defined by its vertices.\n    This function leverages `geopandas` for geometric operations.\n\n    Args:\n        vertices (np.ndarray): (v, 2); A NumPy array where each row represents the (x, y)\n                               coordinates of a vertex defining the polygon. `v` is the\n                               number of vertices. The polygon is closed automatically if\n                               the first and last vertices are not identical.\n        num_samples (int): The desired number of candidate points to sample within the polygon.\n                           Defaults to 5000.\n        seed (Optional[int]): Seed for reproducibility of the random point sampling.\n                              Defaults to None.\n\n    Returns:\n       np.ndarray: (n, 2); A NumPy array where each row represents the (x, y) coordinates\n                   of a sampled candidate sensor placement location. `n` is `num_samples`.\n\n    Usage:\n        ```python\n        import numpy as np\n        # from sgptools.utils.misc import polygon2candidates\n\n        # Define vertices for a square polygon\n        square_vertices = np.array([[0, 0], [10, 0], [10, 10], [0, 10]])\n\n        # Sample 100 candidate points within the square\n        sampled_candidates = polygon2candidates(square_vertices, num_samples=100, random_seed=42)\n        ```\n    \"\"\"\n    # Create a shapely Polygon object from the provided vertices\n    poly = geometry.Polygon(vertices)\n\n    # Create a GeoSeries containing the polygon, which enables sampling points\n    sampler = gpd.GeoSeries([poly])\n\n    # Sample random points within the polygon\n    candidates_geoseries = sampler.sample_points(\n        size=num_samples,\n        rng=seed)  # `rng` is for random number generator seed\n\n    # Extract coordinates from the GeoSeries of points and convert to a NumPy array\n    candidates_array = candidates_geoseries.get_coordinates().to_numpy()\n\n    return candidates_array\n</code></pre>"},{"location":"api/utils/misc.html#sgptools.utils.misc.project_waypoints","title":"<code>project_waypoints(waypoints, candidates)</code>","text":"<p>This function maps a given path (a sequence of waypoints) to a new path consisting of points from a discrete set of candidate locations. It ensures that the original visitation order of the waypoints is preserved in the final projected path.</p> <p>Parameters:</p> Name Type Description Default <code>waypoints</code> <code>ndarray</code> <p>(m, d); The continuous waypoints of the robot's path,                     where <code>m</code> is the number of waypoints and <code>d</code> is the                     dimensionality.</p> required <code>candidates</code> <code>ndarray</code> <p>(n, d); The discrete set of candidate locations,                      where <code>n</code> is the number of candidates.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (m, d); The projected waypoints on the discrete candidate set,         ordered to match the original path sequence.</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.misc import project_waypoints\n\n# A path with 3 waypoints in a 2D space\npath_waypoints = np.array([[0.1, 0.1], [0.8, 0.8], [0.1, 0.9]])\n\n# A set of 4 possible discrete locations\ncandidate_locations = np.array([[0, 0], [1, 1], [0, 1], [0.5, 0.5]])\n\n# Project the path onto the candidate locations\nprojected_path = project_waypoints(path_waypoints, candidate_locations)\n\n# The output will be a new path of shape (3, 2) composed of points from\n# candidate_locations, ordered to best match the original path.\n# e.g., [[0, 0], [1, 1], [0, 1]]\n</code></pre> Source code in <code>sgptools/utils/misc.py</code> <pre><code>def project_waypoints(waypoints: np.ndarray, candidates: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    This function maps a given path (a sequence of waypoints) to a new path\n    consisting of points from a discrete set of candidate locations. It ensures\n    that the original visitation order of the waypoints is preserved in the\n    final projected path.\n\n    Args:\n        waypoints (np.ndarray): (m, d); The continuous waypoints of the robot's path,\n                                where `m` is the number of waypoints and `d` is the\n                                dimensionality.\n        candidates (np.ndarray): (n, d); The discrete set of candidate locations,\n                                 where `n` is the number of candidates.\n\n    Returns:\n        np.ndarray: (m, d); The projected waypoints on the discrete candidate set,\n                    ordered to match the original path sequence.\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.misc import project_waypoints\n\n        # A path with 3 waypoints in a 2D space\n        path_waypoints = np.array([[0.1, 0.1], [0.8, 0.8], [0.1, 0.9]])\n\n        # A set of 4 possible discrete locations\n        candidate_locations = np.array([[0, 0], [1, 1], [0, 1], [0.5, 0.5]])\n\n        # Project the path onto the candidate locations\n        projected_path = project_waypoints(path_waypoints, candidate_locations)\n\n        # The output will be a new path of shape (3, 2) composed of points from\n        # candidate_locations, ordered to best match the original path.\n        # e.g., [[0, 0], [1, 1], [0, 1]]\n        ```\n    \"\"\"\n    waypoints_disc = cont2disc(waypoints, candidates)\n    dists = pairwise_distances(waypoints, Y=waypoints_disc, metric='euclidean')\n    _, col_ind = linear_sum_assignment(dists)\n    waypoints_valid = waypoints_disc[col_ind].copy()\n    return waypoints_valid\n</code></pre>"},{"location":"api/utils/tsp.html","title":"TSP","text":""},{"location":"api/utils/tsp.html#sgptools.utils.tsp","title":"<code>sgptools.utils.tsp</code>","text":""},{"location":"api/utils/tsp.html#sgptools.utils.tsp.resample_path","title":"<code>resample_path(waypoints, num_inducing=10)</code>","text":"<p>Resamples a given path (sequence of waypoints) to have a fixed number of <code>num_inducing</code> points. This is useful for standardizing path representations or for converting a path with an arbitrary number of waypoints into a fixed-size representation for models. The resampling maintains the path's shape and geometric integrity.</p> <p>Parameters:</p> Name Type Description Default <code>waypoints</code> <code>ndarray</code> <p>(num_waypoints, ndim); A NumPy array representing the                     waypoints of a path. <code>num_waypoints</code> is the original                     number of points, <code>ndim</code> is the dimensionality.</p> required <code>num_inducing</code> <code>int</code> <p>The desired number of points in the resampled path. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (num_inducing, ndim); The resampled path with <code>num_inducing</code> points.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the input <code>ndim</code> is not 2 or 3 (as <code>shapely.geometry.LineString</code>        primarily supports 2D/3D geometries).</p> Usage <pre><code>import numpy as np\nfrom sgptools.utils.tsp import resample_path\n\n# Example 2D path\noriginal_path_2d = np.array([[0,0], [1,5], [3,0], [5,5]], dtype=np.float64)\nresampled_path_2d = resample_path(original_path_2d, num_inducing=5)\n\n# Example 3D path\noriginal_path_3d = np.array([[0,0,0], [1,1,1], [2,0,2]], dtype=np.float64)\nresampled_path_3d = resample_path(original_path_3d, num_inducing=7)\n</code></pre> Source code in <code>sgptools/utils/tsp.py</code> <pre><code>def resample_path(waypoints: np.ndarray, num_inducing: int = 10) -&gt; np.ndarray:\n    \"\"\"Resamples a given path (sequence of waypoints) to have a fixed number of\n    `num_inducing` points. This is useful for standardizing path representations\n    or for converting a path with an arbitrary number of waypoints into a\n    fixed-size representation for models. The resampling maintains the path's\n    shape and geometric integrity.\n\n    Args:\n        waypoints (np.ndarray): (num_waypoints, ndim); A NumPy array representing the\n                                waypoints of a path. `num_waypoints` is the original\n                                number of points, `ndim` is the dimensionality.\n        num_inducing (int): The desired number of points in the resampled path. Defaults to 10.\n\n    Returns:\n        np.ndarray: (num_inducing, ndim); The resampled path with `num_inducing` points.\n\n    Raises:\n        Exception: If the input `ndim` is not 2 or 3 (as `shapely.geometry.LineString`\n                   primarily supports 2D/3D geometries).\n\n    Usage:\n        ```python\n        import numpy as np\n        from sgptools.utils.tsp import resample_path\n\n        # Example 2D path\n        original_path_2d = np.array([[0,0], [1,5], [3,0], [5,5]], dtype=np.float64)\n        resampled_path_2d = resample_path(original_path_2d, num_inducing=5)\n\n        # Example 3D path\n        original_path_3d = np.array([[0,0,0], [1,1,1], [2,0,2]], dtype=np.float64)\n        resampled_path_3d = resample_path(original_path_3d, num_inducing=7)\n        ```\n    \"\"\"\n    ndim = np.shape(waypoints)[-1]\n    if not (ndim == 2 or ndim == 3):\n        raise Exception(f\"ndim={ndim} is not supported for path resampling!\")\n    line = LineString(waypoints)\n    distances = np.linspace(0, line.length, num_inducing)\n    points = [line.interpolate(distance) for distance in distances]\n    if ndim == 2:\n        resampled_points = np.array([[p.x, p.y] for p in points])\n    elif ndim == 3:\n        resampled_points = np.array([[p.x, p.y, p.z] for p in points])\n    return resampled_points\n</code></pre>"},{"location":"api/utils/tsp.html#sgptools.utils.tsp.run_tsp","title":"<code>run_tsp(nodes, num_vehicles=1, max_dist=25.0, depth=1, resample=None, start_nodes=None, end_nodes=None, time_limit=10)</code>","text":"<p>Method to run TSP/VRP with arbitrary start and end nodes, and without any distance constraint.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>ndarray</code> <p>(# nodes, ndim); Nodes to visit.</p> required <code>num_vehicles</code> <code>int</code> <p>Number of robots/vehicles.</p> <code>1</code> <code>max_dist</code> <code>float</code> <p>Maximum distance allowed for each path when handling multi-robot case.</p> <code>25.0</code> <code>depth</code> <code>int</code> <p>Internal parameter used to track re-try recursion depth.</p> <code>1</code> <code>resample</code> <code>Optional[int]</code> <p>Each solution path will be resampled to have                        <code>resample</code> number of points.</p> <code>None</code> <code>start_nodes</code> <code>Optional[ndarray]</code> <p>(# num_vehicles, ndim); Optional array of start nodes from which                                  to start each vehicle's solution path.</p> <code>None</code> <code>end_nodes</code> <code>Optional[ndarray]</code> <p>(# num_vehicles, ndim); Optional array of end nodes at which                                to end each vehicle's solution path.</p> <code>None</code> <code>time_limit</code> <code>int</code> <p>TSP runtime time limit in seconds.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple[Optional[ndarray], Optional[List[float]]]</code> <p>Tuple[Optional[np.ndarray], Optional[List[float]]]: - paths (np.ndarray): Solution paths if found, otherwise None. - distances (List[float]): List of path lengths if paths are found, otherwise None.</p> Source code in <code>sgptools/utils/tsp.py</code> <pre><code>def run_tsp(\n    nodes: np.ndarray,\n    num_vehicles: int = 1,\n    max_dist: float = 25.0,\n    depth: int = 1,\n    resample: Optional[int] = None,\n    start_nodes: Optional[np.ndarray] = None,\n    end_nodes: Optional[np.ndarray] = None,\n    time_limit: int = 10,\n) -&gt; Tuple[Optional[np.ndarray], Optional[List[float]]]:\n    \"\"\"Method to run TSP/VRP with arbitrary start and end nodes,\n    and without any distance constraint.\n\n    Args:\n        nodes (np.ndarray): (# nodes, ndim); Nodes to visit.\n        num_vehicles (int): Number of robots/vehicles.\n        max_dist (float): Maximum distance allowed for each path when handling multi-robot case.\n        depth (int): Internal parameter used to track re-try recursion depth.\n        resample (Optional[int]): Each solution path will be resampled to have\n                                   `resample` number of points.\n        start_nodes (Optional[np.ndarray]): (# num_vehicles, ndim); Optional array of start nodes from which\n                                             to start each vehicle's solution path.\n        end_nodes (Optional[np.ndarray]): (# num_vehicles, ndim); Optional array of end nodes at which\n                                           to end each vehicle's solution path.\n        time_limit (int): TSP runtime time limit in seconds.\n\n    Returns:\n        Tuple[Optional[np.ndarray], Optional[List[float]]]:\n            - paths (np.ndarray): Solution paths if found, otherwise None.\n            - distances (List[float]): List of path lengths if paths are found, otherwise None.\n    \"\"\"\n    if depth &gt; 5:\n        print('Warning: Max depth reached')\n        return None, None\n\n    # Backup original nodes\n    original_nodes = np.copy(nodes)\n\n    # Add the start and end nodes to the node list\n    if end_nodes is not None:\n        assert end_nodes.shape == (num_vehicles, nodes.shape[-1]), \\\n            \"Incorrect end_nodes shape, should be (num_vehicles, ndim)!\"\n        nodes = np.concatenate([end_nodes, nodes])\n    if start_nodes is not None:\n        assert start_nodes.shape == (num_vehicles, nodes.shape[-1]), \\\n            \"Incorrect start_nodes shape, should be (num_vehicles, ndim)!\"\n        nodes = np.concatenate([start_nodes, nodes])\n\n    # Add dummy 0 location to get arbitrary start and end node sols\n    if start_nodes is None or end_nodes is None:\n        distance_mat = np.zeros((len(nodes) + 1, len(nodes) + 1))\n        distance_mat[1:, 1:] = pairwise_distances(nodes, nodes) * 1e4\n        trim_paths = True  #shift to account for dummy node\n    else:\n        distance_mat = pairwise_distances(nodes, nodes) * 1e4\n        trim_paths = False\n    distance_mat = distance_mat.astype(int)\n    max_dist = int(max_dist * 1e4)\n\n    # Get start and end node indices for ortools\n    if start_nodes is None:\n        start_idx = np.zeros(num_vehicles, dtype=int)\n        num_start_nodes = 0\n    else:\n        start_idx = np.arange(num_vehicles) + int(trim_paths)\n        num_start_nodes = len(start_nodes)\n\n    if end_nodes is None:\n        end_idx = np.zeros(num_vehicles, dtype=int)\n    else:\n        end_idx = np.arange(num_vehicles) + num_start_nodes + int(trim_paths)\n\n    # used by ortools\n    def distance_callback(from_index, to_index):\n        from_node = manager.IndexToNode(from_index)\n        to_node = manager.IndexToNode(to_index)\n        return distance_mat[from_node][to_node]\n\n    # num_locations, num vehicles, start, end\n    manager = pywrapcp.RoutingIndexManager(len(distance_mat), num_vehicles,\n                                           start_idx.tolist(),\n                                           end_idx.tolist())\n    routing = pywrapcp.RoutingModel(manager)\n    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\n    if num_vehicles &gt; 1:\n        # Dummy distaance constraint to ensure all paths have similar length\n        dimension_name = \"Distance\"\n        routing.AddDimension(\n            transit_callback_index,\n            0,  # no slack\n            max_dist,  # vehicle maximum travel distance\n            True,  # start cumul to zero\n            dimension_name,\n        )\n        distance_dimension = routing.GetDimensionOrDie(dimension_name)\n        distance_dimension.SetGlobalSpanCostCoefficient(100)\n\n    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n    search_parameters.first_solution_strategy = (\n        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n    search_parameters.local_search_metaheuristic = (\n        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n    search_parameters.time_limit.seconds = time_limit\n    solution = routing.SolveWithParameters(search_parameters)\n\n    paths: Optional[List[np.ndarray]] = None\n    distances: Optional[List[float]] = None\n\n    if solution is not None:\n        paths_indices, distances_raw = _get_routes(manager, routing, solution,\n                                                   num_vehicles, start_idx,\n                                                   end_idx, trim_paths)\n\n        # Check for empty paths and retry with increased max_dist if necessary\n        for path in paths_indices:\n            if len(path) &lt; 2:\n                print(\n                    \"TSP Warning: Empty path detected, retrying with increased max_dist.\"\n                )\n                # Recalculate max_dist based on the current average distance\n                mean_dist = np.mean(\n                    distances_raw) / 1e4 if distances_raw else max_dist\n                return run_tsp(\n                    original_nodes,\n                    num_vehicles,\n                    mean_dist * (1.5 / depth),\n                    depth + 1,\n                    resample,\n                    start_nodes,\n                    end_nodes,\n                    time_limit,\n                )\n        paths = [nodes[path] for path in paths_indices]\n        distances = [d / 1e4 for d in distances_raw]\n\n    else:\n        print(\n            \"TSP Warning: No solution found, retrying with increased max_dist.\"\n        )\n        return run_tsp(\n            original_nodes,\n            num_vehicles,\n            max_dist * 1.5,\n            depth + 1,\n            resample,\n            start_nodes,\n            end_nodes,\n            time_limit,\n        )\n\n    # Resample each solution path to have resample number of points\n    if resample is not None and paths is not None:\n        paths = np.array([resample_path(path, resample) for path in paths])\n\n    return paths, distances\n</code></pre>"},{"location":"tutorials/index.html","title":"Tutorials","text":"<p>This collection of tutorials will guide you through the features and capabilities of the <code>sgptools</code> library. You will learn how to model a variety of sensor placement and informative path planning problems, from basic setups to more advanced, real-world scenarios.</p> <p>We include tutorials for the following:</p> <ul> <li> <p>Informative Path Planning: This tutorial covers various Informative Path Planning (IPP) scenarios using the <code>sgptools</code> library. It starts with a basic setup and then explores single-robot and multi-robot IPP with different sensor configurations.</p> </li> <li> <p>Adaptive Informative Path Planning: This tutorial demonstrates Adaptive Informative Path Planning (AIPP), where a robot can update its understanding of the environment and re-plan its path on the fly as it gathers new data.</p> </li> <li> <p>Non-Stationary Kernels: This tutorial walks you through using non-stationary kernels within the <code>sgptools</code> library. It compares the performance of a <code>Neural Kernel</code>, an <code>Attentive Kernel</code>, and a standard <code>RBF Kernel</code> on a sensor placement task.</p> </li> </ul>"},{"location":"tutorials/AIPP.html","title":"Adaptive Informative Path Planning","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n\nimport numpy as np\nimport tensorflow as tf\nfrom time import time\n\n# Import necessary components from sgptools\nfrom sgptools.utils.metrics import get_reconstruction, get_rmse\nfrom sgptools.utils.data import Dataset\nfrom sgptools.core.osgpr import init_osgpr\nfrom sgptools.utils.tsp import run_tsp\nfrom sgptools.utils.gpflow import get_model_params, optimize_model\nfrom sgptools.methods import ContinuousSGP\nfrom sgptools.core.transformations import IPPTransform, SquareHeightTransform\nfrom gpflow.utilities import print_summary\nfrom sgptools.utils.misc import get_inducing_pts\n\n# Plotting libraries for visualization\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nimport mpl_toolkits.mplot3d.art3d as art3d\nfrom scipy.optimize import linear_sum_assignment\nfrom sklearn.metrics import pairwise_distances\n\n# Set random seeds for reproducibility\nnp.random.seed(1234)\ntf.random.set_seed(1234)\n</pre> import os os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  import numpy as np import tensorflow as tf from time import time  # Import necessary components from sgptools from sgptools.utils.metrics import get_reconstruction, get_rmse from sgptools.utils.data import Dataset from sgptools.core.osgpr import init_osgpr from sgptools.utils.tsp import run_tsp from sgptools.utils.gpflow import get_model_params, optimize_model from sgptools.methods import ContinuousSGP from sgptools.core.transformations import IPPTransform, SquareHeightTransform from gpflow.utilities import print_summary from sgptools.utils.misc import get_inducing_pts  # Plotting libraries for visualization from matplotlib import colors import matplotlib.pyplot as plt from matplotlib.patches import Polygon import mpl_toolkits.mplot3d.art3d as art3d from scipy.optimize import linear_sum_assignment from sklearn.metrics import pairwise_distances  # Set random seeds for reproducibility np.random.seed(1234) tf.random.set_seed(1234) In\u00a0[2]: Copied! <pre>def get_vertices(Xu, X_fov):\n    \"\"\"\n    A utility function to calculate the corner vertices of the square FoV for plotting.\n    It takes the central waypoint coordinates (`Xu`) and the expanded FoV points (`X_fov`)\n    and returns the coordinates of the four corners of the square.\n    \"\"\"\n    X_fov = X_fov.reshape(len(Xu), -1, 2)\n    vertices = np.zeros((len(Xu), 5, 2))\n    vertices[:, 0] = X_fov.min(axis=1)\n    vertices[:, 1] = np.array([X_fov[:, :, 0].min(axis=1),\n                              X_fov[:, :, 1].max(axis=1)]).T\n    vertices[:, 2] = X_fov.max(axis=1)\n    vertices[:, 3] = np.array([X_fov[:, :, 0].max(axis=1),\n                              X_fov[:, :, 1].min(axis=1)]).T\n    vertices[:, 4] = X_fov.mean(axis=1)\n\n    dists = pairwise_distances(vertices[:, 4], Y=Xu[:, :2],\n                               metric='euclidean')\n    _, idx = linear_sum_assignment(dists)\n\n    vertices[:, 4] = Xu[idx][:, :2]\n    return vertices\n\ndef plot_results(path, dataset, noise_variance, kernel,\n                 current_idx=0, fov_points=None):\n    \"\"\"\n    This function visualizes the state of the simulation at a single time step.\n    It creates a 3D plot showing:\n    - The robot's reconstructed map of the environment.\n    - The path the robot has traveled so far.\n    - The path the robot plans to travel next.\n    - The sensor's Field of View (FoV) at each waypoint.\n    \"\"\"\n    # Get sensor data from the waypoints visited so far\n    current_idx += 1 # Adjust for zero-based indexing\n    num_fov_pts = len(fov_points)//len(path)\n    sol_X, sol_y = dataset.get_sensor_data(fov_points[:num_fov_pts*(current_idx)], \n                                           max_samples=1500)\n    # Create a GP model to reconstruct the data field from the gathered sensor data\n    y_pred, _ = get_reconstruction((sol_X, sol_y), dataset.get_test()[0],\n                                   noise_variance, kernel)\n\n    # Setup 3D plot\n    fig = plt.figure(figsize=(5, 5))\n    ax = fig.add_subplot(111, projection='3d', computed_zorder=False)\n\n    # Plot the reconstructed environment state as a colored surface on the floor of the plot\n    vmin = min(dataset.y.min(), y_pred.min())\n    vmax = max(dataset.y.max(), y_pred.max())\n    norm = colors.Normalize(vmin, vmax)\n    data_shape = dataset.y.shape\n    _ = ax.plot_surface(dataset.get_test()[0][:, 0].reshape(data_shape),\n                        dataset.get_test()[0][:, 1].reshape(data_shape),\n                        np.atleast_2d(-0.1),\n                        facecolors=plt.cm.jet(norm(y_pred.reshape(data_shape))),\n                        shade=False,\n                        alpha=0.8,\n                        zorder=0)\n\n    # Plot the solution path: visited waypoints in red, planned waypoints in green\n    ax.scatter(path[:current_idx, 0],\n               path[:current_idx, 1],\n               path[:current_idx, 2], c='C3')\n    ax.scatter(path[current_idx:, 0],\n               path[current_idx:, 1],\n               path[current_idx:, 2], c='C2')\n    ax.plot(path[:, 0], path[:, 1], path[:, 2], 'k-')\n\n    # Plot the square Field of View at each waypoint\n    vertices = get_vertices(path, fov_points)\n    for i in range(vertices.shape[0]):\n        color = 'C3' if i &lt; current_idx else 'C2'\n        verts = []\n        verts.append([vertices[i, 0], vertices[i, 1],\n                      vertices[i, 2], vertices[i, 3]])\n        fov = Polygon(np.array(verts)[0, :, :2],\n                      linewidth=1.5,\n                      edgecolor=color,\n                      facecolor=color,\n                      fill=False,\n                      zorder=15)\n        ax.add_patch(fov)\n        art3d.pathpatch_2d_to_3d(fov)\n\n    # Configure plot labels, limits, and view angle\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n\n    ax.set_xlim(np.min(dataset.get_train()[0][:, 0])-0.5, np.max(dataset.get_train()[0][:, 0])+0.5)\n    ax.set_ylim(np.min(dataset.get_train()[0][:, 1])-0.5, np.max(dataset.get_train()[0][:, 1])+0.5)\n    ax.set_zlim(0, 14)\n\n    ax.view_init(elev=30, azim=45+180)\n    ax.set_title(f'Waypoint: {current_idx}, RMSE: {get_rmse(y_pred, dataset.get_test()[1]):.2f}\\nData Field Reconstruction', y=0.99)\n\n    plt.tight_layout()\n    plt.show()\n</pre> def get_vertices(Xu, X_fov):     \"\"\"     A utility function to calculate the corner vertices of the square FoV for plotting.     It takes the central waypoint coordinates (`Xu`) and the expanded FoV points (`X_fov`)     and returns the coordinates of the four corners of the square.     \"\"\"     X_fov = X_fov.reshape(len(Xu), -1, 2)     vertices = np.zeros((len(Xu), 5, 2))     vertices[:, 0] = X_fov.min(axis=1)     vertices[:, 1] = np.array([X_fov[:, :, 0].min(axis=1),                               X_fov[:, :, 1].max(axis=1)]).T     vertices[:, 2] = X_fov.max(axis=1)     vertices[:, 3] = np.array([X_fov[:, :, 0].max(axis=1),                               X_fov[:, :, 1].min(axis=1)]).T     vertices[:, 4] = X_fov.mean(axis=1)      dists = pairwise_distances(vertices[:, 4], Y=Xu[:, :2],                                metric='euclidean')     _, idx = linear_sum_assignment(dists)      vertices[:, 4] = Xu[idx][:, :2]     return vertices  def plot_results(path, dataset, noise_variance, kernel,                  current_idx=0, fov_points=None):     \"\"\"     This function visualizes the state of the simulation at a single time step.     It creates a 3D plot showing:     - The robot's reconstructed map of the environment.     - The path the robot has traveled so far.     - The path the robot plans to travel next.     - The sensor's Field of View (FoV) at each waypoint.     \"\"\"     # Get sensor data from the waypoints visited so far     current_idx += 1 # Adjust for zero-based indexing     num_fov_pts = len(fov_points)//len(path)     sol_X, sol_y = dataset.get_sensor_data(fov_points[:num_fov_pts*(current_idx)],                                             max_samples=1500)     # Create a GP model to reconstruct the data field from the gathered sensor data     y_pred, _ = get_reconstruction((sol_X, sol_y), dataset.get_test()[0],                                    noise_variance, kernel)      # Setup 3D plot     fig = plt.figure(figsize=(5, 5))     ax = fig.add_subplot(111, projection='3d', computed_zorder=False)      # Plot the reconstructed environment state as a colored surface on the floor of the plot     vmin = min(dataset.y.min(), y_pred.min())     vmax = max(dataset.y.max(), y_pred.max())     norm = colors.Normalize(vmin, vmax)     data_shape = dataset.y.shape     _ = ax.plot_surface(dataset.get_test()[0][:, 0].reshape(data_shape),                         dataset.get_test()[0][:, 1].reshape(data_shape),                         np.atleast_2d(-0.1),                         facecolors=plt.cm.jet(norm(y_pred.reshape(data_shape))),                         shade=False,                         alpha=0.8,                         zorder=0)      # Plot the solution path: visited waypoints in red, planned waypoints in green     ax.scatter(path[:current_idx, 0],                path[:current_idx, 1],                path[:current_idx, 2], c='C3')     ax.scatter(path[current_idx:, 0],                path[current_idx:, 1],                path[current_idx:, 2], c='C2')     ax.plot(path[:, 0], path[:, 1], path[:, 2], 'k-')      # Plot the square Field of View at each waypoint     vertices = get_vertices(path, fov_points)     for i in range(vertices.shape[0]):         color = 'C3' if i &lt; current_idx else 'C2'         verts = []         verts.append([vertices[i, 0], vertices[i, 1],                       vertices[i, 2], vertices[i, 3]])         fov = Polygon(np.array(verts)[0, :, :2],                       linewidth=1.5,                       edgecolor=color,                       facecolor=color,                       fill=False,                       zorder=15)         ax.add_patch(fov)         art3d.pathpatch_2d_to_3d(fov)      # Configure plot labels, limits, and view angle     ax.set_xlabel('X')     ax.set_ylabel('Y')     ax.set_zlabel('Z')      ax.set_xlim(np.min(dataset.get_train()[0][:, 0])-0.5, np.max(dataset.get_train()[0][:, 0])+0.5)     ax.set_ylim(np.min(dataset.get_train()[0][:, 1])-0.5, np.max(dataset.get_train()[0][:, 1])+0.5)     ax.set_zlim(0, 14)      ax.view_init(elev=30, azim=45+180)     ax.set_title(f'Waypoint: {current_idx}, RMSE: {get_rmse(y_pred, dataset.get_test()[1]):.2f}\\nData Field Reconstruction', y=0.99)      plt.tight_layout()     plt.show() In\u00a0[3]: Copied! <pre># Get the synthetic elevation data\ndataset = Dataset(shape=(100, 100), \n                  num_test=10000, \n                  random_seed=0,\n                  verbose=False)\nX_train, y_train = dataset.get_train()\nX_test, y_test = dataset.get_test()\n\n# Train a Gaussian Process (GP) model and get the optimized kernel parameters\n# `get_model_params` returns loss_values, noise_variance, kernel_object\n_, noise_variance_opt, kernel_opt = get_model_params(X_train, y_train, \n                                             lengthscales=[1.0, 1.0], # Initial lengthscales for the RBF kernel\n                                             optimizer='scipy.L-BFGS-B') # Use SciPy's L-BFGS-B optimizer\n\n# Plot the ground truth data\nplt.figure()\nim1 = plt.imshow(y_test.reshape(100, 100).T,\n                 cmap='jet', origin='lower',\n                 extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n                         np.min(X_test[:, 1]), np.max(X_test[:, 1])])\nax1 = plt.gca()\nax1.set_title('Ground Truth')\nax1.set_xlabel('X-coordinate')\nax1.set_ylabel('Y-coordinate')\nax1.set_aspect('equal', adjustable='box')\nax1.grid(True)\n</pre> # Get the synthetic elevation data dataset = Dataset(shape=(100, 100),                    num_test=10000,                    random_seed=0,                   verbose=False) X_train, y_train = dataset.get_train() X_test, y_test = dataset.get_test()  # Train a Gaussian Process (GP) model and get the optimized kernel parameters # `get_model_params` returns loss_values, noise_variance, kernel_object _, noise_variance_opt, kernel_opt = get_model_params(X_train, y_train,                                               lengthscales=[1.0, 1.0], # Initial lengthscales for the RBF kernel                                              optimizer='scipy.L-BFGS-B') # Use SciPy's L-BFGS-B optimizer  # Plot the ground truth data plt.figure() im1 = plt.imshow(y_test.reshape(100, 100).T,                  cmap='jet', origin='lower',                  extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),                          np.min(X_test[:, 1]), np.max(X_test[:, 1])]) ax1 = plt.gca() ax1.set_title('Ground Truth') ax1.set_xlabel('X-coordinate') ax1.set_ylabel('Y-coordinate') ax1.set_aspect('equal', adjustable='box') ax1.grid(True) <pre>2025-06-30 14:01:13.690761: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n</pre> <pre>\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                    \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 GPR.kernel.variance     \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.7356971010336169   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.kernel.lengthscales \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [2.16791 2.14484]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.likelihood.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.020845990883794487 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[\u00a0]: Copied! <pre>num_waypoints = 12\npts_per_side = 5  # The FoV will be approximated by a pts_per_sidexpts_per_side grid of points\n\n# We start with all the hyperparameters set to unit values. These will be updated online.\nprint('Initial AIPP Hyperparameters')\n_, noise_variance, kernel = get_model_params(X_train, y_train,\n                                             lengthscales=[1.0, 1.0],\n                                             max_steps=0)\n\n# Generate an initial path for the robot. We use `get_inducing_pts` to select\n# waypoints and then `run_tsp` to order them into a logical path.\n# The path is in 3D (x, y, altitude), so we initialize the altitude to 2.0.\nXu_init = get_inducing_pts(X_train, num_waypoints)\n# Initialize the height dimension for all points with random values\nheight = np.random.normal(loc = 2, size=(Xu_init.shape[0], 1))\nXu_init = np.concatenate((Xu_init, height), axis=1)\npaths, _ = run_tsp(Xu_init[:, :2])\nif paths:\n    Xu_init[:, :2] = paths[0]\n\n# Define the sensor model using `SquareHeightTransform`. This transform models an\n# FoV that changes size with altitude. We wrap it in an `IPPTransform` to integrate\n# it into our planning framework.\nfov_transform = SquareHeightTransform(pts_per_side=pts_per_side)\ntransform = IPPTransform(num_dim=3, # Defaults to 2\n                         sensor_model=fov_transform,\n                         aggregate_fov=False,\n                         distance_budget=120., # Distance budget for the robot\n                         constraint_weight=500.) # Weight for the distance constraint in optimization\n\n\n# Initialize the IPP model using the `ContinuousSGP` method. This is the core\n# component that will optimize the robot's path.\nipp_model = ContinuousSGP(\n    num_sensing=num_waypoints,\n    X_objective=X_train,\n    noise_variance=noise_variance,\n    kernel=kernel,\n    transform=transform,\n    X_init=Xu_init,\n)\n</pre> num_waypoints = 12 pts_per_side = 5  # The FoV will be approximated by a pts_per_sidexpts_per_side grid of points  # We start with all the hyperparameters set to unit values. These will be updated online. print('Initial AIPP Hyperparameters') _, noise_variance, kernel = get_model_params(X_train, y_train,                                              lengthscales=[1.0, 1.0],                                              max_steps=0)  # Generate an initial path for the robot. We use `get_inducing_pts` to select # waypoints and then `run_tsp` to order them into a logical path. # The path is in 3D (x, y, altitude), so we initialize the altitude to 2.0. Xu_init = get_inducing_pts(X_train, num_waypoints) # Initialize the height dimension for all points with random values height = np.random.normal(loc = 2, size=(Xu_init.shape[0], 1)) Xu_init = np.concatenate((Xu_init, height), axis=1) paths, _ = run_tsp(Xu_init[:, :2]) if paths:     Xu_init[:, :2] = paths[0]  # Define the sensor model using `SquareHeightTransform`. This transform models an # FoV that changes size with altitude. We wrap it in an `IPPTransform` to integrate # it into our planning framework. fov_transform = SquareHeightTransform(pts_per_side=pts_per_side) transform = IPPTransform(num_dim=3, # Defaults to 2                          sensor_model=fov_transform,                          aggregate_fov=False,                          distance_budget=120., # Distance budget for the robot                          constraint_weight=500.) # Weight for the distance constraint in optimization   # Initialize the IPP model using the `ContinuousSGP` method. This is the core # component that will optimize the robot's path. ipp_model = ContinuousSGP(     num_sensing=num_waypoints,     X_objective=X_train,     noise_variance=noise_variance,     kernel=kernel,     transform=transform,     X_init=Xu_init, ) <pre>Initial AIPP Hyperparameters\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                    \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 GPR.kernel.variance     \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 1.0                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.kernel.lengthscales \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [1. 1.]             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.likelihood.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.09999999999999999 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[5]: Copied! <pre>total_time_param = 0\ntotal_ipp_time = 0\ncurr_sol = Xu_init.copy().reshape(1, -1, 3)\n\n# Get the initial expanded path for the first plot\nexpanded_path = ipp_model.transform.expand(curr_sol.reshape(-1, 3), \n                                           expand_sensor_model=False)\nexpanded_path = expanded_path.numpy()\n\n# Plot the initial state before the mission starts\nplot_results(expanded_path,\n             dataset, noise_variance_opt, kernel_opt,\n             fov_points=ipp_model.transform.expand(curr_sol.reshape(-1, 3)).numpy())\n\n# Initialize the Online Sparse GP model (`OSGPR`) for hyperparameter updates\ninit_kernel, init_noise_variance = ipp_model.get_hyperparameters()\nparam_model = init_osgpr(X_train,\n                         num_inducing=40,\n                         kernel=init_kernel,\n                         noise_variance=init_noise_variance)\n\n# Main simulation loop\nfor time_step in range(num_waypoints):\n    print(f\"\\n--- Time Step {time_step + 1}/{num_waypoints} ---\")\n\n    # Get a new batch of data from the last visited waypoint\n    last_visited = curr_sol[:, time_step].copy()\n    data_pts = ipp_model.transform.sensor_model.expand(last_visited).numpy()\n    data_X_batch, data_y_batch = dataset.get_sensor_data(data_pts)\n\n    # Skip param and path update for the last waypoint\n    if time_step == num_waypoints - 1:\n        break\n\n    # Update the Online GP model (`OSGPR`) with the new data\n    print(\"Updating the online GP model model with new data...\")\n    param_model.update((np.array(data_X_batch),\n                        np.array(data_y_batch)),\n                        update_inducing=True)\n    # Optimize the kernel and noise hyperparameters of the online model\n    start_time = time()\n    optimize_model(param_model)\n    end_time = time()\n    total_time_param += end_time - start_time\n    print(\"Updated Kernel and Likelihood:\")\n    print_summary(param_model.kernel)\n    print_summary(param_model.likelihood)\n\n    # Update and re-plan the path with the `ContinuousSGP` model\n    print(\"Re-planning the rest of the path...\")\n    # Fix the waypoints that have already been visited\n    Xu_visited = curr_sol.copy()[:, :time_step + 1]\n    ipp_model.transform.update_Xu_fixed(Xu_visited)\n    # Update the planner with the new hyperparameters from the online model\n    ipp_model.update(param_model.kernel, \n                     param_model.likelihood.variance.numpy())\n    \n    # Optimize the remaining part of the path\n    start_time = time()\n    curr_sol = ipp_model.optimize(verbose=False)\n    end_time = time()\n    total_ipp_time += end_time - start_time\n    print(\"Path re-optimized.\")\n\n    # Visualize the current state\n    expanded_path = ipp_model.transform.expand(curr_sol.reshape(-1, 3), \n                                               expand_sensor_model=False)\n    expanded_path = expanded_path.numpy()\n\n    plot_results(expanded_path,\n                 dataset, noise_variance_opt, kernel_opt,\n                 current_idx=time_step + 1,\n                 fov_points=ipp_model.transform.expand(curr_sol.reshape(-1, 3)).numpy())\n</pre> total_time_param = 0 total_ipp_time = 0 curr_sol = Xu_init.copy().reshape(1, -1, 3)  # Get the initial expanded path for the first plot expanded_path = ipp_model.transform.expand(curr_sol.reshape(-1, 3),                                             expand_sensor_model=False) expanded_path = expanded_path.numpy()  # Plot the initial state before the mission starts plot_results(expanded_path,              dataset, noise_variance_opt, kernel_opt,              fov_points=ipp_model.transform.expand(curr_sol.reshape(-1, 3)).numpy())  # Initialize the Online Sparse GP model (`OSGPR`) for hyperparameter updates init_kernel, init_noise_variance = ipp_model.get_hyperparameters() param_model = init_osgpr(X_train,                          num_inducing=40,                          kernel=init_kernel,                          noise_variance=init_noise_variance)  # Main simulation loop for time_step in range(num_waypoints):     print(f\"\\n--- Time Step {time_step + 1}/{num_waypoints} ---\")      # Get a new batch of data from the last visited waypoint     last_visited = curr_sol[:, time_step].copy()     data_pts = ipp_model.transform.sensor_model.expand(last_visited).numpy()     data_X_batch, data_y_batch = dataset.get_sensor_data(data_pts)      # Skip param and path update for the last waypoint     if time_step == num_waypoints - 1:         break      # Update the Online GP model (`OSGPR`) with the new data     print(\"Updating the online GP model model with new data...\")     param_model.update((np.array(data_X_batch),                         np.array(data_y_batch)),                         update_inducing=True)     # Optimize the kernel and noise hyperparameters of the online model     start_time = time()     optimize_model(param_model)     end_time = time()     total_time_param += end_time - start_time     print(\"Updated Kernel and Likelihood:\")     print_summary(param_model.kernel)     print_summary(param_model.likelihood)      # Update and re-plan the path with the `ContinuousSGP` model     print(\"Re-planning the rest of the path...\")     # Fix the waypoints that have already been visited     Xu_visited = curr_sol.copy()[:, :time_step + 1]     ipp_model.transform.update_Xu_fixed(Xu_visited)     # Update the planner with the new hyperparameters from the online model     ipp_model.update(param_model.kernel,                       param_model.likelihood.variance.numpy())          # Optimize the remaining part of the path     start_time = time()     curr_sol = ipp_model.optimize(verbose=False)     end_time = time()     total_ipp_time += end_time - start_time     print(\"Path re-optimized.\")      # Visualize the current state     expanded_path = ipp_model.transform.expand(curr_sol.reshape(-1, 3),                                                 expand_sensor_model=False)     expanded_path = expanded_path.numpy()      plot_results(expanded_path,                  dataset, noise_variance_opt, kernel_opt,                  current_idx=time_step + 1,                  fov_points=ipp_model.transform.expand(curr_sol.reshape(-1, 3)).numpy()) <pre>\n--- Time Step 1/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value                   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.2327835934018852      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [0.98424141 1.14156   ] \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502     value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.0105753 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 2/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.3909714420310825 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [6.45418 3.54678]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502   value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.18264 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 3/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 1.95838           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [5.15126 3.71883] \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502    value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.110979 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 4/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.73042140691213  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [4.41423 4.14698] \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502    value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.058691 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 5/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.2286429758847512 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [3.35848 1.88981]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502    value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.126621 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 6/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.3813628961175243 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [2.44825 4.90212]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502   value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.11031 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 7/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.6266021176837389 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [3.47098 3.60558]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502    value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.122391 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 8/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.9663967915248568 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [4.44781 3.97362]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502   value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.24431 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 9/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.6044801308260008 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [2.88835 3.75912]  \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502     value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.0974913 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 10/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.17318604418364328 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [2.29347 3.45906]   \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502     value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.0740142 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 11/12 ---\nUpdating the online GP model model with new data...\nUpdated Kernel and Likelihood:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                            \u2502 class     \u2502 transform   \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SquaredExponential.variance     \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.37144769581607917 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SquaredExponential.lengthscales \u2502 Parameter \u2502 Softplus    \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [1.81332 5.9557 ]   \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name              \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502     value \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Gaussian.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.0585437 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\nRe-planning the rest of the path...\nPath re-optimized.\n</pre> <pre>\n--- Time Step 12/12 ---\n</pre> <p>The simulation is now complete! Let's review the total and average time taken for the two key adaptive steps: updating the online GP model and re-planning the path. In a real-world robotic system, these times are critical for ensuring the robot can make decisions in real-time.</p> In\u00a0[6]: Copied! <pre>print(\"\\n--- Mission Performance Summary ---\")\nprint(f\"Solution Path Total Length: {ipp_model.transform.sensor_model.distance(curr_sol.reshape(-1, 3)).numpy():.4f}\")\n\nprint(f'Total Hyperparameter Update Time:   {total_time_param:.2f}s')\nprint(f'Total IPP Update Time:              {total_ipp_time:.2f}s')\n\nprint(f'Average Hyperparameter Update Time: {total_time_param/num_waypoints:.2f}s')\nprint(f'Average IPP Update Time:            {total_ipp_time/num_waypoints:.2f}s')\n</pre> print(\"\\n--- Mission Performance Summary ---\") print(f\"Solution Path Total Length: {ipp_model.transform.sensor_model.distance(curr_sol.reshape(-1, 3)).numpy():.4f}\")  print(f'Total Hyperparameter Update Time:   {total_time_param:.2f}s') print(f'Total IPP Update Time:              {total_ipp_time:.2f}s')  print(f'Average Hyperparameter Update Time: {total_time_param/num_waypoints:.2f}s') print(f'Average IPP Update Time:            {total_ipp_time/num_waypoints:.2f}s') <pre>\n--- Mission Performance Summary ---\nSolution Path Total Length: 120.0000\nTotal Hyperparameter Update Time:   77.32s\nTotal IPP Update Time:              90.67s\nAverage Hyperparameter Update Time: 6.44s\nAverage IPP Update Time:            7.56s\n</pre>"},{"location":"tutorials/AIPP.html#adaptive-informative-path-planning","title":"Adaptive Informative Path Planning\u00b6","text":"<p>This tutorial will walk you through Adaptive Informative Path Planning (AIPP) using the <code>sgptools</code> library. In many real-world scenarios, a robot doesn't know everything about its environment from the start. AIPP addresses this by allowing the robot to update its understanding and re-plan its path on the fly as it gathers new data.</p> <p>This tutorial will demonstrate an AIPP scenario where:</p> <ol> <li>The robot has a non-point Field of View (FoV), specifically a square-shaped sensor whose size changes with its altitude, similar to a camera. This is much more realistic than assuming a simple point sensor.</li> <li>The robot adaptively re-plans its path. After visiting each waypoint, it uses the newly collected data to update its internal model of the world and then re-optimizes the remainder of its path.</li> </ol> <p>We will walk through the entire process, from setting up the environment to running the simulation and visualizing the robot's adaptive behavior step-by-step.</p>"},{"location":"tutorials/AIPP.html#setup-and-imports","title":"Setup and Imports\u00b6","text":"<p>We begin by importing the necessary libraries and modules.</p> <ul> <li><code>os</code>: Used to set environment variables to avoid potential conflicts with underlying libraries.</li> <li><code>numpy</code>: For numerical operations.</li> <li><code>tensorflow</code>: The backend for GPflow.</li> <li><code>matplotlib.pyplot</code>: For plotting the results.</li> <li><code>sgptools</code> modules: We import specific classes and functions from the library that we'll be using.</li> </ul>"},{"location":"tutorials/AIPP.html#helper-functions-for-plotting","title":"Helper Functions for Plotting\u00b6","text":"<p>To make our results easy to understand, we'll create two helper functions. These will handle the complexities of plotting our 3D environment and the robot's state within it.</p>"},{"location":"tutorials/AIPP.html#data-loading-and-hyperparameter-learning","title":"Data Loading and Hyperparameter Learning\u00b6","text":"<p>Before we can start planning paths, we need to:</p> <ol> <li>Load a dataset: We'll use the <code>Dataset</code> class to generate a synthetic elevation map. This map will serve as the \"ground truth\" environment that our robot(s) will explore.</li> <li>Learn GP hyperparameters: We'll train a Gaussian Process (GP) model on a small sample of the data to learn the kernel's hyperparameters (like lengthscales and variance). These parameters describe the spatial correlation of the data and are crucial for evaluating the reconstructions from the solution.</li> </ol>"},{"location":"tutorials/AIPP.html#setting-up-the-adaptive-ipp-mission","title":"Setting Up the Adaptive IPP Mission\u00b6","text":"<p>Now, we configure the parameters for our AIPP mission. This includes setting the number of waypoints, defining the robot's sensor model, and a distance budget.</p>"},{"location":"tutorials/AIPP.html#simulating-the-adaptive-ipp-mission","title":"Simulating the Adaptive IPP Mission\u00b6","text":"<p>This is the heart of the tutorial. We will now simulate the AIPP mission step-by-step in a loop. At each step, the robot will:</p> <ol> <li>\"Visit\" a waypoint: We'll simulate this by taking the current solution path.</li> <li>Gather data: The robot collects new sensor readings from its current location and FoV.</li> <li>Update its world model: The new data is used to update an Online Sparse GP model (<code>OSGPR</code>). This model efficiently incorporates new information without retraining from scratch, which is key for adaptive planning. The kernel hyperparameters are re-optimized.</li> <li>Re-plan its path: The <code>ContinuousSGP</code> planner is updated with the new hyperparameters from the <code>OSGPR</code>. It then re-optimizes the remaining waypoints in its path.</li> <li>Visualize: We plot the robot's current state and its new plan.</li> </ol> <p>We repeat this process until the robot has visited all waypoints.</p>"},{"location":"tutorials/AIPP.html#conclusion","title":"Conclusion\u00b6","text":"<p>In this tutorial, we've demonstrated a complete Adaptive Informative Path Planning (AIPP) loop. We've seen how a robot can start with a basic understanding of its environment, and then intelligently update both its world model and its future plans as it gathers new information.</p> <p>Here are the key takeaways:</p> <ul> <li><p>The Power of Adaptation: By re-planning at each step, the robot can react to what it has learned. You can see in the visualizations how the planned path (in green) changes based on the data gathered from the visited waypoints (in red). This allows the robot to focus its efforts on areas of high uncertainty or interest, leading to a much more efficient mission.</p> </li> <li><p>Modeling Realistic Sensors: We've gone beyond simple point sensors and modeled a more realistic altitude-dependent Field of View. The <code>sgptools</code> library makes it straightforward to define and incorporate such custom sensor models into the planning process.</p> </li> <li><p>Efficient Online Updates: The use of an Online Sparse GP (<code>OSGPR</code>) is crucial for the adaptive component. It allows the robot's world model to be updated efficiently without the need to retrain from scratch.</p> </li> </ul> <p>We encourage you to experiment with the parameters in this tutorial\u2014try different numbers of waypoints, different sensor models, or even different environments\u2014to further explore the capabilities of adaptive planning.</p>"},{"location":"tutorials/IPP.html","title":"Informative Path Planning","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Import necessary components from sgptools\nfrom sgptools.utils.data import Dataset # Class for loading and managing datasets\nfrom sgptools.utils.misc import get_inducing_pts # Utility for selecting inducing points\nfrom sgptools.utils.tsp import run_tsp # TSP/VRP solver for initial path planning\nfrom sgptools.utils.gpflow import get_model_params # For training initial GP/SGP hyperparameters\nfrom sgptools.methods import ContinuousSGP # The main class for continuous SGP optimization\nfrom sgptools.core.transformations import IPPTransform, SquareTransform # Transforms for IPP and sensor models\n\n# Set random seeds for reproducibility\nnp.random.seed(0)\ntf.random.set_seed(0)\n</pre> import os os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  # Import necessary components from sgptools from sgptools.utils.data import Dataset # Class for loading and managing datasets from sgptools.utils.misc import get_inducing_pts # Utility for selecting inducing points from sgptools.utils.tsp import run_tsp # TSP/VRP solver for initial path planning from sgptools.utils.gpflow import get_model_params # For training initial GP/SGP hyperparameters from sgptools.methods import ContinuousSGP # The main class for continuous SGP optimization from sgptools.core.transformations import IPPTransform, SquareTransform # Transforms for IPP and sensor models  # Set random seeds for reproducibility np.random.seed(0) tf.random.set_seed(0) In\u00a0[\u00a0]: Copied! <pre>def plot_paths(paths, dataset, kernel, noise_variance, title, continuous_sening=False, expanded_points=None):\n    \"\"\"\n    This function takes the optimized paths and generates a side-by-side comparison of the\n    ground truth data field and the reconstruction of that field based on the data\n    gathered along the optimized paths.\n\n    Args:\n        paths (np.ndarray): The optimized paths for the robots.\n        dataset (Dataset): The dataset object containing the ground truth data.\n        kernel (gpflow.kernels.Kernel): The GPflow kernel function used for the GP model.\n        noise_variance (float): The noise variance of the GP model.\n        title (str): The title for the plot.\n        continuous_sening (bool): Flag to indicate if the sensor data should be sampled continuously along the path.\n        expanded_points (np.ndarray): The expanded points for the sensor's FoV, if applicable.\n    \"\"\"\n\n    # Get sensor data along the optimized paths\n    sol_X, sol_y = [], []\n    for path in paths:\n        X, y = dataset.get_sensor_data(path.reshape(-1, 2), \n                                       continuous_sening=continuous_sening)\n        sol_X.extend(X)\n        sol_y.extend(y)\n    sol_X = np.array(sol_X)\n    sol_y = np.array(sol_y)\n    \n    # Create a GP model to reconstruct the data field from the gathered sensor data\n    _, _, _, model = get_model_params(\n        sol_X, sol_y, max_steps=0, return_model=True,\n        kernel=kernel, \n        noise_variance=noise_variance,\n        verbose=False\n    )\n    X_test, _ = dataset.get_test()\n    # Get the  reconstruction\n    mean, var = model.predict_f(X_test)\n    mean, var = mean.numpy(), var.numpy()\n\n    # ==============================================================================\n    # Plotting\n    # ==============================================================================\n\n    # Determine the common color scale\n    vmin = min(dataset.y.min(), mean.min())\n    vmax = max(dataset.y.max(), mean.max())\n\n    # Create a figure with two subplots\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n\n    # Plot 1: Ground Truth\n    im1 = ax1.imshow(dataset.y.T,\n                    cmap='jet', origin='lower',\n                    extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n                            np.min(X_test[:, 1]), np.max(X_test[:, 1])],\n                    vmin=vmin, vmax=vmax)\n    ax1.set_title('Ground Truth')\n    ax1.set_xlabel('X-coordinate')\n    ax1.set_ylabel('Y-coordinate')\n    ax1.set_aspect('equal', adjustable='box') # Maintain aspect ratio\n    ax1.grid(True)\n\n    # Plot 2: Reconstruction from Solution Path Data\n    im2 = ax2.imshow(mean.reshape(dataset.y.shape).T,\n                     cmap='jet', origin='lower',\n                     extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n                             np.min(X_test[:, 1]), np.max(X_test[:, 1])],\n                     vmin=vmin, vmax=vmax)\n\n    colors = ['r', 'g', 'b', 'c', 'm', 'y'] # Colors for different robot paths\n    \n    # Plot the paths\n    for i, path in enumerate(paths):\n        ax2.plot(path[:, 0], path[:, 1], 'o-', color=colors[i % len(colors)], label=f'Optimized Path {i+1}')\n\n    # Plot non point FoV if present\n    if expanded_points is not None:\n        ax2.scatter(expanded_points[:, 0], expanded_points[:, 1], s=10, c='purple', alpha=0.3, label='Expanded FoV Points')\n\n    ax2.set_title('Reconstruction from Solution Path(s) Data')\n    ax2.set_xlabel('X-coordinate')\n    ax2.set_aspect('equal', adjustable='box') # Maintain aspect ratio\n    ax2.grid(True) \n    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n    plt.suptitle(title)\n</pre> def plot_paths(paths, dataset, kernel, noise_variance, title, continuous_sening=False, expanded_points=None):     \"\"\"     This function takes the optimized paths and generates a side-by-side comparison of the     ground truth data field and the reconstruction of that field based on the data     gathered along the optimized paths.      Args:         paths (np.ndarray): The optimized paths for the robots.         dataset (Dataset): The dataset object containing the ground truth data.         kernel (gpflow.kernels.Kernel): The GPflow kernel function used for the GP model.         noise_variance (float): The noise variance of the GP model.         title (str): The title for the plot.         continuous_sening (bool): Flag to indicate if the sensor data should be sampled continuously along the path.         expanded_points (np.ndarray): The expanded points for the sensor's FoV, if applicable.     \"\"\"      # Get sensor data along the optimized paths     sol_X, sol_y = [], []     for path in paths:         X, y = dataset.get_sensor_data(path.reshape(-1, 2),                                         continuous_sening=continuous_sening)         sol_X.extend(X)         sol_y.extend(y)     sol_X = np.array(sol_X)     sol_y = np.array(sol_y)          # Create a GP model to reconstruct the data field from the gathered sensor data     _, _, _, model = get_model_params(         sol_X, sol_y, max_steps=0, return_model=True,         kernel=kernel,          noise_variance=noise_variance,         verbose=False     )     X_test, _ = dataset.get_test()     # Get the  reconstruction     mean, var = model.predict_f(X_test)     mean, var = mean.numpy(), var.numpy()      # ==============================================================================     # Plotting     # ==============================================================================      # Determine the common color scale     vmin = min(dataset.y.min(), mean.min())     vmax = max(dataset.y.max(), mean.max())      # Create a figure with two subplots     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))      # Plot 1: Ground Truth     im1 = ax1.imshow(dataset.y.T,                     cmap='jet', origin='lower',                     extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),                             np.min(X_test[:, 1]), np.max(X_test[:, 1])],                     vmin=vmin, vmax=vmax)     ax1.set_title('Ground Truth')     ax1.set_xlabel('X-coordinate')     ax1.set_ylabel('Y-coordinate')     ax1.set_aspect('equal', adjustable='box') # Maintain aspect ratio     ax1.grid(True)      # Plot 2: Reconstruction from Solution Path Data     im2 = ax2.imshow(mean.reshape(dataset.y.shape).T,                      cmap='jet', origin='lower',                      extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),                              np.min(X_test[:, 1]), np.max(X_test[:, 1])],                      vmin=vmin, vmax=vmax)      colors = ['r', 'g', 'b', 'c', 'm', 'y'] # Colors for different robot paths          # Plot the paths     for i, path in enumerate(paths):         ax2.plot(path[:, 0], path[:, 1], 'o-', color=colors[i % len(colors)], label=f'Optimized Path {i+1}')      # Plot non point FoV if present     if expanded_points is not None:         ax2.scatter(expanded_points[:, 0], expanded_points[:, 1], s=10, c='purple', alpha=0.3, label='Expanded FoV Points')      ax2.set_title('Reconstruction from Solution Path(s) Data')     ax2.set_xlabel('X-coordinate')     ax2.set_aspect('equal', adjustable='box') # Maintain aspect ratio     ax2.grid(True)      ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)     plt.suptitle(title)  In\u00a0[3]: Copied! <pre># Get the synthetic elevation data\ndataset = Dataset(shape=(100, 100), \n                  num_test=10000, \n                  random_seed=0,\n                  verbose=False)\nX_train, y_train = dataset.get_train()\nX_test, y_test = dataset.get_test()\n\n# Train a Gaussian Process (GP) model and get the optimized kernel parameters\n# `get_model_params` returns loss_values, noise_variance, kernel_object\n_, noise_variance, kernel = get_model_params(X_train, y_train, \n                                             lengthscales=[1.0, 1.0], # Initial lengthscales for the RBF kernel\n                                             optimizer='scipy.L-BFGS-B') # Use SciPy's L-BFGS-B optimizer\n\n# Plot the ground truth data\nplt.figure()\nim1 = plt.imshow(y_test.reshape(100, 100).T,\n                 cmap='jet', origin='lower',\n                 extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n                         np.min(X_test[:, 1]), np.max(X_test[:, 1])])\nax1 = plt.gca()\nax1.set_title('Ground Truth')\nax1.set_xlabel('X-coordinate')\nax1.set_ylabel('Y-coordinate')\nax1.set_aspect('equal', adjustable='box')\nax1.grid(True)\n</pre> # Get the synthetic elevation data dataset = Dataset(shape=(100, 100),                    num_test=10000,                    random_seed=0,                   verbose=False) X_train, y_train = dataset.get_train() X_test, y_test = dataset.get_test()  # Train a Gaussian Process (GP) model and get the optimized kernel parameters # `get_model_params` returns loss_values, noise_variance, kernel_object _, noise_variance, kernel = get_model_params(X_train, y_train,                                               lengthscales=[1.0, 1.0], # Initial lengthscales for the RBF kernel                                              optimizer='scipy.L-BFGS-B') # Use SciPy's L-BFGS-B optimizer  # Plot the ground truth data plt.figure() im1 = plt.imshow(y_test.reshape(100, 100).T,                  cmap='jet', origin='lower',                  extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),                          np.min(X_test[:, 1]), np.max(X_test[:, 1])]) ax1 = plt.gca() ax1.set_title('Ground Truth') ax1.set_xlabel('X-coordinate') ax1.set_ylabel('Y-coordinate') ax1.set_aspect('equal', adjustable='box') ax1.grid(True) <pre>2025-06-29 16:40:32.666089: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n</pre> <pre>\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 name                    \u2502 class     \u2502 transform        \u2502 prior   \u2502 trainable   \u2502 shape   \u2502 dtype   \u2502 value                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 GPR.kernel.variance     \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.6951937832093493   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.kernel.lengthscales \u2502 Parameter \u2502 Softplus         \u2502         \u2502 True        \u2502 (2,)    \u2502 float64 \u2502 [1.95108 2.15753]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPR.likelihood.variance \u2502 Parameter \u2502 Softplus + Shift \u2502         \u2502 True        \u2502 ()      \u2502 float64 \u2502 0.023864834955535326 \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[4]: Copied! <pre>num_robots = 1\nnum_placements = 20 # Number of sensing locations (waypoints) for the robot\n\n# Initialize the path waypoints using k-means to get a good spatial distribution,\n# then run a TSP solver to get a coherent initial path.\nXu_init = get_inducing_pts(X_train, num_placements * num_robots)\nXu_init, _ = run_tsp(Xu_init, num_vehicles=num_robots)\nXu_init = Xu_init[0] # Original shaope (num_robots, num_placements, num_dim)\n\n\n# Setup the IPP transform for point sensing\n# For point sensing, the `sampling_rate` is effectively 2 (the start and end of each path segment).\ntransform_point_sensing = IPPTransform(num_robots=num_robots)\n\n# Initialize the ContinuousSGP optimizer\ncsgp_method_point_sensing = ContinuousSGP(\n    num_placements, \n    X_train, # X_train serves as the X_objective for the SGP model\n    kernel,\n    noise_variance, \n    transform_point_sensing,\n    num_robots,\n    X_init=Xu_init\n)\n\n# Optimize the inducing points (path waypoints)\nsgp_paths_point_sensing = csgp_method_point_sensing.optimize(max_steps=1000)\n\n# Plot the solution\nplot_paths(sgp_paths_point_sensing, dataset, kernel, noise_variance,\n           title=\"Single-Robot IPP with Point Sensing\")\n</pre> num_robots = 1 num_placements = 20 # Number of sensing locations (waypoints) for the robot  # Initialize the path waypoints using k-means to get a good spatial distribution, # then run a TSP solver to get a coherent initial path. Xu_init = get_inducing_pts(X_train, num_placements * num_robots) Xu_init, _ = run_tsp(Xu_init, num_vehicles=num_robots) Xu_init = Xu_init[0] # Original shaope (num_robots, num_placements, num_dim)   # Setup the IPP transform for point sensing # For point sensing, the `sampling_rate` is effectively 2 (the start and end of each path segment). transform_point_sensing = IPPTransform(num_robots=num_robots)  # Initialize the ContinuousSGP optimizer csgp_method_point_sensing = ContinuousSGP(     num_placements,      X_train, # X_train serves as the X_objective for the SGP model     kernel,     noise_variance,      transform_point_sensing,     num_robots,     X_init=Xu_init )  # Optimize the inducing points (path waypoints) sgp_paths_point_sensing = csgp_method_point_sensing.optimize(max_steps=1000)  # Plot the solution plot_paths(sgp_paths_point_sensing, dataset, kernel, noise_variance,            title=\"Single-Robot IPP with Point Sensing\") In\u00a0[5]: Copied! <pre>num_robots = 1\nnum_placements = 15\n\n# Initialize inducing points and get initial path as before\nXu_init_continuous = get_inducing_pts(X_train, num_placements * num_robots)\nXu_init_continuous, _ = run_tsp(Xu_init_continuous, num_vehicles=num_robots)\nXu_init_continuous = Xu_init_continuous[0]\n\n# Setup IPP transform with a higher sampling rate for continuous sensing\ntransform_continuous_sensing = IPPTransform(num_robots=num_robots,\n                                            sampling_rate=5)\n\n# Initialize and optimize the ContinuousSGP model\ncsgp_method_continuous_sensing = ContinuousSGP(\n    num_placements, \n    X_train, \n    kernel,\n    noise_variance, \n    transform_continuous_sensing,\n    num_robots,\n    X_init=Xu_init_continuous\n)\nsgp_paths_continuous_sensing = csgp_method_continuous_sensing.optimize(max_steps=1000)\n\n# Plot the solution\nplot_paths(sgp_paths_continuous_sensing, dataset, kernel, noise_variance,\n           title=\"Single-Robot IPP with Continuous Sensing\",\n           continuous_sening=True)\n</pre> num_robots = 1 num_placements = 15  # Initialize inducing points and get initial path as before Xu_init_continuous = get_inducing_pts(X_train, num_placements * num_robots) Xu_init_continuous, _ = run_tsp(Xu_init_continuous, num_vehicles=num_robots) Xu_init_continuous = Xu_init_continuous[0]  # Setup IPP transform with a higher sampling rate for continuous sensing transform_continuous_sensing = IPPTransform(num_robots=num_robots,                                             sampling_rate=5)  # Initialize and optimize the ContinuousSGP model csgp_method_continuous_sensing = ContinuousSGP(     num_placements,      X_train,      kernel,     noise_variance,      transform_continuous_sensing,     num_robots,     X_init=Xu_init_continuous ) sgp_paths_continuous_sensing = csgp_method_continuous_sensing.optimize(max_steps=1000)  # Plot the solution plot_paths(sgp_paths_continuous_sensing, dataset, kernel, noise_variance,            title=\"Single-Robot IPP with Continuous Sensing\",            continuous_sening=True) In\u00a0[6]: Copied! <pre>num_robots = 1\nnum_placements = 15 # Number of sensing locations (waypoints) for the robot\n\n# Initialize inducing points, including an initial random angle for each FoV\nXu_init_fov = get_inducing_pts(X_train, num_placements * num_robots)\nXu_init_fov, _ = run_tsp(Xu_init_fov, num_vehicles=num_robots)\nXu_init_fov = Xu_init_fov[0] # Path for the single robot\n\n# Add random angles (orientation of FoV) to inducing points (waypoints)\n# For a 2D position (x, y), we add a 3rd dimension for angle.\nangles = np.random.uniform(-np.pi, np.pi, num_placements).reshape(-1, 1)\nXu_init_fov_with_angles = np.concatenate([Xu_init_fov, angles], axis=1)\n\n# Setup a SquareTransform to model a square FoV\n# `length` is the side length of the square\n# `num_side` is points along each side (3x3 grid for FoV approx)\nsquare_transform = SquareTransform(side_length=5, pts_per_side=4)\n\n# Setup IPP transform with the custom sensor model\n# num_dim=3 because the inducing points now have (x, y, angle) dimensions\ntransform_fov_sensing = IPPTransform(num_robots=num_robots,\n                                     num_dim=3, # Input to transform has 3 dimensions (x, y, angle)\n                                     sensor_model=square_transform, # The custom FoV model\n                                     aggregate_fov=True) # aggregate fov for faster performance\n\n# Initialize and optimize the ContinuousSGP model\n# Explicitly mention number of dimensions (x, y, angle) since it is different from X_train dim\ncsgp_method_fov_sensing = ContinuousSGP(\n    num_placements, \n    X_train, \n    kernel,\n    noise_variance,\n    transform_fov_sensing,\n    num_robots,\n    X_init=Xu_init_fov_with_angles,\n    num_dim=3\n)\nsgp_sol_sp_fov_sensing = csgp_method_fov_sensing.optimize(max_steps=1000)\n\n# Extract just the (x,y) coordinates of the path for plotting\nsgp_paths_fov_sensing = sgp_sol_sp_fov_sensing[:, :, :2].reshape(num_robots, -1 , 2)\n\n# Get the expanded FoV points for visualization\nexpanded_fov_points = csgp_method_fov_sensing.transform.expand(sgp_sol_sp_fov_sensing).numpy()\n\n# Plot the solution path and the FoVs\nplot_paths(sgp_paths_fov_sensing, dataset, kernel, noise_variance,\n           title=\"Single-Robot IPP with Non-point FoV Sensor\", \n           expanded_points=expanded_fov_points)\n</pre> num_robots = 1 num_placements = 15 # Number of sensing locations (waypoints) for the robot  # Initialize inducing points, including an initial random angle for each FoV Xu_init_fov = get_inducing_pts(X_train, num_placements * num_robots) Xu_init_fov, _ = run_tsp(Xu_init_fov, num_vehicles=num_robots) Xu_init_fov = Xu_init_fov[0] # Path for the single robot  # Add random angles (orientation of FoV) to inducing points (waypoints) # For a 2D position (x, y), we add a 3rd dimension for angle. angles = np.random.uniform(-np.pi, np.pi, num_placements).reshape(-1, 1) Xu_init_fov_with_angles = np.concatenate([Xu_init_fov, angles], axis=1)  # Setup a SquareTransform to model a square FoV # `length` is the side length of the square # `num_side` is points along each side (3x3 grid for FoV approx) square_transform = SquareTransform(side_length=5, pts_per_side=4)  # Setup IPP transform with the custom sensor model # num_dim=3 because the inducing points now have (x, y, angle) dimensions transform_fov_sensing = IPPTransform(num_robots=num_robots,                                      num_dim=3, # Input to transform has 3 dimensions (x, y, angle)                                      sensor_model=square_transform, # The custom FoV model                                      aggregate_fov=True) # aggregate fov for faster performance  # Initialize and optimize the ContinuousSGP model # Explicitly mention number of dimensions (x, y, angle) since it is different from X_train dim csgp_method_fov_sensing = ContinuousSGP(     num_placements,      X_train,      kernel,     noise_variance,     transform_fov_sensing,     num_robots,     X_init=Xu_init_fov_with_angles,     num_dim=3 ) sgp_sol_sp_fov_sensing = csgp_method_fov_sensing.optimize(max_steps=1000)  # Extract just the (x,y) coordinates of the path for plotting sgp_paths_fov_sensing = sgp_sol_sp_fov_sensing[:, :, :2].reshape(num_robots, -1 , 2)  # Get the expanded FoV points for visualization expanded_fov_points = csgp_method_fov_sensing.transform.expand(sgp_sol_sp_fov_sensing).numpy()  # Plot the solution path and the FoVs plot_paths(sgp_paths_fov_sensing, dataset, kernel, noise_variance,            title=\"Single-Robot IPP with Non-point FoV Sensor\",             expanded_points=expanded_fov_points) In\u00a0[\u00a0]: Copied! <pre>num_robots = 3\nnum_placements = 15 # Number of sensing locations (waypoints) for each robot\n\n# Initialize inducing points for multiple robots\nXu_init_multi_robot = get_inducing_pts(X_train, num_placements * num_robots)\n\n# Run TSP for multiple vehicles, with a max_dist constraint and resampling\nXu_init_multi_robot, _ = run_tsp(Xu_init_multi_robot, \n                                 num_vehicles=num_robots,\n                                 max_dist=100, # Initial max distance budget for TSP\n                                 resample=num_placements) # Ensure each path has num_placements waypoints\nXu_init_multi_robot = Xu_init_multi_robot.reshape(-1, 2) # Flatten paths into a single array of waypoints\n\n# Setup distance-constrained IPP transform for multiple robots\ntransform_multi_robot = IPPTransform(num_robots=num_robots,\n                                     sampling_rate=5, # Continuous sensing\n                                     distance_budget=30., # Distance budget for each robot\n                                     constraint_weight=500.) # Weight for the distance constraint in optimization\n\n# Initialize and optimize the ContinuousSGP model for multi-robot scenario\ncsgp_method_multi_robot = ContinuousSGP(\n    num_placements, \n    X_train, \n    kernel,\n    noise_variance, \n    transform_multi_robot,\n    num_robots,\n    X_init=Xu_init_multi_robot\n)\nsol_paths_multi_robot = csgp_method_multi_robot.optimize(max_steps=5000)\n\n# Plot the optimized paths\nplot_paths(sol_paths_multi_robot, dataset, kernel, noise_variance,\n           title=\"Multi-Robot IPP with Continuous Sensing (Distance Budget)\",\n           continuous_sening=True)\n\n# Print the final distances for each optimized path\n# The transform.distance method calculates the total path length based on the current inducing points\nprint(\"Distances (Normalized Units):\", transform_multi_robot.distance(tf.constant(sol_paths_multi_robot, dtype=tf.float64)).numpy())\n</pre> num_robots = 3 num_placements = 15 # Number of sensing locations (waypoints) for each robot  # Initialize inducing points for multiple robots Xu_init_multi_robot = get_inducing_pts(X_train, num_placements * num_robots)  # Run TSP for multiple vehicles, with a max_dist constraint and resampling Xu_init_multi_robot, _ = run_tsp(Xu_init_multi_robot,                                   num_vehicles=num_robots,                                  max_dist=100, # Initial max distance budget for TSP                                  resample=num_placements) # Ensure each path has num_placements waypoints Xu_init_multi_robot = Xu_init_multi_robot.reshape(-1, 2) # Flatten paths into a single array of waypoints  # Setup distance-constrained IPP transform for multiple robots transform_multi_robot = IPPTransform(num_robots=num_robots,                                      sampling_rate=5, # Continuous sensing                                      distance_budget=30., # Distance budget for each robot                                      constraint_weight=500.) # Weight for the distance constraint in optimization  # Initialize and optimize the ContinuousSGP model for multi-robot scenario csgp_method_multi_robot = ContinuousSGP(     num_placements,      X_train,      kernel,     noise_variance,      transform_multi_robot,     num_robots,     X_init=Xu_init_multi_robot ) sol_paths_multi_robot = csgp_method_multi_robot.optimize(max_steps=5000)  # Plot the optimized paths plot_paths(sol_paths_multi_robot, dataset, kernel, noise_variance,            title=\"Multi-Robot IPP with Continuous Sensing (Distance Budget)\",            continuous_sening=True)  # Print the final distances for each optimized path # The transform.distance method calculates the total path length based on the current inducing points print(\"Distances (Normalized Units):\", transform_multi_robot.distance(tf.constant(sol_paths_multi_robot, dtype=tf.float64)).numpy()) <pre>Distances (Normalized Units): [30.00042943 29.99999999 30.00000204]\n</pre>"},{"location":"tutorials/IPP.html#informative-path-planning","title":"Informative Path Planning\u00b6","text":"<p>This tutorial will walk you through various Informative Path Planning (IPP) scenarios using the <code>sgptools</code> library. We'll start with the basic setup and then explore single-robot and multi-robot IPP with different sensor configurations.</p>"},{"location":"tutorials/IPP.html#setup-and-imports","title":"Setup and Imports\u00b6","text":"<p>We begin by importing the necessary libraries and modules.</p> <ul> <li><code>os</code>: Used to set environment variables to avoid potential conflicts with underlying libraries.</li> <li><code>numpy</code>: For numerical operations.</li> <li><code>tensorflow</code>: The backend for GPflow.</li> <li><code>matplotlib.pyplot</code>: For plotting the results.</li> <li><code>sgptools</code> modules: We import specific classes and functions from the library that we'll be using.</li> </ul>"},{"location":"tutorials/IPP.html#helper-function-for-plotting","title":"Helper Function for Plotting\u00b6","text":"<p>To keep our main code clean, we define a helper function <code>plot_paths</code> to visualize the results of our IPP experiments.</p>"},{"location":"tutorials/IPP.html#data-loading-and-hyperparameter-learning","title":"Data Loading and Hyperparameter Learning\u00b6","text":"<p>Before we can start planning paths, we need to:</p> <ol> <li>Load a dataset: We'll use the <code>Dataset</code> class to generate a synthetic elevation map. This map will serve as the \"ground truth\" environment that our robot(s) will explore.</li> <li>Learn GP hyperparameters: We'll train a Gaussian Process (GP) model on a small sample of the data to learn the kernel's hyperparameters (like lengthscales and variance). These parameters describe the spatial correlation of the data and are crucial for the SGP-based IPP model.</li> </ol>"},{"location":"tutorials/IPP.html#ipp-scenarios","title":"IPP Scenarios\u00b6","text":"<p>Now we'll explore different IPP scenarios, from simple to more complex.</p>"},{"location":"tutorials/IPP.html#single-robot-ipp-with-point-sensing","title":"Single-Robot IPP with Point Sensing\u00b6","text":"<p>This is the most basic scenario. We have a single robot that takes measurements at discrete points (waypoints) along its path.</p>"},{"location":"tutorials/IPP.html#single-robot-ipp-with-continuous-sensing","title":"Single-Robot IPP with Continuous Sensing\u00b6","text":"<p>Here, we model the robot as sensing continuously along its path, not just at the waypoints. We achieve this by setting a <code>sampling_rate &gt; 2</code> in the <code>IPPTransform</code>, which interpolates points between the waypoints.</p>"},{"location":"tutorials/IPP.html#single-robot-ipp-with-a-non-point-fov-sensor","title":"Single-Robot IPP with a Non-Point FoV Sensor\u00b6","text":"<p>In this more complex scenario, we model a sensor with a square Field of View (FoV). The <code>SquareTransform</code> expands each waypoint (which now includes position and orientation) into a grid of points representing the FoV.</p>"},{"location":"tutorials/IPP.html#multi-robot-ipp-with-a-distance-budget","title":"Multi-Robot IPP with a Distance Budget\u00b6","text":"<p>This is a more complex scenario involving multiple robots, each with a limited path length (distance budget). The <code>IPPTransform</code> is configured to handle these constraints, and the optimization will try to find the best set of paths that respect the budget.</p>"},{"location":"tutorials/non_stationary_kernels.html","title":"Non-Stationary Kernels","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\nos.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n\nfrom sklearn.preprocessing import StandardScaler\nfrom gpflow.utilities.traversal import deepcopy\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport gpflow\ngpflow.config.set_default_float(np.float32)\n\nfrom sgptools.methods import ContinuousSGP\nfrom sgptools.utils.misc import get_inducing_pts, cont2disc\nfrom sgptools.kernels import get_kernel\nfrom sgptools.utils.gpflow import get_model_params, optimize_model\n\n# Set random seeds for reproducibility\nnp.random.seed(1234)\ntf.random.set_seed(1234)\n</pre> import os os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\" os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"  from sklearn.preprocessing import StandardScaler from gpflow.utilities.traversal import deepcopy import matplotlib.pyplot as plt import tensorflow as tf import numpy as np import gpflow gpflow.config.set_default_float(np.float32)  from sgptools.methods import ContinuousSGP from sgptools.utils.misc import get_inducing_pts, cont2disc from sgptools.kernels import get_kernel from sgptools.utils.gpflow import get_model_params, optimize_model  # Set random seeds for reproducibility np.random.seed(1234) tf.random.set_seed(1234) In\u00a0[2]: Copied! <pre>def non_stationary_function(X, Y):\n    Z1 = np.sin(X/10) + np.cos(Y/10)\n    Z2 = np.cos(X/6) + np.cos(Y/6)\n    Z = np.concatenate([Z1[:, ::2], Z2[:, ::2]], \n                       axis=1)\n    return Z\n\n# Generate the training and testing data grids\ntrain_data_dims = (40, 20)\nx = np.linspace(0, 200, train_data_dims[0])\ny = np.linspace(0, 100, train_data_dims[1])\nX, Y = np.meshgrid(x, y)\nZ = non_stationary_function(X, Y)\n\n# Flatten the grid data into a list of (x, y) coordinates and corresponding values\nX_train = np.stack([X.ravel(), Y.ravel()], \n                   axis=1).astype(np.float32)\nY_train = Z.ravel()[:, None].astype(np.float32)\nprint('Train Data:', X_train.shape, Y_train.shape)\n\n# Generate a higher-resolution grid for testing our model's predictions\ntest_data_dims = (100, 50)\nx = np.linspace(0, 200, test_data_dims[0])\ny = np.linspace(0, 100, test_data_dims[1])\nX, Y = np.meshgrid(x, y)\nZ = non_stationary_function(X, Y)\n\nX_test = np.stack([X.ravel(), Y.ravel()], \n                  axis=1).astype(np.float32)\nY_test = Z.ravel()[:, None].astype(np.float32)\nprint('Test Data:', X_test.shape, Y_test.shape)\n\n# Normalize the data: This is a standard practice in machine learning that helps\n# optimization algorithms converge faster and more reliably.\nXscalar = StandardScaler()\nX_train = Xscalar.fit_transform(X_train)\nX_test = Xscalar.transform(X_test)\n\nyScalar = StandardScaler()\nY_train = yScalar.fit_transform(Y_train)\nY_test = yScalar.transform(Y_test)\n\n# Plot the training and testing data to visualize the non-stationary patterns\nplt.figure()\nplt.imshow(Y_test.reshape(test_data_dims[1], \n                          test_data_dims[0]), \n           cmap='jet')\nplt.gca().set_aspect('equal')\nplt.title('Test Data')\nplt.show()\n</pre> def non_stationary_function(X, Y):     Z1 = np.sin(X/10) + np.cos(Y/10)     Z2 = np.cos(X/6) + np.cos(Y/6)     Z = np.concatenate([Z1[:, ::2], Z2[:, ::2]],                         axis=1)     return Z  # Generate the training and testing data grids train_data_dims = (40, 20) x = np.linspace(0, 200, train_data_dims[0]) y = np.linspace(0, 100, train_data_dims[1]) X, Y = np.meshgrid(x, y) Z = non_stationary_function(X, Y)  # Flatten the grid data into a list of (x, y) coordinates and corresponding values X_train = np.stack([X.ravel(), Y.ravel()],                     axis=1).astype(np.float32) Y_train = Z.ravel()[:, None].astype(np.float32) print('Train Data:', X_train.shape, Y_train.shape)  # Generate a higher-resolution grid for testing our model's predictions test_data_dims = (100, 50) x = np.linspace(0, 200, test_data_dims[0]) y = np.linspace(0, 100, test_data_dims[1]) X, Y = np.meshgrid(x, y) Z = non_stationary_function(X, Y)  X_test = np.stack([X.ravel(), Y.ravel()],                    axis=1).astype(np.float32) Y_test = Z.ravel()[:, None].astype(np.float32) print('Test Data:', X_test.shape, Y_test.shape)  # Normalize the data: This is a standard practice in machine learning that helps # optimization algorithms converge faster and more reliably. Xscalar = StandardScaler() X_train = Xscalar.fit_transform(X_train) X_test = Xscalar.transform(X_test)  yScalar = StandardScaler() Y_train = yScalar.fit_transform(Y_train) Y_test = yScalar.transform(Y_test)  # Plot the training and testing data to visualize the non-stationary patterns plt.figure() plt.imshow(Y_test.reshape(test_data_dims[1],                            test_data_dims[0]),             cmap='jet') plt.gca().set_aspect('equal') plt.title('Test Data') plt.show() <pre>Train Data: (800, 2) (800, 1)\nTest Data: (5000, 2) (5000, 1)\n</pre> In\u00a0[3]: Copied! <pre>kernels = []\nnoice_vars = []\nlabels = []\n</pre> kernels = [] noice_vars = [] labels = [] In\u00a0[\u00a0]: Copied! <pre>_, noise_variance, kernel = get_model_params(\n    X_train=X_train, y_train=Y_train, \n    kernel=get_kernel('RBF')(),\n    optimizer='scipy.L-BFGS-B',\n)\n\nkernels.append(kernel)\nnoice_vars.append(noise_variance)\nlabels.append('RBF')\n</pre> _, noise_variance, kernel = get_model_params(     X_train=X_train, y_train=Y_train,      kernel=get_kernel('RBF')(),     optimizer='scipy.L-BFGS-B', )  kernels.append(kernel) noice_vars.append(noise_variance) labels.append('RBF') In\u00a0[\u00a0]: Copied! <pre>_, noise_variance, kernel = get_model_params(\n    X_train=X_train, y_train=Y_train, \n    kernel=get_kernel('Attentive')(),\n    optimizer='tf.Nadam',\n    learning_rate=1e-2,\n    max_steps=3000)\n\nkernels.append(kernel)\nnoice_vars.append(noise_variance)\nlabels.append('Attentive')\n</pre> _, noise_variance, kernel = get_model_params(     X_train=X_train, y_train=Y_train,      kernel=get_kernel('Attentive')(),     optimizer='tf.Nadam',     learning_rate=1e-2,     max_steps=3000)  kernels.append(kernel) noice_vars.append(noise_variance) labels.append('Attentive') In\u00a0[\u00a0]: Copied! <pre>_, noise_variance, kernel = get_model_params(\n    X_train=X_train, y_train=Y_train, \n    kernel=get_kernel('NeuralSpectral')(Q=5, \n                                        hidden_sizes=[4, 4]),\n    optimizer='tf.Nadam',\n    learning_rate=1e-2,\n    max_steps=3000)\n\nkernels.append(kernel)\nnoice_vars.append(noise_variance)\nlabels.append('Neural Spectral')\n</pre> _, noise_variance, kernel = get_model_params(     X_train=X_train, y_train=Y_train,      kernel=get_kernel('NeuralSpectral')(Q=5,                                          hidden_sizes=[4, 4]),     optimizer='tf.Nadam',     learning_rate=1e-2,     max_steps=3000)  kernels.append(kernel) noice_vars.append(noise_variance) labels.append('Neural Spectral') In\u00a0[7]: Copied! <pre>num_placements_list = [4, 9, 16, 64] # Number of sensor placements to evaluate\n\n# Setup the matplotlib figure for plotting results\nfig, axs = plt.subplots(len(kernels), len(num_placements_list), figsize=(10, 7))\n# Iterate through each trained kernel and its corresponding noise variance\nfor i, (kernel, noice_var) in enumerate(zip(kernels, noice_vars)):\n    for j, num_placements in enumerate(num_placements_list):\n        # Get initial inducing points for the ContinuousSGP optimization\n        # These will be the initial sensor locations.\n        Xu_init = get_inducing_pts(X_train, num_placements)\n        Xu_init = Xu_init.astype(np.float32) # Ensure data type consistency\n\n        # Setup ContinuousSGP model\n        # ContinuousSGP takes X_objective as the data for the SGPR model,\n        # and Xu_init is passed as the initial inducing_variable.\n        csgp_method = ContinuousSGP(\n            num_sensing=num_placements, \n            X_objective=X_train, # Use X_train as the objective points for SGP\n            kernel=kernel, # Pass the trained kernel\n            noise_variance=noice_var, # Pass the trained noise variance\n            X_init=Xu_init # Initial inducing points\n        )\n\n        # Optimize the ContinuousSGP model to find solution sensor placements\n        # The optimize method returns the optimized inducing points (sensor locations).\n        # It reshapes the solution to (num_robots, num_sensing, num_dim) but here num_robots=1\n        # so we flatten it back to (num_sensing, num_dim).\n        sgp_sol_reshaped = csgp_method.optimize(max_steps=500, verbose=0) # Run optimization\n        sgp_sol_sp = sgp_sol_reshaped.reshape(-1, X_train.shape[1])\n\n\n        # To evaluate the performance of the sensor placements,\n        # we will simulate taking measurements at the optimized locations\n        sol_X, sol_y = cont2disc(sgp_sol_sp, \n                                 candidates=X_test,\n                                 candidate_labels=Y_test)\n        \n        # Create a GP model to reconstruct the data field from the gathered sensor data\n        _, _, _, model = get_model_params(\n            sol_X, sol_y, max_steps=0, return_model=True,\n            kernel=kernel, \n            noise_variance=noice_var,\n            verbose=False\n        )\n        y_pred, y_var = model.predict_f(X_test)\n        y_pred = y_pred.numpy()\n\n        # Calculate the Root Mean Square Error (RMSE) to quantify the reconstruction accuracy\n        rmse = np.sqrt(np.mean((y_pred - Y_test)**2))\n\n        # Plot the results\n        axs[i, j].imshow(y_pred.reshape(test_data_dims[1], test_data_dims[0]),\n                         cmap='jet', origin='lower',\n                         extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n                                 np.min(X_test[:, 1]), np.max(X_test[:, 1])])\n        axs[i, j].set_aspect('equal')\n        axs[i, j].scatter(sgp_sol_sp[:, 0], sgp_sol_sp[:, 1], c='k', marker='p', s=5)\n        axs[i, j].set_title(f'RMSE: {rmse:.3f}', fontsize='medium')\n        axs[i, j].set_xticks([])\n        axs[i, j].set_yticks([])\n        axs[i, j].set_xlim([np.min(X_test[:, 0]), np.max(X_test[:, 0])])\n        axs[i, j].set_ylim([np.min(X_test[:, 1]), np.max(X_test[:, 1])])\n\n        if j==0:\n                axs[i, j].set_ylabel(f'{labels[i]}', fontsize='large')\n\n        if i==len(kernels)-1:\n            \n                axs[i, j].set_xlabel(f'{num_placements} Sensors', fontsize='large')\n</pre> num_placements_list = [4, 9, 16, 64] # Number of sensor placements to evaluate  # Setup the matplotlib figure for plotting results fig, axs = plt.subplots(len(kernels), len(num_placements_list), figsize=(10, 7)) # Iterate through each trained kernel and its corresponding noise variance for i, (kernel, noice_var) in enumerate(zip(kernels, noice_vars)):     for j, num_placements in enumerate(num_placements_list):         # Get initial inducing points for the ContinuousSGP optimization         # These will be the initial sensor locations.         Xu_init = get_inducing_pts(X_train, num_placements)         Xu_init = Xu_init.astype(np.float32) # Ensure data type consistency          # Setup ContinuousSGP model         # ContinuousSGP takes X_objective as the data for the SGPR model,         # and Xu_init is passed as the initial inducing_variable.         csgp_method = ContinuousSGP(             num_sensing=num_placements,              X_objective=X_train, # Use X_train as the objective points for SGP             kernel=kernel, # Pass the trained kernel             noise_variance=noice_var, # Pass the trained noise variance             X_init=Xu_init # Initial inducing points         )          # Optimize the ContinuousSGP model to find solution sensor placements         # The optimize method returns the optimized inducing points (sensor locations).         # It reshapes the solution to (num_robots, num_sensing, num_dim) but here num_robots=1         # so we flatten it back to (num_sensing, num_dim).         sgp_sol_reshaped = csgp_method.optimize(max_steps=500, verbose=0) # Run optimization         sgp_sol_sp = sgp_sol_reshaped.reshape(-1, X_train.shape[1])           # To evaluate the performance of the sensor placements,         # we will simulate taking measurements at the optimized locations         sol_X, sol_y = cont2disc(sgp_sol_sp,                                   candidates=X_test,                                  candidate_labels=Y_test)                  # Create a GP model to reconstruct the data field from the gathered sensor data         _, _, _, model = get_model_params(             sol_X, sol_y, max_steps=0, return_model=True,             kernel=kernel,              noise_variance=noice_var,             verbose=False         )         y_pred, y_var = model.predict_f(X_test)         y_pred = y_pred.numpy()          # Calculate the Root Mean Square Error (RMSE) to quantify the reconstruction accuracy         rmse = np.sqrt(np.mean((y_pred - Y_test)**2))          # Plot the results         axs[i, j].imshow(y_pred.reshape(test_data_dims[1], test_data_dims[0]),                          cmap='jet', origin='lower',                          extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),                                  np.min(X_test[:, 1]), np.max(X_test[:, 1])])         axs[i, j].set_aspect('equal')         axs[i, j].scatter(sgp_sol_sp[:, 0], sgp_sol_sp[:, 1], c='k', marker='p', s=5)         axs[i, j].set_title(f'RMSE: {rmse:.3f}', fontsize='medium')         axs[i, j].set_xticks([])         axs[i, j].set_yticks([])         axs[i, j].set_xlim([np.min(X_test[:, 0]), np.max(X_test[:, 0])])         axs[i, j].set_ylim([np.min(X_test[:, 1]), np.max(X_test[:, 1])])          if j==0:                 axs[i, j].set_ylabel(f'{labels[i]}', fontsize='large')          if i==len(kernels)-1:                              axs[i, j].set_xlabel(f'{num_placements} Sensors', fontsize='large')"},{"location":"tutorials/non_stationary_kernels.html#non-stationary-kernels","title":"Non-Stationary Kernels\u00b6","text":"<p>This tutorial will walk you through using non-stationary kernels within the <code>sgptools</code> library. Standard kernels, like the Radial Basis Function (RBF), are \"stationary,\" meaning they assume the data's characteristics (like smoothness and variance) are the same everywhere. This is often not true for real-world environmental data, which can have different patterns in different areas.</p> <p>Non-stationary kernels are more flexible because they can adapt to these local changes. This often leads to more accurate models and better decision-making in tasks like Sensor Placement and Informative Path Planning.</p> <p>In this tutorial, we will:</p> <ol> <li>Generate synthetic non-stationary data to simulate a complex environment.</li> <li>Train and compare three different kernels:<ul> <li>RBF: A standard stationary kernel, which will serve as our baseline for comparison.</li> <li>Attentive: Another non-stationary kernel that uses an attention mechanism to focus on relevant data features.</li> <li>Neural Spectral: A powerful non-stationary kernel that uses a neural network to learn the spatial properties of the data.</li> </ul> </li> <li>Use these kernels for a sensor placement task using the <code>ContinuousSGP</code> method.</li> <li>Visualize and evaluate how well each kernel performs.</li> </ol> <p>Let's get started!</p>"},{"location":"tutorials/non_stationary_kernels.html#setup-and-imports","title":"Setup and Imports\u00b6","text":"<p>We begin by importing the necessary libraries and modules.</p> <ul> <li><code>os</code>: Used to set environment variables to avoid potential conflicts with underlying libraries.</li> <li><code>numpy</code>: For numerical operations.</li> <li><code>tensorflow</code>: The backend for GPflow.</li> <li><code>matplotlib.pyplot</code>: For plotting the results.</li> <li><code>sgptools</code> modules: We import specific classes and functions from the library that we'll be using.</li> </ul>"},{"location":"tutorials/non_stationary_kernels.html#generate-synthetic-non-stationary-data","title":"Generate Synthetic Non-Stationary Data\u00b6","text":"<p>To properly test our non-stationary kernels, we need data that exhibits non-stationary behavior. We'll create a synthetic dataset where the spatial patterns change across the map. Our function <code>non_stationary_function</code> combines two different sinusoidal patterns, creating distinct regions with different characteristics.</p>"},{"location":"tutorials/non_stationary_kernels.html#learning-kernel-parameters","title":"Learning Kernel Parameters\u00b6","text":"<p>Now, we'll train each of our three kernels on the training data. The goal is for each kernel to learn the underlying spatial structure of the environment. We expect the non-stationary kernels to perform better at this task, given the nature of our data.</p> <p>We'll store the trained kernels and their corresponding noise variances in lists</p>"},{"location":"tutorials/non_stationary_kernels.html#stationary-rbf-kernel-our-baseline","title":"Stationary RBF Kernel (Our Baseline)\u00b6","text":"<p>The RBF kernel is a standard choice for GP models. It's a stationary kernel, meaning it assumes the data's properties are the same everywhere. It will serve as a good baseline to see how much of an advantage the non-stationary kernels provide.</p>"},{"location":"tutorials/non_stationary_kernels.html#non-stationary-attentive-kernel","title":"Non-Stationary Attentive Kernel\u00b6","text":"<p>The Attentive Kernel uses a neural network to learn \"attention weights\" for a mixture of standard RBF kernels. This allows it to decide which RBF kernel (with its specific lengthscale) is most important for modeling the data at a particular location.</p>"},{"location":"tutorials/non_stationary_kernels.html#non-stationary-neural-spectral-kernel","title":"Non-Stationary Neural Spectral Kernel\u00b6","text":"<p>The Neural Kernel is a highly expressive model that uses a small neural network to learn the parameters of a spectral mixture kernel at every point. This allows it to adapt to very complex spatial patterns.</p>"},{"location":"tutorials/non_stationary_kernels.html#analysis-of-results","title":"Analysis of Results\u00b6","text":"<p>The plots above show the reconstructed environment for each kernel and for different numbers of sensors. The title of each plot shows the RMSE, which measures the error between the reconstructed map and the ground truth. A lower RMSE is better.</p> <p>Here are some key takeaways:</p> <ul> <li>RBF Kernel: As expected, the stationary RBF kernel struggles to model the non-stationary data. Its reconstructions appear blurry and fail to capture the distinct patterns in the two halves of the environment. This demonstrates the importance of choosing the right kernel for the data at hand.</li> <li>Attentive Kernel: The Attentive Kernel performs well and is a significant improvement over the stationary RBF kernel. It offers a good balance between performance and computational cost. It excels when given a sufficient number of sensing locations to learn the attention weights effectively.</li> <li>Neural Spectral Kernel: This kernel generally performs the best, achieving the lowest RMSE, especially with more sensors. Its high flexibility allows it to capture the complex non-stationary patterns in the data very accurately. However, this power comes at the cost of higher computational requirements during training.</li> </ul> <p>Conclusion: When dealing with complex, real-world environments, non-stationary kernels like the Neural and Attentive Kernels can provide a substantial advantage in modeling accuracy, leading to better-informed decisions in tasks like IPP.</p>"}]}