{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Stationary Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gpflow\n",
    "gpflow.config.set_default_float(np.float32)\n",
    "from gpflow.utilities.traversal import deepcopy\n",
    "\n",
    "# Import all necessary modules from sgptools\n",
    "from sgptools.utils.metrics import get_rmse # Assuming get_rmse is needed, if not, can be removed\n",
    "from sgptools.utils.misc import get_inducing_pts, cont2disc # Explicitly import functions\n",
    "from sgptools.methods import ContinuousSGP # Import the ContinuousSGP class\n",
    "from sgptools.kernels.attentive_kernel import AttentiveKernel\n",
    "from sgptools.kernels.neural_kernel import init_neural_kernel # Assuming init_neural_kernel is part of this module\n",
    "from sgptools.utils.gpflow import get_model_params, optimize_model # Explicitly import functions\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "# Optional: Set TensorFlow to run on CPU only for consistent results if GPU is not always available\n",
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\" # Disable oneDNN custom operations\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\" # For matplotlib rendering\n",
    "tf.config.set_visible_devices([], 'GPU') # Hide GPU to force CPU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic non-stationary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_stationary_function(X, Y):\n",
    "    Z1 = np.sin(X/10) + np.cos(Y/10)\n",
    "    Z2 = np.cos(X/6) + np.cos(Y/6)\n",
    "    Z = np.concatenate([Z1[:, ::2], Z2[:, ::2]], \n",
    "                       axis=1)\n",
    "    return Z\n",
    "\n",
    "# Generate data\n",
    "train_data_dims = (40, 20)\n",
    "x = np.linspace(0, 200, train_data_dims[0])\n",
    "y = np.linspace(0, 100, train_data_dims[1])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = non_stationary_function(X, Y)\n",
    "\n",
    "X_train = np.stack([X.ravel(), Y.ravel()], \n",
    "                   axis=1).astype(np.float32)\n",
    "Y_train = Z.ravel()[:, None].astype(np.float32)\n",
    "print('Train Data:', X_train.shape, Y_train.shape)\n",
    "\n",
    "test_data_dims = (100, 50)\n",
    "x = np.linspace(0, 200, test_data_dims[0])\n",
    "y = np.linspace(0, 100, test_data_dims[1])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = non_stationary_function(X, Y)\n",
    "\n",
    "X_test = np.stack([X.ravel(), Y.ravel()], \n",
    "                  axis=1).astype(np.float32)\n",
    "Y_test = Z.ravel()[:, None].astype(np.float32)\n",
    "print('Test Data:', X_test.shape, Y_test.shape)\n",
    "\n",
    "# Normalize the data\n",
    "Xscalar = StandardScaler()\n",
    "X_train = Xscalar.fit_transform(X_train)\n",
    "X_test = Xscalar.transform(X_test)\n",
    "\n",
    "yScalar = StandardScaler()\n",
    "Y_train = yScalar.fit_transform(Y_train)\n",
    "Y_test = yScalar.transform(Y_test)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.imshow(Y_train.reshape(train_data_dims[1], \n",
    "                           train_data_dims[0]), \n",
    "           cmap='jet')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Train Data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Y_test.reshape(test_data_dims[1], \n",
    "                          test_data_dims[0]), \n",
    "           cmap='jet')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn kernel parameters from train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = []\n",
    "noice_vars = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Stationary Neural Kernel\n",
    "model = init_neural_kernel(X_train, Y_train, \n",
    "                           n_inits=5,\n",
    "                           inducing_variable=get_inducing_pts(X_train, 800, random=True),\n",
    "                           Q=5, \n",
    "                           hidden_sizes=[4, 4])\n",
    "model_ak = deepcopy(model)\n",
    "optimize_model(model,\n",
    "               optimizer='tf.adam')\n",
    "\n",
    "kernels.append(model.kernel)\n",
    "noice_vars.append(model.likelihood.variance.numpy())\n",
    "labels.append('Neural Kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Stationary Attentive Kernel\n",
    "gpflow.config.set_default_jitter(1e-1)\n",
    "model_ak.kernel = AttentiveKernel(np.linspace(0.01, 2.0, 10))\n",
    "optimize_model(model_ak,\n",
    "               optimizer='tf.adam')\n",
    "\n",
    "kernels.append(model_ak.kernel)\n",
    "noice_vars.append(model_ak.likelihood.variance.numpy())\n",
    "labels.append('Attentive Kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationary RBF Kernel\n",
    "# get_model_params automatically handles GPR/SGPR creation and optimization.\n",
    "# It returns the loss history, optimized noise variance, and the optimized kernel.\n",
    "_, rbf_noise_variance, rbf_kernel = get_model_params(\n",
    "    X_train=X_train, y_train=Y_train, \n",
    "    lengthscales=[1.0, 0.5], # Initial lengthscales for RBF\n",
    ")\n",
    "\n",
    "# Store the trained RBF kernel and noise variance\n",
    "kernels.append(rbf_kernel)\n",
    "noice_vars.append(rbf_noise_variance)\n",
    "labels.append('RBF Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous-SGP solution from each kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_placements_list = [4, 9, 16, 64] # Number of sensor placements to evaluate\n",
    "labels_reversed = labels[::-1] # Reverse labels to match the kernel order in the loop below\n",
    "\n",
    "# Setup the matplotlib figure for plotting results\n",
    "fig, axs = plt.subplots(len(kernels), len(num_placements_list), figsize=(10, 7))\n",
    "# Iterate through each trained kernel and its corresponding noise variance\n",
    "for i, (kernel, noice_var) in enumerate(zip(kernels[::-1], noice_vars[::-1])):\n",
    "    for j, num_placements in enumerate(num_placements_list):\n",
    "        # Get initial inducing points for the ContinuousSGP optimization\n",
    "        # These will be the initial sensor locations.\n",
    "        Xu_init = get_inducing_pts(X_train, num_placements)\n",
    "        Xu_init = Xu_init.astype(np.float32) # Ensure data type consistency\n",
    "\n",
    "        # Setup ContinuousSGP model\n",
    "        # ContinuousSGP takes X_objective as the data for the SGPR model,\n",
    "        # and Xu_init is passed as the initial inducing_variable.\n",
    "        csgp_method = ContinuousSGP(\n",
    "            num_sensing=num_placements, \n",
    "            X_objective=X_train, # Use X_train as the objective points for SGP\n",
    "            kernel=kernel, # Pass the trained kernel\n",
    "            noise_variance=noice_var, # Pass the trained noise variance\n",
    "            X_init=Xu_init # Initial inducing points\n",
    "        )\n",
    "\n",
    "        # Optimize the ContinuousSGP model to find optimal sensor placements\n",
    "        # The optimize method returns the optimized inducing points (sensor locations).\n",
    "        # It reshapes the solution to (num_robots, num_sensing, num_dim) but here num_robots=1\n",
    "        # so we flatten it back to (num_sensing, num_dim).\n",
    "        sgp_sol_reshaped = csgp_method.optimize(max_steps=500, verbose=0) # Run optimization\n",
    "        sgp_sol_sp = sgp_sol_reshaped.reshape(-1, X_train.shape[1])\n",
    "\n",
    "        # Get the GP predictions\n",
    "        Xu_X, Xu_y = cont2disc(sgp_sol_sp, \n",
    "                               candidates=X_test,\n",
    "                               candidate_labels=Y_test)\n",
    "        gpr = gpflow.models.GPR((Xu_X, Xu_y),\n",
    "                                noise_variance=noice_var,\n",
    "                                kernel=kernel)\n",
    "        y_pred, y_var = gpr.predict_f(X_test)\n",
    "        y_pred = y_pred.numpy()\n",
    "\n",
    "        rmse = np.sqrt(np.mean((y_pred - Y_test)**2))\n",
    "\n",
    "        # Plot the results\n",
    "        axs[i, j].imshow(y_pred.reshape(test_data_dims[1], test_data_dims[0]),\n",
    "                         cmap='jet', origin='lower',\n",
    "                         extent=[np.min(X_test[:, 0]), np.max(X_test[:, 0]),\n",
    "                                 np.min(X_test[:, 1]), np.max(X_test[:, 1])])\n",
    "        axs[i, j].set_aspect('equal')\n",
    "        axs[i, j].scatter(sgp_sol_sp[:, 0], sgp_sol_sp[:, 1], c='k', marker='p', s=5)\n",
    "        axs[i, j].set_title(f'RMSE: {rmse:.3f}', fontsize='medium')\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "        axs[i, j].set_xlim([np.min(X_test[:, 0]), np.max(X_test[:, 0])])\n",
    "        axs[i, j].set_ylim([np.min(X_test[:, 1]), np.max(X_test[:, 1])])\n",
    "\n",
    "        if j==0:\n",
    "                axs[i, j].set_ylabel(f'{labels[i]}', fontsize='large')\n",
    "\n",
    "        if i==len(kernels)-1:\n",
    "                axs[i, j].set_xlabel(f'{num_placements} Sensors', fontsize='large')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The neural kernel performs the best but requires a large amount of computational power\n",
    "- The attentive kernel works well when given enough sensing locations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
